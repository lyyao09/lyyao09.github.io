<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lyyao09.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="云原生知识星球">
<meta property="og:url" content="https://lyyao09.github.io/page/3/index.html">
<meta property="og:site_name" content="云原生知识星球">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="LeaoYao">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://lyyao09.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>云原生知识星球</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">云原生知识星球</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2022/06/18/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%E5%AF%BC%E8%87%B4Pod%E5%8F%8D%E5%A4%8D%E9%87%8D%E5%90%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/18/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%E5%AF%BC%E8%87%B4Pod%E5%8F%8D%E5%A4%8D%E9%87%8D%E5%90%AF/" class="post-title-link" itemprop="url">K8S问题排查-安全策略导致Pod反复重启</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-06-18 18:47:44" itemprop="dateCreated datePublished" datetime="2022-06-18T18:47:44+00:00">2022-06-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><ol>
<li>查看<code>kube-system</code>下的系统组件，发现<code>harbor、influxdb、coredns</code>等组件反复重启；</li>
<li>使用<code>kubectl get pod -n kube-system</code>命令查看<code>pod</code>列表，发现命令会稳定的卡<code>15s</code>；</li>
</ol>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>先看第一点，这几个<code>pod</code>反复重启已经遇到过几次，看过前面的问题排查文章[1,2]的应该知道，在业务高并发场景下可能出现。先使用<code>top</code>命令看一下负载情况：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">load average: 14.76  18.45  17.85</span><br><span class="line">Tasks: 1998 total,  7 running,  1937 sleeping, 0 stopped,  54 zombie</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">CPU: 15.2 us, 8.3 sys, 0.7 ni, 75.3 <span class="built_in">id</span></span></span><br><span class="line"></span><br><span class="line">cat /proc/cpuinfo|grep MHz| wc -l</span><br><span class="line">40</span><br></pre></td></tr></table></figure>

<p>实际负载不高，排除这个可能（实际定位过程中，也依据前面的经验，做了相关内核参数的优化，问题确实没什么改善）。那就继续看，先<code>describe</code>看几个异常<code>pod</code>的错误信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubelet     Liveness probe failed: Get &quot;http://177.177.138.139:8885/api/health&quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)</span><br><span class="line">kubelet     Readiness probe failed: Get &quot;http://177.177.138.139:8083/&quot;&quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)</span><br><span class="line">kubelet     Back-off restarting failed container</span><br></pre></td></tr></table></figure>

<p>错误基本一致，就是<code>kubelet</code>调用<code>pod</code>提供的健康检查接口超时了，所以被不断地<code>kill</code>再重启。为什么调不通？模拟<code>kubelet</code>的调用操作，在<code>pod</code>所在节点上使用<code>curl</code>命令调用，结果显示<code>timeout</code>，再<code>ping</code>一下看看<code>pod</code>通信有没有问题：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping 177.177.212.186</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>

<p><code>ping</code>不通！这也就讲通了为啥健康检查不过，因为<code>kubelet</code>与所在节点上的<code>Pod</code>根本就无法通信。为啥会这样？通过一顿验证，发现一个规律：**集群各节点无法访问自己节点上的<code>pod</code>，但可以访问其他节点上的<code>pod</code>**；</p>
<p>这个现象是比较奇怪的，一般来说影响节点与自己节点上<code>pod</code>通信的原因不多，对于使用<code>calic</code>的<code>cni</code>网络插件来说，可能的原因有：</p>
<ol>
<li><code>pod</code>内的<code>ip</code>&#x2F;<code>arp</code>&#x2F;路由异常；</li>
<li><code>calico</code>网卡的<code>arp</code>配置异常；</li>
<li>请求被<code>iptables</code>拦截；</li>
</ol>
<p>分别查看1,2相关配置，显示正常：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@influxdb-847b74cbc5-ddxcd]# </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth0@if79: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 32:81:0e:f4:dd:3a brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 177.177.212.186/32 scope global eth0</span><br><span class="line">       valid_lft f</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">[root@influxdb-847b74cbc5-ddxcd]# </span><span class="language-bash">arp</span></span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">gateway                  ether   ee:ee:ee:ee:ee:ee   C                     eth0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">[root@influxdb-847b74cbc5-ddxcd]# </span><span class="language-bash">ip rou</span></span><br><span class="line">default via 169.254.1.1 dev eth0</span><br><span class="line">169.254.1.1 dev eth0 scope link</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/conf/cali7acfda72e71/proxy_arp</span></span><br><span class="line">1</span><br><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/conf/cali7acfda72e71/arp_ignore</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>对于第三点，通过<code>iptables</code>命令检查过，也没什么异常规则；</p>
<p>抓包看看啥情况：</p>
<ol>
<li>在节点上<code>ping</code>本节点上的pod，同时在<code>cali7acfda72e71</code>上抓包，发现请求到了<code>cali</code>网卡，但没有响应；</li>
<li>在<code>pod</code>内<code>ping</code>本节点<code>ip</code>，同时在<code>cali7acfda72e71</code>上抓包，发现<code>cali</code>网卡上有请求和响应，但依然无法<code>ping</code>通；</li>
</ol>
<p>看起来像是请求被主动丢弃了，跟问题提出人确认问题环境的基本情况，发现该集群有额外安装<code>EDR</code>防病毒软件。为了确认该软件有没有影响，先停掉防病毒软件，观察一段时候后，发现环境恢复正常。重新启动防病毒软件，一段时间后问题复现；</p>
<p>与负责防病毒软件的技术沟通确认，该集群被设置到了防病毒软件的默认策略里，触发条件是默认策略组里面有防止端口扫描和流量阈值配置，结果触发了网络防护，导致节点<code>ip</code>被封了。经过软件提供方的调整，将该集群调整到单独的策略编组，问题解决；</p>
<p>问题解决后，现象1和现象2都消失了，但回过头想想，为什么会出现现象2？当时环境好了没有细究，后来自己的测试环境也出现过这个现象，通过<code>debug</code>日志发现，卡在了调用<code>metric</code>服务的接口上，根本原因就是访问<code>metric</code>的<code>pod</code>不通，日志现象比较明显，这里就不贴了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kube-system -owide --v 10</span><br></pre></td></tr></table></figure>

<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li>针对该集群环境，单独配置策略编组；</li>
<li>节点与<code>Pod</code>通信正常后，现象2消失；</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://lyyao09.github.io/2021/06/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E4%B8%9A%E5%8A%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E5%AF%BC%E8%87%B4Pod%E5%8F%8D%E5%A4%8D%E9%87%8D%E5%90%AF/">https://lyyao09.github.io/2021/06/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E4%B8%9A%E5%8A%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E5%AF%BC%E8%87%B4Pod%E5%8F%8D%E5%A4%8D%E9%87%8D%E5%90%AF/</a></li>
<li><a href="https://lyyao09.github.io/2021/07/16/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E4%B8%9A%E5%8A%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E5%AF%BC%E8%87%B4Pod%E5%8F%8D%E5%A4%8D%E9%87%8D%E5%90%AF(%E7%BB%AD)/">https://lyyao09.github.io/2021/07/16/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E4%B8%9A%E5%8A%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E5%AF%BC%E8%87%B4Pod%E5%8F%8D%E5%A4%8D%E9%87%8D%E5%90%AF(%E7%BB%AD)/</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/409634">https://developer.aliyun.com/article/409634</a></li>
<li><a target="_blank" rel="noopener" href="https://www.css3.io/31linuxxi-tong-diao-you.htmls">https://www.css3.io/31linuxxi-tong-diao-you.htmls</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2022/06/05/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-VMWare%E8%99%9A%E6%8B%9F%E5%8C%96%E7%8E%AF%E5%A2%83%E4%B8%8BPod%E8%B7%A8VXLAN%E9%80%9A%E4%BF%A1%E5%BC%82%E5%B8%B8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/05/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-VMWare%E8%99%9A%E6%8B%9F%E5%8C%96%E7%8E%AF%E5%A2%83%E4%B8%8BPod%E8%B7%A8VXLAN%E9%80%9A%E4%BF%A1%E5%BC%82%E5%B8%B8/" class="post-title-link" itemprop="url">K8S问题排查-VMWare虚拟化环境下Pod跨VXLAN通信异常</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-06-05 17:38:44" itemprop="dateCreated datePublished" datetime="2022-06-05T17:38:44+00:00">2022-06-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>为了解决<a href="https://lyyao09.github.io/2022/03/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-Calico%E7%9A%84Vxlan%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%8A%82%E7%82%B9%E5%8F%91%E8%B5%B7K8s%20Service%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F/">节点上请求部分service延迟63s问题[1]</a>，我们临时把OS的版本换成了<code>Redhat 8.4</code>（内核版本<code>4.18.0-305</code>），在<code>VMware</code>上虚出3节点集群后部署跨三层环境失败，提示<code>Harbor</code>部署失败。</p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>说明：距离定位这个问题已经有一段时间了，其实最终也没完全定位出根本原因，所以当时也没有整理记录定位过程，这里就简单描述一下，做个记录。</p>
<p>通过查看<code>Harbor</code>的日志，发现部署失败的原因是健康检查失败，因为<code>Harbor</code>的<code>podIp:port</code>请求在跨三层下超时，抓包发现请求经过<code>vxlan.calico</code>时止于<code>SYN_SENT</code>报文；</p>
<p>实测发现，该环境上不仅是<code>Harbor</code>的<code>podIp:port</code>请求超时，其他<code>pod</code>服务的请求经过跨三层的网络也同样存在问题，说明是一个共性问题，并且<code>pod</code>网段的七层如<code>http</code>请求受影响，4层的<code>icmp</code>请求不受影响）；</p>
<p>继续通过抓包确认，<code>podIp:port</code>的请求已经发送到节点网卡上，但跨三层对端的节点没有收到。所以，可以排除主机上的<code>iptables</code>和路由的影响。实际上，也确实跟踪了<code>iptables</code>的请求过程，确认请求没有被丢弃；</p>
<p>综上，初步怀疑请求被跨三层网络的中间设备（如交换机、路由器）丢弃了，之后相关同事在交换机上抓包，发现<code>ping</code>包可以抓到，但<code>http</code>请求依然抓不到，说明交换机侧也没有收到报文，问题原因进一步缩小，可能情况有：</p>
<ol>
<li><strong>出口网卡丢弃；</strong></li>
<li><strong>出网卡后，入交换机之前丢弃</strong>；</li>
</ol>
<p>通过<code>ehtool -s xxx</code>命令统计虚机网卡报文信息，没有发现丢弃情况，说明问题不在虚机的出网卡；</p>
<p>关于<code>VMware</code>丢弃报文的情况，找到一些资料[2-6]，比如混杂模式，<code>mms</code>配置都会有影响：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1) 通过ping命令指定报文长度，发现跨网段依次ping一下pod的ip均返回正常，确认不是mms问题;</span><br><span class="line">ping -s 1000 177.177.x.x</span><br><span class="line">ping -s 1472 177.177.x.x </span><br><span class="line">ping -s 1500 177.177.x.x </span><br><span class="line"></span><br><span class="line">2) 通过临时修改网卡为混杂模式，测试问题依然存在;</span><br></pre></td></tr></table></figure>

<p>进一步在服务器物理网卡上抓包（登录<code>esxi</code>后台，使用<code>pktcap-uw --uplink vmnicX --dir 2 -o result.pcap</code>，其中<code>vmnicX</code>表示虚机关联的上行口物理网卡, <code>dir 2</code>表示同时抓取双向请求）, 依然是<code>ping</code>包可以抓到，但<code>http</code>请求依然抓不到，说明服务器物理网卡上也没有收到报文；</p>
<p>最后，丢包范围缩小到<code>VMare</code>下的<strong>虚机机请求出网卡后，到服务器物理网卡前</strong>  ，这中间涉及到虚拟化的实现，具体还有什么处理就不清楚了，最后改为使用物理服务器部署；</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>临时改用物理服务器部署跨三层集群成功，如果要使用<code>VMware</code>虚机部署，还需要继续排查根因。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://lyyao09.github.io/2022/03/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-Calico%E7%9A%84Vxlan%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%8A%82%E7%82%B9%E5%8F%91%E8%B5%B7K8s%20Service%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F/">https://lyyao09.github.io/2022/03/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-Calico%E7%9A%84Vxlan%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%8A%82%E7%82%B9%E5%8F%91%E8%B5%B7K8s%20Service%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F/</a></li>
<li><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/2113783">https://kb.vmware.com/s/article/2113783</a></li>
<li><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/52936">https://kb.vmware.com/s/article/52936</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.3/troubleshooting/GUID-4E4A9468-1F2B-44E1-A474-AA048A88BF1E.html">https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.3/troubleshooting/GUID-4E4A9468-1F2B-44E1-A474-AA048A88BF1E.html</a></li>
<li><a target="_blank" rel="noopener" href="https://communities.vmware.com/t5/vCloud-Networking-and-Security/No-SYN-ACK-reply-from-VM-on-virtual-wire-VXLAN/td-p/376545">https://communities.vmware.com/t5/vCloud-Networking-and-Security/No-SYN-ACK-reply-from-VM-on-virtual-wire-VXLAN/td-p/376545</a><ol>
<li><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/2051814?lang=zh_CN">https://kb.vmware.com/s/article/2051814?lang=zh_CN</a></li>
</ol>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2022/03/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-Calico%E7%9A%84Vxlan%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%8A%82%E7%82%B9%E5%8F%91%E8%B5%B7K8s%20Service%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/19/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-Calico%E7%9A%84Vxlan%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%8A%82%E7%82%B9%E5%8F%91%E8%B5%B7K8s%20Service%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F/" class="post-title-link" itemprop="url">K8S问题排查-Calico的Vxlan模式下节点发起K8s Service请求延迟</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-19 16:57:44" itemprop="dateCreated datePublished" datetime="2022-03-19T16:57:44+00:00">2022-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p><code>K8S</code>集群中修改<code>calico</code>的网络为<code>vxlan</code>模式后，发现部分<code>service</code>在节点上无法访问（实际上是延迟访问，延迟时间稳定在<code>1min3s</code>左右）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# time curl -s http://10.96.91.255</span><br><span class="line">real    1m3.136s</span><br><span class="line">user    0m0.005s</span><br><span class="line">sys     0m0.005s</span><br></pre></td></tr></table></figure>

<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>先确认问题范围，在环境上找多个<code>service</code>依次测试发现，如果调用<code>service</code>的节点和实际<code>pod</code>不在同一个节点上，则出现延迟，否则请求正常。也就是说跨节点的访问才有问题。而直接用<code>service</code>对应的<code>podIP</code>访问，也不存在问题，猜测问题可能出在<code>service</code>转<code>pod</code>的过程。</p>
<p>再确认基本环境，<code>OS</code>、<code>K8S</code>、<code>calico</code>等基础环境没有发生任何变化，仅仅是把<code>calico</code>的网络模式从<code>BGP</code>改为了<code>vxlan</code>，但是这个改动改变了集群内<code>service</code>及<code>pod</code>的请求路径，也即所有的容器请求需要走节点上新增的<code>calico.vxlan</code>接口封装一下。网络模式修改前没有问题，修改后必现，之后切回<code>BGP</code>模式问题就消失了，说明问题可能跟新增的<code>calico.vxlan</code>接口有关系。</p>
<p>先看下环境情况，并触发<code>service</code>请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证环境：node2（10.10.72.11）——&gt; node1（10.10.72.10）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证方法：node2上curl service:10.96.91.255 ——&gt; node1上pod:166.166.166.168:8082</span></span><br><span class="line">[root@node2 ~]# ip addr</span><br><span class="line">10: vxlan.calico: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1410 qdisc noqueue state UNKNOWN group default</span><br><span class="line">    link/ether 66:2d:bf:44:a6:8b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 166.166.104.10/32 brd 166.166.104.10 scope global vxlan.calico</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# ip addr</span><br><span class="line">15: vxlan.calico: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1410 qdisc noqueue state UNKNOWN group default</span><br><span class="line">    link/ether 66:f9:37:c3:7e:94 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 166.166.166.175/32 brd 166.166.166.175 scope global vxlan.calico</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">[root@node2 ~]# time curl http://10.96.91.255</span><br></pre></td></tr></table></figure>

<p>在<code>node1</code>的主机网卡上抓包看看封装后的请求是否已到达：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# tcpdump -n -vv -i eth0 host 10.10.72.11 and udp</span><br><span class="line">tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">07:19:42.730996 IP (tos 0x0, ttl 64, id 6470, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.10.72.11.nim-vdrshell &gt; 10.10.72.10.4789: [bad udp cksum 0xffff -&gt; 0x3af0!] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 64, id 39190, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    166.166.104.10.35632 &gt; 166.166.166.168.us-cli: Flags [S], cksum 0xe556 (correct), seq 3025623348, win 29200, options [mss 1460,sackOK,TS val 101892130 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:19:43.733741 IP (tos 0x0, ttl 64, id 6804, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.10.72.11.nim-vdrshell &gt; 10.10.72.10.4789: [bad udp cksum 0xffff -&gt; 0x3af0!] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 64, id 39191, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    166.166.104.10.35632 &gt; 166.166.166.168.us-cli: Flags [S], cksum 0xe16b (correct), seq 3025623348, win 29200, options [mss 1460,sackOK,TS val 101893133 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:19:45.736729 IP (tos 0x0, ttl 64, id 7403, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.10.72.11.nim-vdrshell &gt; 10.10.72.10.4789: [bad udp cksum 0xffff -&gt; 0x3af0!] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 64, id 39192, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    166.166.104.10.35632 &gt; 166.166.166.168.us-cli: Flags [S], cksum 0xd998 (correct), seq 3025623348, win 29200, options [mss 1460,sackOK,TS val 101895136 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:19:49.744801 IP (tos 0x0, ttl 64, id 9648, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.10.72.11.nim-vdrshell &gt; 10.10.72.10.4789: [bad udp cksum 0xffff -&gt; 0x3af0!] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 64, id 39193, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    166.166.104.10.35632 &gt; 166.166.166.168.us-cli: Flags [S], cksum 0xc9f0 (correct), seq 3025623348, win 29200, options [mss 1460,sackOK,TS val 101899144 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:19:57.768735 IP (tos 0x0, ttl 64, id 12853, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.10.72.11.nim-vdrshell &gt; 10.10.72.10.4789: [bad udp cksum 0xffff -&gt; 0x3af0!] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 64, id 39194, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    166.166.104.10.35632 &gt; 166.166.166.168.us-cli: Flags [S], cksum 0xaa98 (correct), seq 3025623348, win 29200, options [mss 1460,sackOK,TS val 101907168 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:20:05.087057 IP (tos 0x0, ttl 64, id 8479, offset 0, flags [none], proto UDP (17), length 164)</span><br><span class="line">    10.10.72.10.34565 &gt; 10.10.72.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 3425, offset 0, flags [DF], proto UDP (17), length 114)</span><br><span class="line">    166.166.166.168.57850 &gt; 166.166.104.6.domain: [udp sum ok] 10121+ AAAA? influxdb-nginx-service.kube-system.svc.kube-system.svc.cluster.local. (86)</span><br><span class="line">07:20:05.087076 IP (tos 0x0, ttl 64, id 54475, offset 0, flags [none], proto UDP (17), length 164)</span><br><span class="line">    10.10.72.10.51841 &gt; 10.10.72.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 3424, offset 0, flags [DF], proto UDP (17), length 114)</span><br><span class="line">    166.166.166.168.57984 &gt; 166.166.104.6.domain: [udp sum ok] 20020+ A? influxdb-nginx-service.kube-system.svc.kube-system.svc.cluster.local. (86)</span><br><span class="line">07:20:05.087671 IP (tos 0x0, ttl 64, id 13540, offset 0, flags [none], proto UDP (17), length 257)</span><br><span class="line">    10.10.72.11.60395 &gt; 10.10.72.10.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 19190, offset 0, flags [DF], proto UDP (17), length 207)</span><br><span class="line">    166.166.104.6.domain &gt; 166.166.166.168.57850: [udp sum ok] 10121 NXDomain*- q: AAAA? influxdb-nginx-service.kube-system.svc.kube-system.svc.cluster.local. 0/1/0 ns: cluster.local. SOA ns.dns.cluster.local. hostmaster.cluster.local. 1647633218 7200 1800 86400 5 (179)</span><br><span class="line">07:20:05.087702 IP (tos 0x0, ttl 64, id 13541, offset 0, flags [none], proto UDP (17), length 257)</span><br><span class="line">    10.10.72.11.48571 &gt; 10.10.72.10.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 19191, offset 0, flags [DF], proto UDP (17), length 207)</span><br><span class="line">    166.166.104.6.domain &gt; 166.166.166.168.57984: [udp sum ok] 20020 NXDomain*- q: A? influxdb-nginx-service.kube-system.svc.kube-system.svc.cluster.local. 0/1/0 ns: cluster.local. SOA ns.dns.cluster.local. hostmaster.cluster.local. 1647633218 7200 1800 86400 5 (179)</span><br><span class="line">07:20:05.088801 IP (tos 0x0, ttl 64, id 8480, offset 0, flags [none], proto UDP (17), length 152)</span><br><span class="line">    10.10.72.10.55780 &gt; 10.10.72.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 3427, offset 0, flags [DF], proto UDP (17), length 102)</span><br><span class="line">    166.166.166.168.56015 &gt; 166.166.104.6.domain: [udp sum ok] 19167+ AAAA? influxdb-nginx-service.kube-system.svc.svc.cluster.local. (74)</span><br><span class="line">07:20:05.089048 IP (tos 0x0, ttl 64, id 13542, offset 0, flags [none], proto UDP (17), length 245)</span><br><span class="line">    10.10.72.11.50151 &gt; 10.10.72.10.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 19192, offset 0, flags [DF], proto UDP (17), length 195)</span><br><span class="line">    166.166.104.6.domain &gt; 166.166.166.168.56015: [udp sum ok] 19167 NXDomain*- q: AAAA? influxdb-nginx-service.kube-system.svc.svc.cluster.local. 0/1/0 ns: cluster.local. SOA ns.dns.cluster.local. hostmaster.cluster.local. 1647633218 7200 1800 86400 5 (167)</span><br><span class="line">07:20:05.089212 IP (tos 0x0, ttl 64, id 8481, offset 0, flags [none], proto UDP (17), length 148)</span><br><span class="line">    10.10.72.10.50272 &gt; 10.10.72.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 3430, offset 0, flags [DF], proto UDP (17), length 98)</span><br><span class="line">    166.166.166.168.54926 &gt; 166.166.104.6.domain: [udp sum ok] 40948+ A? influxdb-nginx-service.kube-system.svc.cluster.local. (70)</span><br><span class="line">07:20:05.089403 IP (tos 0x0, ttl 64, id 13543, offset 0, flags [none], proto UDP (17), length 241)</span><br><span class="line">    10.10.72.11.59882 &gt; 10.10.72.10.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 19193, offset 0, flags [DF], proto UDP (17), length 191)</span><br><span class="line">    166.166.104.6.domain &gt; 166.166.166.168.54926: [udp sum ok] 40948 NXDomain*- q: A? influxdb-nginx-service.kube-system.svc.cluster.local. 0/1/0 ns: cluster.local. SOA ns.dns.cluster.local. hostmaster.cluster.local. 1647633218 7200 1800 86400 5 (163)</span><br><span class="line">07:20:05.089524 IP (tos 0x0, ttl 64, id 8482, offset 0, flags [none], proto UDP (17), length 134)</span><br><span class="line">    10.10.72.10.58964 &gt; 10.10.72.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 3431, offset 0, flags [DF], proto UDP (17), length 84)</span><br><span class="line">    166.166.166.168.50263 &gt; 166.166.104.6.domain: [udp sum ok] 18815+ A? influxdb-nginx-service.kube-system.svc. (56)</span><br><span class="line">07:20:05.089681 IP (tos 0x0, ttl 64, id 13544, offset 0, flags [none], proto UDP (17), length 134)</span><br><span class="line">    10.10.72.11.51874 &gt; 10.10.72.10.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 19194, offset 0, flags [DF], proto UDP (17), length 84)</span><br><span class="line">    166.166.104.6.domain &gt; 166.166.166.168.50263: [udp sum ok] 18815 ServFail- q: A? influxdb-nginx-service.kube-system.svc. 0/0/0 (56)</span><br><span class="line">07:20:05.089706 IP (tos 0x0, ttl 64, id 8483, offset 0, flags [none], proto UDP (17), length 134)</span><br><span class="line">    10.10.72.10.59891 &gt; 10.10.72.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 3433, offset 0, flags [DF], proto UDP (17), length 84)</span><br><span class="line">    166.166.166.168.49202 &gt; 166.166.104.6.domain: [udp sum ok] 58612+ AAAA? influxdb-nginx-service.kube-system.svc. (56)</span><br><span class="line">07:20:05.089859 IP (tos 0x0, ttl 64, id 13545, offset 0, flags [none], proto UDP (17), length 134)</span><br><span class="line">    10.10.72.11.44146 &gt; 10.10.72.10.4789: [no cksum] VXLAN, flags [I] (0x08), vni 4096</span><br><span class="line">IP (tos 0x0, ttl 63, id 19195, offset 0, flags [DF], proto UDP (17), length 84)</span><br><span class="line">    166.166.104.6.domain &gt; 166.166.166.168.49202: [udp sum ok] 58612 ServFail- q: AAAA? influxdb-nginx-service.kube-system.svc. 0/0/0 (56)</span><br></pre></td></tr></table></figure>

<p>从抓包结果看，出现一个可疑点：前几个报文中提示<code>bad udp cksum 0xffff</code>，请求通的最后几个报文提示的是<code>no cksum</code>。</p>
<p>根据这个错误信息，搜索发现是个已知<code>bug</code>，相关的详细定位可以参考[1]-[3]，这里就不细说了。大概原因如下所述：</p>
<blockquote>
<p>内核中存在一个和<code>VXLAN</code>处理有关的缺陷，该缺陷会导致<code>Checksum Offloading</code>不能正确完成。这个缺陷仅仅在很边缘的场景下才会表现出来。</p>
<p>在<code>VXLAN</code>的<code>UDP</code>头被<code>NAT</code>过的前提下，如果：</p>
<ol>
<li><code>VXLAN</code>设备禁用（这是<code>RFC</code>的建议）了<code>UDP Checksum</code></li>
<li><code>VXLAN</code>设备启用了<code>Tx Checksum Offloading</code></li>
</ol>
<p>就会导致生成错误的<code>UDP Checksum</code>。</p>
</blockquote>
<p>从资料[1]看，<code>K8S</code>的<code>v1.18.5</code>版本已经修复了这个问题，但我的问题是在<code>v1.21.0</code>上发现的，所以不确定只升级<code>K8S</code>是否可以解决该问题，或者升级后还需要额外配置什么？</p>
<p>从资料[3]和[4]看，<code>calico</code>在<code>v3.20.0</code>版本做了修改：在<code>kernels &lt; v5.7</code>时也禁用了<code>calico.vxlan</code>接口的<code>Offloading</code>功能。</p>
<p>本地临时禁用并验证：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# ethtool --offload vxlan.calico rx off tx off</span><br><span class="line">Actual changes:</span><br><span class="line">rx-checksumming: off</span><br><span class="line">tx-checksumming: off</span><br><span class="line">        tx-checksum-ip-generic: off</span><br><span class="line">tcp-segmentation-offload: off</span><br><span class="line">        tx-tcp-segmentation: off [requested on]</span><br><span class="line">        tx-tcp-ecn-segmentation: off [requested on]</span><br><span class="line">        tx-tcp6-segmentation: off [requested on]</span><br><span class="line">        tx-tcp-mangleid-segmentation: off [requested on]</span><br><span class="line">udp-fragmentation-offload: off [requested on]</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# time curl http://10.96.91.255</span><br><span class="line">real    0m0.009s</span><br><span class="line">user    0m0.002s</span><br><span class="line">sys     0m0.007s</span><br></pre></td></tr></table></figure>

<p>请求恢复正常。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li>临时解决： <code>ethtool --offload vxlan.calico rx off tx off</code></li>
<li>永久解决：升级<code>calico &gt;=v3.20.0</code>或升级内核到<code>5.6.13, 5.4.41, 4.19.123, 4.14.181</code>，单独升级<code>K8S &gt;= v1.18.5</code>版本待确认是否能解决</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://blog.gmem.cc/nodeport-63s-delay-due-to-kernel-issue">https://blog.gmem.cc/nodeport-63s-delay-due-to-kernel-issue</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudnative.to/blog/kubernetes-1-17-vxlan-63s-delay/">https://cloudnative.to/blog/kubernetes-1-17-vxlan-63s-delay/</a></li>
<li><a target="_blank" rel="noopener" href="https://bowser1704.github.io/posts/vxlan-bug/">https://bowser1704.github.io/posts/vxlan-bug/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/projectcalico/calico/issues/3145">https://github.com/projectcalico/calico/issues/3145</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/projectcalico/felix/pull/2811/files">https://github.com/projectcalico/felix/pull/2811/files</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2022/02/26/docker/Docker%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E5%BC%82%E5%B8%B8%E6%96%AD%E7%94%B5%E5%AF%BC%E8%87%B4Docker%E5%90%AF%E5%8A%A8%E5%8D%A1%E4%BD%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/26/docker/Docker%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E5%BC%82%E5%B8%B8%E6%96%AD%E7%94%B5%E5%AF%BC%E8%87%B4Docker%E5%90%AF%E5%8A%A8%E5%8D%A1%E4%BD%8F/" class="post-title-link" itemprop="url">Docker问题排查-异常断电导致Docker启动卡住</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-26 18:13:11" itemprop="dateCreated datePublished" datetime="2022-02-26T18:13:11+00:00">2022-02-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>12 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>Docker守护进程在异常断电后卡在<code>activating</code>状态，并且内存占用在无限增加。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 docker]# service docker status</span><br><span class="line">Redirecting to /bin/systemctl status docker.service</span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/docker.service.d</span><br><span class="line">           └─restart.conf</span><br><span class="line">   Active: activating (start) since Tue 2021-12-07 15:44:32 CST; 1min 18s ago</span><br><span class="line">     Docs: https:/docs.docker.com</span><br><span class="line"> Main PID: 274797 (dockerd)</span><br><span class="line">    Tasks: 481</span><br><span class="line">   Memory: 15.4G  -- 占用不正常</span><br><span class="line">   CGroup: /system</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 docker]# service docker status</span><br><span class="line">Redirecting to /bin/systemctl status docker.service</span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/docker.service.d</span><br><span class="line">           └─restart.conf</span><br><span class="line">   Active: deactivating (stop-sigterm)</span><br><span class="line">     Docs: https:/docs.docker.com</span><br><span class="line"> Main PID: 274797 (dockerd)</span><br><span class="line">    Tasks: 481</span><br><span class="line">   Memory: 247.3G   -- 一直在疯狂增加</span><br><span class="line">   CGroup: /system.slice/docker.service</span><br><span class="line">           └─274</span><br></pre></td></tr></table></figure>

<h2 id="定位过程"><a href="#定位过程" class="headerlink" title="定位过程"></a>定位过程</h2><p>首先，查看<code>docker</code>版本和<code>docker info</code>信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node01files]# </span><span class="language-bash">docker version</span></span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           20.10.7</span><br><span class="line"> API version:       1.41</span><br><span class="line"> Go version:        go1.13.15</span><br><span class="line"> Git commit:        f0df350</span><br><span class="line"> Built:             Wed Jun  2 11:58:10 2021</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Context:           default</span><br><span class="line"> Experimental:      true</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          20.10.7</span><br><span class="line">  API version:      1.41 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.13.15</span><br><span class="line">  Git commit:       b0f5bc3</span><br><span class="line">runc:</span><br><span class="line">  Version:          1.0.0-rc95</span><br><span class="line">  GitCommit:        b9ee9c6314599f1b4a7f497e1f1f856fe433d3b7</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.19.0</span><br><span class="line">  GitCommit:        de40ad0</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 files]# docker info</span><br><span class="line">Client:</span><br><span class="line"> Context:    default</span><br><span class="line"> Debug Mode: false</span><br><span class="line"> Plugins:</span><br><span class="line">  app: Docker App (Docker Inc., v0.9.1-beta3)</span><br><span class="line">  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)</span><br><span class="line">  scan: Docker Scan (Docker Inc., v0.8.0)</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Server Version: 20.10.7</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Supports d_type: true</span><br><span class="line">  Native Overlay Diff: true</span><br><span class="line">  userxattr: false</span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: systemd</span><br><span class="line"> Cgroup Version: 1</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: local</span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d</span><br><span class="line"> runc version: b9ee9c6314599f1b4a7f497e1f1f856fe433d3b7</span><br><span class="line"> init version: de40ad0</span><br><span class="line"> Security Options:</span><br><span class="line">   seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 3.10.0-957.21.3.el7.x86_64</span><br><span class="line"> Operating System: CentOS 7.6</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> Total Memory: 256GiB</span><br><span class="line"> Name: node01</span><br><span class="line"> Docker Root Dir: /var/lib/docker</span><br><span class="line"> Debug Mode: false</span><br><span class="line">  File Descriptors: 366</span><br><span class="line">  Goroutines: 290</span><br><span class="line">  EventsListeners: 0</span><br><span class="line"> Registry: https:/index.docker.io/v1/</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: false</span><br><span class="line"> Insecure Registries:</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Live Restore Enabled: true</span><br></pre></td></tr></table></figure>

<p>版本还算比较新，查看<code>docker</code>日志：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">Dec 07 14:57:57 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:57.831370861+08:00&quot; level=info msg=&quot;Starting up&quot;</span><br><span class="line">Dec 07 14:57:57 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:57.950367668+08:00&quot; level=info msg=&quot;parsed scheme: \&quot;unix\&quot;&quot; module=grpc</span><br><span class="line">Dec 07 14:57:57 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:57.950430356+08:00&quot; level=info msg=&quot;scheme \&quot;unix\&quot; not registered, fallback to default scheme&quot; module=grpc</span><br><span class="line">Dec 07 14:57:57 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:57.950486773+08:00&quot; level=info msg=&quot;ccResolverWrapper: sending update to cc: &#123;[&#123;unix://run/containerd/containerd.sock  &lt;nil&gt; 0 &lt;nil&gt;&#125;] &lt;nil&gt; &lt;nil&gt;&#125;&quot; module=grpc</span><br><span class="line">Dec 07 14:57:57 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:57.950524941+08:00&quot; level=info msg=&quot;ClientConn switching balancer to \&quot;pick_first\&quot;&quot; module=grpc</span><br><span class="line">Dec 07 14:57:58 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:58.004622322+08:00&quot; level=info msg=&quot;parsed scheme: \&quot;unix\&quot;&quot; module=grpc</span><br><span class="line">Dec 07 14:57:58 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:58.004663918+08:00&quot; level=info msg=&quot;scheme \&quot;unix\&quot; not registered, fallback to default scheme&quot; module=grpc</span><br><span class="line">Dec 07 14:57:58 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:58.004697382+08:00&quot; level=info msg=&quot;ccResolverWrapper: sending update to cc: &#123;[&#123;unix://run/containerd/containerd.sock  &lt;nil&gt; 0 &lt;nil&gt;&#125;] &lt;nil&gt; &lt;nil&gt;&#125;&quot; module=grpc</span><br><span class="line">Dec 07 14:57:58 node01 dockerd[239420]: time=&quot;2021-12-07T14:57:58.004726533+08:00&quot; level=info msg=&quot;ClientConn switching balancer to \&quot;pick_first\&quot;&quot; module=grpc</span><br><span class="line">Dec 07 14:58:14 node01 dockerd[239420]: time=&quot;2021-12-07T14:58:14.832862519+08:00&quot; level=info msg=&quot;[graphdriver] using prior storage driver: overlay2&quot;</span><br><span class="line">Dec 07 14:59:00 node01 dockerd[239420]: time=&quot;2021-12-07T14:59:00.039554832+08:00&quot; level=info msg=&quot;Loading containers: start.&quot;</span><br><span class="line">Dec 07 15:02:27 node01 dockerd[239420]: fatal error: runtime: out of memory</span><br><span class="line">Dec 07 15:02:27 node01 dockerd[239420]: runtime stack:</span><br><span class="line">Dec 07 15:02:27 node01 dockerd[239420]: runtime.throw(0x5604d0deee9d, 0x16)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/panic.go:774 +0x74</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.sysMap(0xfb6c000000, 0x5c000000, 0x5604d35dab58)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/mem_linux.go:169 +0xc7</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.(*mheap).sysAlloc(0x5604d35be240, 0x5beee000, 0x7f6fd1fbab88, 0x5604cf22bf6b)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/malloc.go:701 +0x1cf</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.(*mheap).grow(0x5604d35be240, 0x2df77, 0xffffffff)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/mheap.go:1255 +0xa5</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.(*mheap).allocSpanLocked(0x5604d35be240, 0x2df77, 0x5604d35dab68, 0x5604cf212927)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/mheap.go:1170 +0x268</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.(*mheap).alloc_m(0x5604d35be240, 0x2df77, 0x7f6c01180100, 0x7f6c01184350)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/mheap.go:1022 +0xc6</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.(*mheap).alloc.func1()</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/mheap.go:1093 +0x4e</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.(*mheap).alloc(0x5604d35be240, 0x2df77, 0x7f6fd1010100, 0x7f6c01184350)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/mheap.go:1092 +0x8c</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.largeAlloc(0x5beee000, 0x5604cf250001, 0x7f6c01184350)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/malloc.go:1138 +0x99</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.mallocgc.func1()</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/malloc.go:1033 +0x48</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.systemstack(0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/asm_amd64.s:370 +0x63</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.mstart()</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/proc.go:1146</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: goroutine 1 [running]:</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.systemstack_switch()</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/asm_amd64.s:330 fp=0xc0008bff70 sp=0xc0008bff68 pc=0x5604cf2528e0</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.mallocgc(0x5beee000, 0x5604d1e8fde0, 0x1, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/malloc.go:1032 +0x8a7 fp=0xc0008c0010 sp=0xc0008bff70 pc=0x5604cf200ef7</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: runtime.growslice(0x5604d1e8fde0, 0xef119e4000, 0x3107eaa, 0x3107eaa, 0x3107eab, 0x5604cf20146b, 0xfb6bbbfb80, 0x7f6c01184350)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /usr/local/go/src/runtime/slice.go:181 +0x1e4 fp=0xc0008c0078 sp=0xc0008c0010 pc=0x5604cf23b0b4</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt.(*Cursor).first(0xc0008c0288)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: docker/vendor/go.etcd.io/bbolt/cursor.go:182 +0x138 fp=0xc0008c00d8 sp=0xc0008c0078 pc=0x5604d012d348</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt.(*Cursor).next(0xc0008c0288, 0x0, 0x9f, 0x9f, 0x7f7150506429, 0x2b8, 0xc0008c0188, 0x5604cf23ee10)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt/cursor.go:234 +0x84 fp=0xc0008c0128 sp=0xc0008c00d8 pc=0x5604d012d684</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt.(*Cursor).Next(0xc0008c0288, 0x7f715050638a, 0x9f, 0x9f, 0xfb6bbcf720, 0x9f, 0x2b8)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt/cursor.go:75 +0x43 fp=0xc0008c0198 sp=0xc0008c0128 pc=0x5604d012ca43</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libkv/store/boltdb.(*BoltDB).List.func1(0xc0034350a0, 0xc0008c0200, 0xc0034350a0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libkv/store/boltdb/boltdb.go:288 +0x19a fp=0xc0008c02b8 sp=0xc0008c0198 pc=0x5604d0142a4a</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt.(*DB).View(0xc0001dc200, 0xc0008c03f8, 0x0, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/go.etcd.io/bbolt/db.go:725 +0xaa fp=0xc0008c0340 sp=0xc0008c02b8 pc=0x5604d0130a3a</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libkv/store/boltdb.(*BoltDB).List(0xc00482f2c0, 0xc001a7af00, 0x5e, 0x0, 0x0, 0x0, 0x0, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libkv/store/boltdb/boltdb.go:279 +0x1b3 fp=0xc0008c0430 sp=0xc0008c0340 pc=0x5604d0141583</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/datastore.(*cache).kmap(0xc003bf5900, 0x5604d220c1a0, 0xc001e7c160, 0x0, 0x5e, 0xc001a7ae40)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/datastore/cache.go:43 +0x286 fp=0xc0008c0560 sp=0xc0008c0430 pc=0x5604cfcc81a6</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/datastore.(*cache).list(0xc003bf5900, 0x5604d220c1a0, 0xc001e7c160, 0x0, 0x0, 0x0, 0x0, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/datastore/cache.go:164 +0x7e fp=0xc0008c0678 sp=0xc0008c0560 pc=0x5604cfcc988e</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/datastore.(*datastore).List(0xc0079ff680, 0xc001a7ae40, 0x5e, 0x5604d220c1a0, 0xc001e7c160, 0x0, 0x0, 0x0, 0x0, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/datastore/datastore.go:517 +0x205 fp=0xc0008c0730 sp=0xc0008c0678 pc=0x5604cfccc745</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork.(*network).getEndpointsFromStore(0xc00289a380, 0xc004a99258, 0x7, 0x5604d2206920, 0xc001a515f0, 0xc002f3ff48)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/store.go:190 +0x343 fp=0xc0008c09f8 sp=0xc0008c0730 pc=0x5604d01acaf3</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork.(*controller).reservePools(0xc0004b7400)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/controller.go:977 +0x4c1 fp=0xc0008c0c28 sp=0xc0008c09f8 pc=0x5604d0159701</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork.New(0xc001055d00, 0x9, 0x10, 0xc0007ac870, 0xc001387fb0, 0xc001055d00, 0x9)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/vendor/libnetwork/controller.go:245 +0x615 fp=0xc0008c0dd8 sp=0xc0008c0c28 pc=0x5604d0154815</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/daemon.(*Daemon).initNetworkController(0xc00000c1e0, 0xc000207080, 0xc001387fb0, 0xc000236f50, 0xc00000c1e0, 0xc0007170c8, 0xc001387fb0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/daemon/daemon_unix.go:855 +0xa9 fp=0xc0008c0e90 sp=0xc0008c0dd8 pc=0x5604d0a49429</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/daemon.(*Daemon).restore(0xc00000c1e0, 0xc00004e5c0, 0xc000220000)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/daemon/daemon.go:490 +0x50b fp=0xc0008c1088 sp=0xc0008c0e90 pc=0x5604d0a3898b</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/daemon.NewDaemon(0x5604d21de4c0, 0xc00004e5c0, 0xc000207080, 0xc0007ac870, 0x0, 0x0, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/daemon/daemon.go:1147 +0x2be8 fp=0xc0008c19c8 sp=0xc0008c1088 pc=0x5604d0a3c938</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: main.(*DaemonCli).start(0xc0007ab410, 0xc000218600, 0x0, 0x0)</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: /docker/cmd/dockerd/daemon.go:195 +0x743 fp=0xc0008c1d00 sp=0xc0008c19c8 pc=0x5604d0dbb3c3</span><br><span class="line">Dec 07 15:02:28 node01 dockerd[239420]: main.runDaemon(...)</span><br></pre></td></tr></table></figure>

<p>日志中存在明显的异常堆栈打印，分析可知，启动过程中走到<code>Loading containers: start.</code>之后卡住，然后打印<code>fatal error: runtime: out of memory</code>，也就是内存爆了。根据堆栈信息，可以看出异常的调用路径如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NewDaemon —&gt; restore() —&gt; initNetworkController —&gt; libnetwork.New() —&gt; reservePools() —&gt;  getEndpointsFromStore() —&gt; List —&gt; cache.list(kvObject) —&gt; cache.kmap(kvObject) —&gt; List(keyPrefix) —&gt; Next —&gt; next —&gt; first</span><br></pre></td></tr></table></figure>

<p>拉取对应版本的代码，根据上述调用过程，找到指定的代码位置：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// List returns the range of keys starting with the passed in prefix</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *BoltDB)</span></span> List(keyPrefix <span class="type">string</span>) ([]*store.KVPair, <span class="type">error</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> (</span><br><span class="line">        db  *bolt.DB</span><br><span class="line">        err <span class="type">error</span></span><br><span class="line">    )</span><br><span class="line">    b.Lock()</span><br><span class="line">    <span class="keyword">defer</span> b.Unlock()</span><br><span class="line"></span><br><span class="line">    kv := []*store.KVPair&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> db, err = b.getDBhandle(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> b.releaseDBhandle()</span><br><span class="line"></span><br><span class="line">    err = db.View(<span class="function"><span class="keyword">func</span><span class="params">(tx *bolt.Tx)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">        bucket := tx.Bucket(b.boltBucket)</span><br><span class="line">        <span class="keyword">if</span> bucket == <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> store.ErrKeyNotFound</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        cursor := bucket.Cursor()</span><br><span class="line">        prefix := []<span class="type">byte</span>(keyPrefix)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> key, v := cursor.Seek(prefix); bytes.HasPrefix(key, prefix); key, v = cursor.Next() &#123;</span><br><span class="line"></span><br><span class="line">            dbIndex := binary.LittleEndian.Uint64(v[:libkvmetadatalen])</span><br><span class="line">            v = v[libkvmetadatalen:]</span><br><span class="line">            val := <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="built_in">len</span>(v))</span><br><span class="line">            <span class="built_in">copy</span>(val, v)</span><br><span class="line"></span><br><span class="line">            kv = <span class="built_in">append</span>(kv, &amp;store.KVPair&#123;</span><br><span class="line">                Key:       <span class="type">string</span>(key),</span><br><span class="line">                Value:     val,</span><br><span class="line">                LastIndex: dbIndex,</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(kv) == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, store.ErrKeyNotFound</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> kv, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出，这段是读取<code>boltdb</code>数据库（用于缓存网络配置），从之前了解看，这个数据库在异常断电时很容易损坏，所以怀疑是数据库损坏了，导致此处的遍历读取超出了预期的循环次数，而每次循环都会创建变量，分配内存，最终被内核<code>OOM</code>。</p>
<p>在<code>docker</code>社区查找相关<code>issue</code>[1] [2]，发现确实存在<code>boltdb</code>数据库损坏的现象，不过最终报错的现象不太一样。最后，在<code>docker</code>社区也提了个<code>issue</code>[3]，社区反馈也是怀疑<code>boltdb</code>数据库损坏，并建议可以把<code>local-kv.db</code>文件删除再重启来恢复。</p>
<p>个人觉得，上面报错的地方可以优化一下，对<code>db</code>文件做一次检查，如果检查到异常，提前抛异常，而不是不停地吃内存（由于异常的环境被破坏了，这个想法需要等复现后再考虑优化）。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li>临时解决：删除<code>local-kv.db</code>文件再重启<code>docker</code>服务。</li>
<li>永久解决：优化异常代码。</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/moby/moby/issues/37238">https://github.com/moby/moby/issues/37238</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/moby/moby/issues/42099">https://github.com/moby/moby/issues/42099</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/moby/moby/issues/43072">https://github.com/moby/moby/issues/43072</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2021/12/25/java/Karaf%E6%A1%86%E6%9E%B6%E5%8D%87%E7%BA%A7Lg4j%E5%8E%86%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/25/java/Karaf%E6%A1%86%E6%9E%B6%E5%8D%87%E7%BA%A7Lg4j%E5%8E%86%E7%A8%8B/" class="post-title-link" itemprop="url">Karaf框架升级Lg4j历程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-25 09:15:21" itemprop="dateCreated datePublished" datetime="2021-12-25T09:15:21+00:00">2021-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p><code>karaf</code>框架没有直接依赖<code>log4j</code>包，所以简单的升级项目中的<code>log4j</code>或实际项目中没有<code>log4j</code>，都无法解决最近发现的漏洞问题（<strong>CVE-2021-44228</strong>、<strong>CVE-2021-45046</strong>、<strong>CVE-2021-45046</strong>）。</p>
<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>分析发现，<code>karaf</code>框架实际依赖的日志包是<code>org.ops4j.pax.logging.xxx</code>，而<code>org.ops4j.pax.logging.xxx</code>依赖了<code>log4j</code>，相当于做了一层包装。所以，要解决漏洞，有三种升级方式：</p>
<ol>
<li><strong>升级框架</strong>：这个影响就比较大了，而且框架的版本发布周期比较慢，目前还没有编译好的框架包，要升级框架就需要自己编译出所有的框架包，风险较大；</li>
<li><strong>升级依赖包</strong>：影响较小，如果没有配置依赖包的地方，可能无法升级；（实际确认，无法单独升级）</li>
<li><strong>修改当前版本依赖包并重新编译</strong>：影响较小，如果与最新版本跨度较大，可能修改点会很多；</li>
</ol>
<p>综合比较，考虑使用第3个方案走走看，从参考资料[1]的代码提交记录看，<code>org.ops4j.pax.logging</code>为了解决<code>log4j</code>漏洞，仅涉及依赖包<code>log4j</code>的版本升级，版本跨度是从<code>1.11.9</code>升级到<code>1.11.12</code>，跨度不大，实际有哪些修改点，先编译看看有没有问题：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pom.xml</span><br><span class="line">        &lt;version.org.apache.felix.configadmin&gt;1.9.20&lt;/version.org.apache.felix.configadmin&gt;</span><br><span class="line">        &lt;version.org.apache.felix.framework&gt;5.6.12&lt;/version.org.apache.felix.framework&gt;</span><br><span class="line">        &lt;version.org.apache.felix6.framework&gt;6.0.3&lt;/version.org.apache.felix6.framework&gt;</span><br><span class="line">-       &lt;version.org.apache.logging.log4j&gt;2.16.0&lt;/version.org.apache.logging.log4j&gt;</span><br><span class="line">+       &lt;version.org.apache.logging.log4j&gt;2.17.0&lt;/version.org.apache.logging.log4j&gt;</span><br><span class="line">        &lt;version.org.apache.servicemix.bundles.javax-inject&gt;1_3&lt;/version.org.apache.servicemix.bundles.javax-inject&gt;</span><br><span class="line">        &lt;version.org.jboss.logging&gt;3.4.1.Final&lt;/version.org.jboss.logging&gt;</span><br><span class="line">        &lt;version.org.mockito&gt;3.7.7&lt;/version.org.mockito&gt;</span><br></pre></td></tr></table></figure>

<p>下载当前使用的版本，从源码的各模块看，可能需要<code>jdk9</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@node org.ops4j.pax.logging-logging-1.11.9]# ll</span><br><span class="line">total 144</span><br><span class="line">-rw-r--r--  1 root root   939 Feb 23  2021 CONTRIBUTORS.txt</span><br><span class="line">-rw-r--r--  1 root root   755 Feb 23  2021 license-header.txt</span><br><span class="line">-rw-r--r--  1 root root 12525 Feb 23  2021 LICENSE.txt</span><br><span class="line">drwxr-xr-x  4 root root    99 Dec 21 17:51 pax-logging-api</span><br><span class="line">drwxr-xr-x  4 root root    46 Dec 21 17:51 pax-logging-api-java9</span><br><span class="line">drwxr-xr-x  4 root root    46 Dec 21 17:51 pax-logging-it</span><br><span class="line">drwxr-xr-x  6 root root   106 Feb 23  2021 pax-logging-it-karaf</span><br><span class="line">drwxr-xr-x  4 root root    99 Dec 21 17:51 pax-logging-log4j2</span><br><span class="line">drwxr-xr-x  4 root root    99 Dec 21 17:51 pax-logging-log4j2-extra</span><br><span class="line">drwxr-xr-x  4 root root    99 Dec 21 17:51 pax-logging-logback</span><br><span class="line">drwxr-xr-x  2 root root    21 Feb 23  2021 pax-logging-report</span><br><span class="line">drwxr-xr-x 10 root root   166 Feb 23  2021 pax-logging-samples</span><br><span class="line">drwxr-xr-x  4 root root    99 Dec 21 17:51 pax-logging-service</span><br><span class="line">-rw-r--r--  1 root root 46604 Dec 21 17:46 pom.xml</span><br><span class="line">-rw-r--r--  1 root root 67356 Feb 23  2021 readme.adoc</span><br><span class="line">drwxr-xr-x  3 root root    18 Feb 23  2021 src</span><br></pre></td></tr></table></figure>

<p>先下载个<code>maven:3.3.9-jdk-9</code>编译镜像试试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash">docker pull maven:3.3.9-jdk-9</span></span><br><span class="line">3.3.9-jdk-9: Pulling from library/maven</span><br><span class="line">...</span><br><span class="line">2ce3b259f3e2: Pull complete</span><br><span class="line">Digest: sha256:ad6b04c52e7f83c05e8840e0b1de0c39ba097c1e40efb294e740db303468cbe8</span><br><span class="line">Status: Downloaded newer image for maven:3.3.9-jdk-9</span><br><span class="line">docker.io/library/maven:3.3.9-jdk-9</span><br></pre></td></tr></table></figure>

<p>启动编译，先尝试编译原始版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash">docker run -it -v /home:/home docker.io/library/maven:3.3.9-jdk-9 bash</span></span><br><span class="line">root@aae0956cb558:/home# cd org.ops4j.pax.logging-logging-1.11.9</span><br><span class="line">root@aae0956cb558:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[WARNING] Error injecting: org.apache.maven.wagon.providers.http.HttpWagon</span><br><span class="line">java.lang.ExceptionInInitializerError</span><br><span class="line">        at java.base/javax.crypto.JceSecurityManager.&lt;clinit&gt;(JceSecurityManager.java:66)</span><br><span class="line">        at java.base/javax.crypto.Cipher.getConfiguredPermission(Cipher.java:2610)</span><br><span class="line">        at java.base/javax.crypto.Cipher.getMaxAllowedKeyLength(Cipher.java:2634)</span><br><span class="line">        ...</span><br><span class="line">Caused by: java.lang.SecurityException: Can not initialize cryptographic mechanism</span><br><span class="line">        at java.base/javax.crypto.JceSecurity.&lt;clinit&gt;(JceSecurity.java:118)</span><br><span class="line">        ... 96 more</span><br><span class="line">Caused by: java.lang.SecurityException: Can&#x27;t read cryptographic policy directory: unlimited</span><br><span class="line">        at java.base/javax.crypto.JceSecurity.setupJurisdictionPolicies(JceSecurity.java:324)</span><br><span class="line">        at java.base/javax.crypto.JceSecurity.access$000(JceSecurity.java:73)</span><br><span class="line">        at java.base/javax.crypto.JceSecurity$1.run(JceSecurity.java:109)</span><br><span class="line">        at java.base/javax.crypto.JceSecurity$1.run(JceSecurity.java:106)</span><br><span class="line">        at java.base/java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at java.base/javax.crypto.JceSecurity.&lt;clinit&gt;(JceSecurity.java:105)</span><br><span class="line">        ... 96 more</span><br></pre></td></tr></table></figure>

<p>参考资料[2]，问题出在编译镜像的<code>$JAVA_HOME/conf</code>命令下找不到一个安全相关的配置文件，查看一下发现<code>conf</code>文件夹都不存在，说明编译镜像有问题：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@aae0956cb558:/home/org.ops4j.pax.logging-logging-1.11.9# env</span><br><span class="line">JAVA_HOME=/usr/lib/jvm/java-9-openjdk-amd64</span><br><span class="line"></span><br><span class="line">root@aae0956cb558:/home/org.ops4j.pax.logging-logging-1.11.9# ls /usr/lib/jvm/java-9-openjdk-amd64</span><br><span class="line">bin  docs  include  jmods  legal  lib  man  src.zip</span><br><span class="line"></span><br><span class="line">//正常情况下$JAVA_HOME/conf目录下有以下文件</span><br><span class="line">java-9-openjdk  logging.properties  management  net.properties  security  sound.properties</span><br></pre></td></tr></table></figure>

<p>那就换个新版本试试，下载<code>maven:3.6-openjdk-11</code>编译镜像：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash">docker pull maven:3.6-openjdk-11</span></span><br><span class="line">3.6-openjdk-11: Pulling from library/maven</span><br><span class="line">...s</span><br><span class="line">Digest: sha256:1d29ccf46ef2a5e64f7de3d79a63f9bcffb4dc56be0ae3daed5ca5542b38aa2d</span><br><span class="line">Status: Downloaded newer image for maven:3.6-openjdk-11</span><br><span class="line">docker.io/library/maven:3.6-openjdk-11</span><br></pre></td></tr></table></figure>

<p>启动编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash">docker run -it -v /home:/home maven:3.6-openjdk-11 bash</span></span><br><span class="line">root@ff2407bc2d9e:/# cd /home/org.ops4j.pax.logging-logging-1.11.9</span><br><span class="line">root@ff2407bc2d9e:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">Downloading from knopflerfish: http://resources.knopflerfish.org/repo/maven2/release/org/ops4j/master/4.3.0/master-4.3.0.pom</span><br><span class="line">...</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ pax-logging-api-java9 ---</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (enforce-maven) @ pax-logging-api-java9 ---</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-toolchains-plugin:3.0.0:toolchain (default) @ pax-logging-api-java9 ---</span><br><span class="line">[INFO] Required toolchain: jdk [ version=&#x27;[9, )&#x27; ]</span><br><span class="line">[ERROR] No toolchain found for type jdk</span><br><span class="line">[ERROR] Cannot find matching toolchain definitions for the following toolchain types:</span><br><span class="line">jdk [ version=&#x27;[9, )&#x27; ]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary for OPS4J Pax Logging (Build POM) 1.11.9:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] OPS4J Pax Logging (Build POM) ...................... SUCCESS [ 35.399 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API (Java9) .................... FAILURE [ 10.045 s]</span><br><span class="line">...</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-toolchains-plugin:3.0.0:toolchain (default) on project pax-logging-api-java9: Cannot find matching toolchain definitions for the following toolchain types:</span><br><span class="line">[ERROR] jdk [ version=&#x27;[9, )&#x27; ]</span><br><span class="line">[ERROR] Please make sure you define the required toolchains in your ~/.m2/toolchains.xml file.</span><br></pre></td></tr></table></figure>

<p>第一个问题解决了，但从报错信息看，应该是要求<code>jdk9</code>的版本，那就再换一个<code>maven:3.5-jdk-9-slim</code>镜像：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash">docker pull maven:3.5-jdk-9-slim</span></span><br><span class="line">3.5-jdk-9-slim: Pulling from library/maven</span><br><span class="line">...</span><br><span class="line">7afb9733d3e4: Pull complete</span><br><span class="line">Digest: sha256:f5d85a2b5498c0a36a6515722e108969ff2fcfec5bef6c8ef83c8ebc4b671af1</span><br><span class="line">Status: Downloaded newer image for maven:3.5-jdk-9-slim</span><br><span class="line">docker.io/library/maven:3.5-jdk-9-slim</span><br></pre></td></tr></table></figure>

<p>继续编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@node]# </span><span class="language-bash">docker run -it -v /home:/home docker.io/library/maven:3.5-jdk-9-slim  bash</span></span><br><span class="line">root@895be557c3cd:/# cd /home/org.ops4j.pax.logging-logging-1.11.9</span><br><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">Downloading from knopflerfish: http://resources.knopflerfish.org/repo/maven2/release/org/ops4j/master/4.3.0/master-4.3.0.pom</span><br><span class="line">...</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ pax-logging-api-java9 ---</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (enforce-maven) @ pax-logging-api-java9 ---</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-toolchains-plugin:3.0.0:toolchain (default) @ pax-logging-api-java9 ---</span><br><span class="line">[INFO] Required toolchain: jdk [ version=&#x27;[9, )&#x27; ]</span><br><span class="line">[ERROR] No toolchain found for type jdk</span><br><span class="line">[ERROR] Cannot find matching toolchain definitions for the following toolchain types:</span><br><span class="line">jdk [ version=&#x27;[9, )&#x27; ]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] OPS4J Pax Logging (Build POM) 1.11.9 ............... SUCCESS [01:27 min]</span><br><span class="line">[INFO] OPS4J Pax Logging - API (Java9) .................... FAILURE [ 17.560 s]</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-toolchains-plugin:3.0.0:toolchain (default) on project pax-logging-api-java9: Cannot find matching toolchain definitions for the following toolchain types:</span><br><span class="line">[ERROR] jdk [ version=&#x27;[9, )&#x27; ]</span><br><span class="line">[ERROR] Please make sure you define the required toolchains in your ~/.m2/toolchains.xml file.</span><br></pre></td></tr></table></figure>

<p>当前编译镜像已经符合要求了，但依然报错，参考资料[3]，需要在<code>~/.m2/</code>目录下创建<code>toolchains.xml</code>文件并做相关配置：</p>
<p>通过<code>env</code>命令查看<code>java</code>的相关环境变量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# env</span><br><span class="line">...</span><br><span class="line">JAVA_HOME=/docker-java-home</span><br><span class="line">JAVA_VERSION=9.0.4+12</span><br><span class="line">JAVA_DEBIAN_VERSION=9.0.4+12-4</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>修改<code>version</code>和<code>jdkHome</code>字段：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# cat ~/.m2/toolchains.xml</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;toolchains xmlns=&quot;http://maven.apache.org/TOOLCHAINS/1.1.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">  xsi:schemaLocation=&quot;http://maven.apache.org/TOOLCHAINS/1.1.0 http://maven.apache.org/xsd/toolchains-1.1.0.xsd&quot;&gt;</span><br><span class="line">  &lt;toolchain&gt;</span><br><span class="line">    &lt;type&gt;jdk&lt;/type&gt;</span><br><span class="line">    &lt;provides&gt;</span><br><span class="line">      &lt;version&gt;9&lt;/version&gt;</span><br><span class="line">      &lt;vendor&gt;oracle&lt;/vendor&gt;</span><br><span class="line">    &lt;/provides&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">      &lt;jdkHome&gt;/docker-java-home&lt;/jdkHome&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">  &lt;/toolchain&gt;</span><br><span class="line">&lt;/toolchains&gt;</span><br></pre></td></tr></table></figure>

<p>继续编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] Inspecting build with total of 19 modules...</span><br><span class="line">[INFO] Installing Nexus Staging features:</span><br><span class="line">[INFO]   ... total of 19 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] OPS4J Pax Logging (Build POM) 1.11.9 ............... SUCCESS [  0.335 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API (Java9) .................... SUCCESS [ 40.867 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API ............................ SUCCESS [ 51.690 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API tests ...................... FAILURE [02:11 min]</span><br></pre></td></tr></table></figure>

<p>失败在<code>test</code>模块，测试模块不影响，修改<code>pom.xml</code>注释掉即可；</p>
<p>再编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">...</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] OPS4J Pax Logging (Build POM) 1.11.9 ............... SUCCESS [  0.275 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API (Java9) .................... SUCCESS [  1.873 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API ............................ SUCCESS [  4.672 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4Jv1 implementation ......... SUCCESS [ 39.435 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4Jv2 implementation ......... SUCCESS [  8.208 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4j v2 Extra packages ........ SUCCESS [  0.131 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Logback implementation ......... SUCCESS [ 15.241 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Integration Tests .............. SUCCESS [01:48 min]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf .......................... SUCCESS [  0.014 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf KAR Logger ............... SUCCESS [  0.148 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf KAR ...................... SUCCESS [ 28.098 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf Distribution ............. SUCCESS [  2.002 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf Integration Tests 1.11.9 . SUCCESS [ 36.557 s]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 04:07 min</span><br><span class="line">[INFO] Finished at: 2021-12-21T09:45:18Z</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>不容易，终于成功了！开始修改<code>pod.xml</code>，把依赖的<code>log4j</code>包升级上去：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- &lt;version.org.apache.logging.log4j&gt;2.14.0&lt;/version.org.apache.logging.log4j&gt;</span><br><span class="line">+ &lt;version.org.apache.logging.log4j&gt;2.17.0&lt;/version.org.apache.logging.log4j&gt;</span><br></pre></td></tr></table></figure>

<p>编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] Inspecting build with total of 13 modules...</span><br><span class="line">[INFO] Installing Nexus Staging features:</span><br><span class="line">[INFO]   ... total of 13 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">...</span><br><span class="line">[ERROR] COMPILATION ERROR :</span><br><span class="line">[INFO] -------------------------------------------------------------</span><br><span class="line">[ERROR] /home/org.ops4j.pax.logging-logging-1.11.9/pax-logging-log4j2/src/main/java/org/apache/logging/log4j/core/impl/ThrowableProxy.java:[85,54] cannot find symbol</span><br><span class="line">  symbol:   variable EMPTY_THROWABLE_PROXY_ARRAY</span><br><span class="line">  location: class org.apache.logging.log4j.core.impl.ThrowableProxyHelper</span><br><span class="line">[INFO] 1 error</span><br><span class="line">[INFO] -------------------------------------------------------------</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] OPS4J Pax Logging (Build POM) 1.11.9 ............... SUCCESS [  0.302 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API (Java9) .................... SUCCESS [  1.836 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API ............................ SUCCESS [ 10.592 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4Jv1 implementation ......... SUCCESS [  2.017 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4Jv2 implementation ......... FAILURE [  4.279 s]</span><br></pre></td></tr></table></figure>

<p>又报错了，找到官方升级过<code>log4j</code>的版本，发现<code>ThrowableProxy</code>方法的构造方法里<code>suppressedProxies</code>字段的赋值有变化，老版本是<code>ThrowableProxyHelper.EMPTY_THROWABLE_PROXY_ARRAY</code>，而新版本变成了<code>ThrowableProxy.EMPTY_ARRAY</code>。问题不大，改一下就行；</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">src/main/java/org/apache/logging/log4j/core/impl/ThrowableProxy.java</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThrowableProxy</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> ThrowableProxy[] EMPTY_ARRAY = &#123;&#125;;</span><br><span class="line">	ThrowableProxy() &#123;</span><br><span class="line">        <span class="built_in">this</span>.throwable = <span class="literal">null</span>;</span><br><span class="line">        <span class="built_in">this</span>.name = <span class="literal">null</span>;</span><br><span class="line">        <span class="built_in">this</span>.extendedStackTrace = ExtendedStackTraceElement.EMPTY_ARRAY;</span><br><span class="line">        <span class="built_in">this</span>.causeProxy = <span class="literal">null</span>;</span><br><span class="line">        <span class="built_in">this</span>.message = <span class="literal">null</span>;</span><br><span class="line">        <span class="built_in">this</span>.localizedMessage = <span class="literal">null</span>;</span><br><span class="line">        <span class="built_in">this</span>.suppressedProxies = ThrowableProxy.EMPTY_ARRAY;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>再次编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">root@895be557c3cd:/home/org.ops4j.pax.logging-logging-1.11.9# mvn clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] Inspecting build with total of 13 modules...</span><br><span class="line">[INFO] Installing Nexus Staging features:</span><br><span class="line">[INFO]   ... total of 13 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] OPS4J Pax Logging (Build POM) 1.11.9 ............... SUCCESS [  0.290 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API (Java9) .................... SUCCESS [  1.819 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - API ............................ SUCCESS [  4.717 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4Jv1 implementation ......... SUCCESS [  2.057 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4Jv2 implementation ......... SUCCESS [  2.654 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Log4j v2 Extra packages ........ SUCCESS [  0.144 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Logback implementation ......... SUCCESS [  0.908 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Integration Tests .............. SUCCESS [  4.402 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf .......................... SUCCESS [  0.012 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf KAR Logger ............... SUCCESS [  0.138 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf KAR ...................... SUCCESS [  1.588 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf Distribution ............. SUCCESS [  2.114 s]</span><br><span class="line">[INFO] OPS4J Pax Logging - Karaf Integration Tests 1.11.9 . SUCCESS [  0.163 s]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 23.440 s</span><br><span class="line">[INFO] Finished at: 2021-12-21T09:51:37Z</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>升级<code>log4j</code>的版本编译成功。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>把新编译的<code>pax-logging-api</code>和<code>pax-logging-log4j</code>替换到依赖仓库中，重新编译交付件，验证漏洞解决，日志功能正常。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/ops4j/org.ops4j.pax.logging">https://github.com/ops4j/org.ops4j.pax.logging</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/docker-library/openjdk/issues/101">https://github.com/docker-library/openjdk/issues/101</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/yiqiu3812/article/details/103298980">https://blog.csdn.net/yiqiu3812/article/details/103298980</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2021/12/18/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E6%8C%82%E8%BD%BDSubpath%E7%9A%84%E5%AE%B9%E5%99%A8%E5%9C%A8Configmap%E5%8F%98%E6%9B%B4%E5%90%8E%E9%87%8D%E5%90%AF%E6%97%B6%E6%8C%82%E8%BD%BD%E5%A4%B1%E8%B4%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/18/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E6%8C%82%E8%BD%BDSubpath%E7%9A%84%E5%AE%B9%E5%99%A8%E5%9C%A8Configmap%E5%8F%98%E6%9B%B4%E5%90%8E%E9%87%8D%E5%90%AF%E6%97%B6%E6%8C%82%E8%BD%BD%E5%A4%B1%E8%B4%A5/" class="post-title-link" itemprop="url">K8S问题排查-挂载Subpath的容器在Configmap变更后重启时挂载失败</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-18 14:43:43" itemprop="dateCreated datePublished" datetime="2021-12-18T14:43:43+00:00">2021-12-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本次发现的问题是踩到了老版本<code>Kubernetes</code>的坑，查找资料发现<code>fatedier</code>大佬已经做了很棒的分析，此处转载过来仅做学习记录。</p>
<blockquote>
<p>作者：<a target="_blank" rel="noopener" href="http://blog.fatedier.com/">fatedier</a><br>本文出处：<a target="_blank" rel="noopener" href="https://blog.fatedier.com/2020/04/17/pod-loopcrash-of-k8s-subpath/">https://blog.fatedier.com/2020/04/17/pod-loopcrash-of-k8s-subpath/</a><br>文章版权归本人所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。</p>
</blockquote>
<h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p><code>Kubernetes</code>对于挂载了 <code>subpath</code> 的容器，在<code> configmap</code> 或其他 <code>volume</code> 变更后，如果容器因为意外退出后，就会持续<code>crash</code>，无法正常启动。</p>
<p>社区相关 issue <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues/68211">#68211</a>，问题已经在<code>v1.19</code>版本解决。</p>
<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><h3 id="复现步骤"><a href="#复现步骤" class="headerlink" title="复现步骤"></a>复现步骤</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span> </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">configMap:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">extra-cfg</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">extra-cfg</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ubuntu:bionic</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;sleep&quot;</span>, <span class="string">&quot;30&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">extra-cfg</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/etc/extra.ini</span></span><br><span class="line">        <span class="attr">subPath:</span> <span class="string">extra.ini</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">extra.ini:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    somedata</span></span><br><span class="line"><span class="string"></span><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">extra-cfg</span></span><br></pre></td></tr></table></figure>

<p><code>Apply</code> 此配置，<code>Pod</code> 启动完成后，修改 <code>configmap </code>的内容，等待 <code>30</code> 秒后容器自动退出，<code>kubelet</code> 重启容器，此时观察到容器持续 <code>mount</code> 失败。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: failed to start container &quot;test&quot;: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused &quot;process_linux.go:424: container init caused \&quot;rootfs_linux.go:58: mounting \\\&quot;/var/lib/kubelet/pods/e044883a-48da-4d28-b304-1a57dcb32203/volume-subpaths/extra-cfg/test/0\\\&quot; to rootfs \\\&quot;/var/lib/docker/overlay2/31b076d0012aad47aa938b482de24ecda8b41505489a22f63b8a3e4ce39b43ba/merged\\\&quot; at \\\&quot;/var/lib/docker/overlay2/31b076d0012aad47aa938b482de24ecda8b41505489a22f63b8a3e4ce39b43ba/merged/etc/extra.ini\\\&quot; caused \\\&quot;no such file or directory\\\&quot;\&quot;&quot;: unknown</span><br></pre></td></tr></table></figure>

<h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><h4 id="Configmap-Volume-的更新"><a href="#Configmap-Volume-的更新" class="headerlink" title="Configmap Volume 的更新"></a>Configmap Volume 的更新</h4><p>当容器第一次启动前，<code>kubelet</code> 先将 <code>configmap</code> 中的内容下载到 <code>Pod</code> 对应的 <code>Volume</code> 目录下，例如 <code>/var/lib/kubelet/pods/&#123;Pod UID&#125;/volumes/kubernetes.io~configmap/extra-cfg</code>。</p>
<p>同时为了保证对此 <code>volume</code> 下内容的更新是原子的(更新目录时)，所以会通过软链接的方式进行更新，目录中文件如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">drwxrwxrwx 3 root root 4.0K Mar 29 03:12 .</span><br><span class="line">drwxr-xr-x 3 root root 4.0K Mar 29 03:12 ..</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Mar 29 03:12 ..2020_03_29_03_12_44.788930127</span><br><span class="line">lrwxrwxrwx 1 root root   31 Mar 29 03:12 ..data -&gt; ..2020_03_29_03_12_44.788930127</span><br><span class="line">lrwxrwxrwx 1 root root   16 Mar 29 03:12 extra.ini -&gt; ..data/extra.ini</span><br></pre></td></tr></table></figure>

<p><code>extra.ini</code> 是 <code>..data/extra.ini</code> 的软链，<code>..data</code> 是 <code>..2020_03_29_03_12_44.788930127</code> 的软链，命名为时间戳的目录存放真实内容。</p>
<p>当 <code>configmap</code> 更新后，会生成新的时间戳的目录存放更新后的内容。</p>
<p>创建新的软链 <code>..data_tmp</code> 指向新的时间戳目录，之后重命名为 <code>..data</code>，重命名是一个原子操作。</p>
<p>最后删除旧的时间戳目录。</p>
<h4 id="容器挂载-subpath-Volume-的准备"><a href="#容器挂载-subpath-Volume-的准备" class="headerlink" title="容器挂载 subpath Volume 的准备"></a>容器挂载 subpath Volume 的准备</h4><p>当 <code>configmap Volume</code> 准备完成后，<code>kubelet</code> 会将 <code>configmap</code> 中 <code>subpath</code> 指定的文件 <code>bind mount</code> 到一个特殊的目录下: <code>/var/lib/kubelet/pods/&#123;Pod UID&#125;/volume-subpaths/extra-cfg/&#123;container name&#125;/0</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/self/mountinfo|grep extra</span><br><span class="line">2644 219 8:1 /var/lib/kubelet/pods/&#123;Pod UID&#125;/volumes/kubernetes.io~configmap/extra-cfg/..2020_03_29_03_12_13.444136014/extra.ini /var/lib/kubelet/pods/&#123;Pod UID&#125;/volume-subpaths/extra-cfg/test/0 rw,relatime shared:99 - ext4 /dev/sda1 rw,data=ordered</span><br></pre></td></tr></table></figure>

<p>可以看出，<code>bind mount</code> 的文件其实是真实文件的时间戳目录下的内容。</p>
<p>当 <code>Configmap</code> 更新后，此时间戳目录会被删除，源文件加上了 <code>//deleted</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/self/mountinfo|grep extra</span><br><span class="line">2644 219 8:1 /var/lib/kubelet/pods/&#123;Pod UID&#125;/volumes/kubernetes.io~configmap/extra-cfg/..2020_03_29_03_12_13.444136014/extra.ini//deleted /var/lib/kubelet/pods/&#123;Pod UID&#125;/volume-subpaths/extra-cfg/test/0 rw,relatime shared:99 - ext4 /dev/sda1 rw,data=ordered</span><br></pre></td></tr></table></figure>

<h4 id="Bind-Mount"><a href="#Bind-Mount" class="headerlink" title="Bind Mount"></a>Bind Mount</h4><p>当容器启动时，需要将 <code>/var/lib/kubelet/pods/&#123;Pod UID&#125;/volume-subpaths/extra-cfg/test/0</code> 挂载到容器中。</p>
<p>如果原来的时间戳目录被删除，则 <code>mount</code> 会出错: <code>mount: mount(2) failed: No such file or directory</code>。</p>
<p>通过简单的命令模拟这个问题:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">touch</span> a b c</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mount --<span class="built_in">bind</span> a b</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">rm</span> -f a</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mount --<span class="built_in">bind</span> b c</span></span><br><span class="line">mount: mount(2) failed: No such file or directory</span><br></pre></td></tr></table></figure>

<p>可以看到，当 <code>a</code> 删除后，<code>b</code> 挂载点无法再被 <code>mount</code>。所以，当容器异常退出需要重启后，如果 <code>configmap</code> 被更新，原先的时间戳文件被删除，这个 <code>subpath</code> 就无法再被 <code>mount</code> 到容器中。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="Configmap-变更后-Unmount"><a href="#Configmap-变更后-Unmount" class="headerlink" title="Configmap 变更后 Unmount"></a>Configmap 变更后 Unmount</h4><p>社区相关 PR: <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/82784">https://github.com/kubernetes/kubernetes/pull/82784</a></p>
<p>在容器重启前，检查 <code>subpath</code> 挂载点的源文件和新的目标 <code>subpath</code> 文件是否一致。</p>
<p>当 <code>configmap</code> 被更新后，时间戳目录变更，则检查到不一致。将 <code>/var/lib/kubelet/pods/&#123;Pod UID&#125;/volume-subpaths/extra-cfg/test/0</code> <code>Unmount</code>，再重新 <code>Bind Mount</code> 当前最新的时间戳目录下的对应文件。</p>
<p>根据社区 <code>PR</code> 中的 <code>comments</code> 来看，此方案可能存在一定风险，尚不明确(有人指出在 4.18 以下内核是不安全的 <a target="_blank" rel="noopener" href="https://github.com/es-container/kubernetes/pull/24/files#diff-f0ba2b2ac6f7b574258c97a4001460b2R829">链接</a>)，所以很长时间都没有进展。</p>
<p>通过一段时间的测试，尚未发现明显的问题。</p>
<h4 id="不使用-subpath"><a href="#不使用-subpath" class="headerlink" title="不使用 subpath"></a>不使用 subpath</h4><p>使用其他方式绕过这个问题。</p>
<p>例如可以将 <code>Configmap</code> 整个 <code>Mount</code> 到容器的其他目录下，再在容器启动时通过软链的方式链接到对应的路径下。</p>
<h3 id="为什么使用间接-Bind-Mount-而不是直接-Mount-软链接"><a href="#为什么使用间接-Bind-Mount-而不是直接-Mount-软链接" class="headerlink" title="为什么使用间接 Bind Mount 而不是直接 Mount 软链接"></a>为什么使用间接 Bind Mount 而不是直接 Mount 软链接</h3><p>参考 <a target="_blank" rel="noopener" href="https://kubernetes.io/blog/2018/04/04/fixing-subpath-volume-vulnerability/">https://kubernetes.io/blog/2018/04/04/fixing-subpath-volume-vulnerability/</a> 这篇文章。</p>
<p>可以看出原先使用的就是直接 <code>Mount</code> 软链接的方式，但是存在安全漏洞，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Symlink_race">symlink race</a> 。恶意程序可以通过构造一个软链接，使特权程序(<code>kubelet</code>) 将超出权限范围之外的文件内容挂载到用户容器中。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">my-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prep-symlink</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&quot;busybox&quot;</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>, <span class="string">&quot;-ec&quot;</span>, <span class="string">&quot;ln -s / /mnt/data/symlink-door&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/mnt/data</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&quot;busybox&quot;</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-ec&quot;</span>, <span class="string">&quot;ls /mnt/data; sleep 999999&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/mnt/data</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">my-volume</span></span><br><span class="line">      <span class="attr">subPath:</span> <span class="string">symlink-door</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-volume</span></span><br><span class="line">  <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>使用如上的配置，通过 <code>emptyDir</code>，在 <code>initContainer</code> 中在挂载的 <code>Volume</code> 目录中创建了一个指向根目录的软链接。</p>
<p>之后正常的容器启动，但是指定了 <code>subpath</code>，如果 <code>kubelet</code> 直接 <code>Mount</code> 软链接，会将宿主机的根目录 <code>Mount</code> 到用户容器中。</p>
<p>为了解决这个问题，需要解析出软链接对应的真实文件路径，并且判断此路径是否是在 <code>Volume</code> 目录下，校验通过后才能挂载到容器中。但是由于校验和挂载之间存在时间差，此文件还是有可能会被篡改。</p>
<p>社区讨论后，通过引入中间 <code>Bind Mount</code> 的机制，相当于给这个文件加锁，将原文件的路径固化，之后再 <code>Mount</code> 到容器中时，只会 <code>Mount</code> 当时创建挂载点时的源文件。</p>
<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>给社区提交的修复 <code>PR</code> 已经被合入 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/89629">89629</a> 。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2021/10/24/share/%E6%80%BB%E7%BB%93%E5%88%86%E4%BA%AB-Wireshark%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/24/share/%E6%80%BB%E7%BB%93%E5%88%86%E4%BA%AB-Wireshark%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">总结分享-Wireshark常用命令总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-24 21:43:43" itemprop="dateCreated datePublished" datetime="2021-10-24T21:43:43+00:00">2021-10-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/share/" itemprop="url" rel="index"><span itemprop="name">share</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="功能总结"><a href="#功能总结" class="headerlink" title="功能总结"></a>功能总结</h2><h3 id="导出数据包"><a href="#导出数据包" class="headerlink" title="导出数据包"></a>导出数据包</h3><p>方法：File | Export Packet Dissections | as”CSV”(Comma Separated Values packet summary)file…</p>
<blockquote>
<ol>
<li>导出格式有纯文本、CSV、XML、JSON等；</li>
<li>不仅可以输出选中列，还可以<strong>输出当前页面展示的列</strong>，以及所有列（在导出弹框中设置）；</li>
<li>可以设置包格式，比如导出统计行、统计头、包详细数据等；</li>
</ol>
</blockquote>
<h3 id="添加展示列"><a href="#添加展示列" class="headerlink" title="添加展示列"></a><strong>添加展示列</strong></h3><p>方法：Package Details 面板中展开包详情，找到指定字段右键单击并选择Apply as Column 选项</p>
<h3 id="显示一个TCP-UDP-会话"><a href="#显示一个TCP-UDP-会话" class="headerlink" title="显示一个TCP&#x2F;UDP 会话"></a>显示一个TCP&#x2F;UDP 会话</h3><p>方法1：选中一个包，右键选择Conversation Filter|[TCPIUDP]命令</p>
<p>方法2：选中一个包，右键选择Follow[TCPIUDP] Stream 命令</p>
<p>方法3：工具栏选择Statistics|Conversations命令</p>
<p>方法4：在TCP 头部，通过右键单击stream index 字段并选择Apply as Filter 命令</p>
<h2 id="命令总结"><a href="#命令总结" class="headerlink" title="命令总结"></a>命令总结</h2><h3 id="捕获过滤命令"><a href="#捕获过滤命令" class="headerlink" title="捕获过滤命令"></a>捕获过滤命令</h3><p>捕获过滤器仅支持协议过滤。</p>
<h4 id="1-主机相关过滤命令"><a href="#1-主机相关过滤命令" class="headerlink" title="1. 主机相关过滤命令*"></a>1. 主机相关过滤命令*</h4><ul>
<li>host 10.3.1.1: 捕获到达&#x2F;来自10.3.1.1主机的数据（支持IPv6地址）。</li>
<li>not host 10.3.1.1: 捕获除了到达&#x2F;来自10.3.1.1主机的所有数据。</li>
<li>src host 10.3.1.1: 捕获来自10.3.1.1 主机上的数据。</li>
<li>dst host 10.3.1.1: 捕获到达10.3.1.1 主机上的数据。</li>
<li>host 10.3.1.1 or host 10.3.1.2: 捕获到达&#x2F;来自10.3.1.1主机上的数据，和到达&#x2F;来自10.3.1.2 主机的数据。</li>
</ul>
<h4 id="2-端口相关过滤命令"><a href="#2-端口相关过滤命令" class="headerlink" title="2. 端口相关过滤命令*"></a>2. 端口相关过滤命令*</h4><ul>
<li>port 53: 捕获到达&#x2F;来自端口号为53的UDP&#x2F;TCP 数据（典型的DNS 数据）。</li>
<li>not port 53 : 捕获除到达&#x2F;来自端口号为53的所有UDP&#x2F;TCP 数据。</li>
<li>port 80: 捕获到达&#x2F;来自端口号为80的UDP&#x2F;TCP 数据（典型的HTTP 数据）。</li>
<li>udp port 67 : 捕获到达&#x2F;来自端口号为67的UDP 数据（典型的DHCP 数据）。</li>
<li>tcp port 21: 捕获到达&#x2F;来自端口号为21的TCP 数据（典型的FTP 数据）。</li>
<li>portrange 1-80: 捕获到达&#x2F;来自1~80端口号的UDP&#x2F;TCP 数据。</li>
<li>tcp portrange 1-80: 捕获到达&#x2F;来自1~80端口号的TCP 数据。</li>
</ul>
<h4 id="3-主机和端口混合过滤命令"><a href="#3-主机和端口混合过滤命令" class="headerlink" title="3. 主机和端口混合过滤命令*"></a>3. 主机和端口混合过滤命令*</h4><ul>
<li>port 20 or port 21 :捕获到达&#x2F;来自20 或21 端口号的所有UDP&#x2F;TCP 数据。</li>
<li>host 10.3.1.1 and port 80: 捕获到达&#x2F;来自端口号为80, 并且是到达&#x2F;来自10.3.1.1主机的UDP&#x2F;TCP 数据。</li>
<li>host 10.3.1.1 and not port 80: 捕获到I来自10.3.1.1 主机，并且是非80 端口的UDP&#x2F;TCP 数据。</li>
<li>udp src port 68 and udp dst port 67: 捕获来自端口为68, 目标端口号为67 的所有UDP 数据（典型的DHCP 客户端到DHCP 服务器的数据） 。</li>
<li>udp src port 67 and udp dst port 68: 捕获来自端口号为67, 目标端口号为68 的所有UDP 数据（典型的DHCP 服务器到DHCP 客户端的数据）。</li>
</ul>
<h4 id="4-IP地址范围过滤命令"><a href="#4-IP地址范围过滤命令" class="headerlink" title="4. IP地址范围过滤命令"></a>4. IP地址范围过滤命令</h4><ul>
<li>net 192.168.0.0&#x2F;24：捕获到达&#x2F;来自192.168.0.0网络中任何主机的数据。</li>
<li>net 192.168.0.0 mask 255.255.255.0: 捕获到达&#x2F;来自192.168.0.0网络中任何主机的<br>数据。</li>
<li>ip6 net 2406:daOO:ff00::&#x2F;64: 捕获到达&#x2F;来自2406:daOO:ffDO:OOOO ( IPv6) 网络中任<br>何主机的数据。</li>
<li>not dst net 192.168.0.0&#x2F;24: 捕获除目的IP地址是192.168.0.0网络外的所有数据。</li>
<li>dst net 192.168.0.0&#x2F;24：捕获到达IP地址为192.168.0.0网络内的所有数据。</li>
<li>src net 192.168.0.0&#x2F;24: 捕获来自IP地址为192.168.0.0网络内的所有数据。</li>
</ul>
<h4 id="5-广播或多播地址过滤命令"><a href="#5-广播或多播地址过滤命令" class="headerlink" title="5. 广播或多播地址过滤命令"></a>5. 广播或多播地址过滤命令</h4><ul>
<li>ip broadcast: 捕获到255.255.255.255 的数据。</li>
<li>ip multicast: 捕获通过224.0.0.0~239.255.255.255的数据。</li>
<li>dst host ff02::1: 捕获所有主机到IPv6多播地址的数据。</li>
<li>dst host ff02::2: 捕获所有路由到IPv6多播地址的数据。（<em>跟上一个有什么区别？</em>）</li>
</ul>
<h4 id="6-MAC地址过滤命令"><a href="#6-MAC地址过滤命令" class="headerlink" title="6. MAC地址过滤命令"></a>6. MAC地址过滤命令</h4><ul>
<li>ether host 00:08:15:00:08:15: 捕获到达&#x2F;来自00:08:15:00:08:15主机的数据。</li>
<li>ether src 02:0A:42:23:41:AC: 捕获来自02:0A:42:23:41:AC 主机的数据。</li>
<li>ether dst 02:0A:42:23:41:AC: 捕获到达02:0A:42:23:41:AC 主机的数据。</li>
<li>not ether host 00:08:15:00:08:15:捕获到达&#x2F;来自除了00:08:15:00:08:15的任何MAC<br>地址的流量。</li>
</ul>
<h4 id="7-特定ICMP协议过滤命令"><a href="#7-特定ICMP协议过滤命令" class="headerlink" title="7. 特定ICMP协议过滤命令"></a>7. 特定ICMP协议过滤命令</h4><ul>
<li>icmp：捕获所有ICMP 数据包。</li>
<li>icmp[0]&#x3D;8 : 捕获所有ICMP 字段类型为8 (Echo Request) 的数据包。</li>
<li>icmp[0]&#x3D;17: 捕获所有ICMP 字段类型为17 (Address Mask Request) 的数据包。</li>
<li>icmp[0]&#x3D;8 or icmp[0]&#x3D;0: 捕获所有ICMP 字段类型为8 (Echo Request) 或ICMP<br>字段类型为0 (Echo Reply) 的数据包。</li>
<li>icmp[0]&#x3D;3 and not icmp[1]&#x3D;4 ：捕获所有ICMP 字段类型为3 (Destination<br>Unreachable) 的包，除了ICMP 字段类型为3&#x2F;代码为4 (Fragmentation Needed and<br>Don’t Fragment was Set) 的数据包。</li>
</ul>
<h3 id="显示过滤命令"><a href="#显示过滤命令" class="headerlink" title="显示过滤命令"></a>显示过滤命令</h3><p>显示过滤器可以帮助用户在捕捉结果中进行数据查找。该过滤器可以在得到的捕捉结果中修改，以显示有用数据。</p>
<p>既支持协议过滤也支持内容过滤。</p>
<h4 id="1-通用语法格式"><a href="#1-通用语法格式" class="headerlink" title="1. 通用语法格式"></a>1. 通用语法格式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Protocol | [String1] [String2] | Comparison-Operator | Value | Logical-Operations | Other-expression</span><br><span class="line">协议（2~7层）      协议子类               比较运算符         比较值       逻辑运算符             其他表达式</span><br></pre></td></tr></table></figure>

<p>其中比较运算符有如下6个：</p>
<table>
<thead>
<tr>
<th>英文写法</th>
<th>C 语言写法</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>eq</td>
<td>&#x3D;&#x3D;</td>
<td>等于</td>
</tr>
<tr>
<td>ne</td>
<td>!&#x3D;</td>
<td>不等于</td>
</tr>
<tr>
<td>gt</td>
<td>&gt;</td>
<td>大于</td>
</tr>
<tr>
<td>lt</td>
<td>&lt;</td>
<td>小于</td>
</tr>
<tr>
<td>ge</td>
<td>&gt;&#x3D;</td>
<td>大于等于</td>
</tr>
<tr>
<td>le</td>
<td>&lt;&#x3D;</td>
<td>小于等于</td>
</tr>
<tr>
<td>contains</td>
<td>-</td>
<td>包含</td>
</tr>
<tr>
<td>matches</td>
<td>-</td>
<td>匹配</td>
</tr>
</tbody></table>
<p>逻辑运算符有如下4个：</p>
<table>
<thead>
<tr>
<th>英文写法</th>
<th>C 语言写法</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>and</td>
<td>&amp;&amp;</td>
<td>逻辑与</td>
</tr>
<tr>
<td>or</td>
<td>||</td>
<td>逻辑或</td>
</tr>
<tr>
<td>xor</td>
<td>^^</td>
<td>逻辑异或</td>
</tr>
<tr>
<td>not</td>
<td>!</td>
<td>逻辑非</td>
</tr>
</tbody></table>
<h4 id="2-协议过滤命令"><a href="#2-协议过滤命令" class="headerlink" title="2. 协议过滤命令*"></a>2. 协议过滤命令*</h4><ul>
<li>arp: 显示所有ARP 流量，包括免费ARP 、ARP 请求和ARP 应答。</li>
<li>ip(v6): 显示所有IPv4&#x2F;IPv6 流量，包括有IPv4(IPv6) 头部嵌入式的包（如ICMP 目标不可达的数据包，返回到ICMP 头后进入到IPv4 头部）。<ul>
<li>ip(v6).src</li>
<li>ip(v6).dst</li>
<li>ip(v6).host</li>
<li>ip(v6).addr</li>
</ul>
</li>
<li>tcp: 显示所有基于TCP 的流量数据。</li>
</ul>
<h4 id="3-应用过滤命令"><a href="#3-应用过滤命令" class="headerlink" title="3. 应用过滤命令*"></a>3. 应用过滤命令*</h4><ul>
<li>bootp: 显示所有DHCP 流量（ipv4下基于BOOTP，ipv6下不是基于BOOTP，过滤时使用dhcpv6) 。</li>
<li>dns: 显示所有DNS 流量，包括基于TCP 传输和UDP 的DNS 请求和响应。</li>
<li>tftp: 显示所有TFTP （简单文件传输协议）流量。</li>
<li>http: 显示所有HTTP 命令、响应和数据传输包。但是不显示TCP 握手包、TCP确认包或TCP 断开连接的包。</li>
<li>http contains “GET”: 显示HTTP 客户端发送给HTTP 服务器的所有GET 请求数据。</li>
<li>icmp: 显示所有ICMP 流量。</li>
</ul>
<h4 id="4-字段存在过滤命令"><a href="#4-字段存在过滤命令" class="headerlink" title="4. 字段存在过滤命令"></a>4. 字段存在过滤命令</h4><ul>
<li>bootp.option.hostname: 显示所有DHCP 流量，包含主机名( DHCP 是基于BOOTP) 。</li>
<li>http.host: 显示所有包含有HTTP 主机名字段的HTTP 包。该包通常是由客户端发送给一个Web 服务器的请求。</li>
<li>ftp.request.command: 显示所有FTP 命令数据，如USER 、PASS 或RETR 命令。</li>
<li>ftp.request.arg matches “admin”: 显示匹配admin 字符串的数据。</li>
<li>tcp.analysis.flags: 显示所有与TCP 标识相关的包，包括丢包、重发或者零窗口标志。</li>
<li>tcp.analysis.zero_window: 显示被标志的包，来表示发送方的缓冲空间已满。</li>
</ul>
<h4 id="5-逻辑运算过滤命令"><a href="#5-逻辑运算过滤命令" class="headerlink" title="5. 逻辑运算过滤命令"></a>5. 逻辑运算过滤命令</h4><ul>
<li>&amp;＆或and: ip.src&#x3D;l0.2.2.2 &amp;&amp; tcp.port&#x3D;80，表示显示源地址10.2.2.2 主机，并且端口号为80 的所有IPv4 流量。</li>
<li>||或or: tcp.port&#x3D;80 || tcp.port&#x3D;43，表示显示到达&#x2F;来自80 或443 端口的所有TCP数据。</li>
<li>！或not: !arp，表示查看除ARP 外的所有数据。</li>
<li>!＝或ne: tcp.flags.syn !&#x3D; 1，表示查看TCP SYN 标志位不是1 的TCP 数据帧。</li>
</ul>
<blockquote>
<p>注：</p>
<p>ip.addr !&#x3D; 10.2.2.2  表示显示IP 源或目标地址字段非10.2.2.2 的数据包。如果一个包的源或目标IP 地址字段中不包含10.2.2.2, 则显示该数据包。在该语法中使用了一个隐含或，并且不会过滤掉任何数据包。</p>
<p>!ip.addr &#x3D;&#x3D; 10.2.2.2 表示显示在IP 源和目标地址字段不包含10.2.2.2 的数据包。当排除到达&#x2F;来自一个特定IP 地址的数据时，这是一个合适的过滤器语法。</p>
<p>!tcp.flags.syn&#x3D;&#x3D;l 表示显示TCP SYN 标志位不等于1的所有TCP 包和其他协议包，如UDP 、ARP数据包将匹配该过滤器。因为UDP 和ARP 协议中没有TCP SYN 标志位为1 的数据包。</p>
<p>tcp.flags.syn !&#x3D; 1 表示仅显示包括SYN 设置为0 的TCP 包。</p>
</blockquote>
<h4 id="6-时间过滤命令"><a href="#6-时间过滤命令" class="headerlink" title="6. 时间过滤命令"></a>6. 时间过滤命令</h4><ul>
<li>frame.time_delta &gt; 1，表示时间延迟超过1 秒的数据，显示捕获文件中所有包的时间。</li>
<li>tcp.time_delta &gt; 1，表示TCP 时间差大于1 秒的数据。</li>
</ul>
<blockquote>
<p>注：上述命令主要用于判断各种网络延迟。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2021/09/26/linux/%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-IPv6%E7%8E%AF%E5%A2%83%E4%B8%8BVIP%E5%9C%B0%E5%9D%80%E4%B8%8D%E9%80%9A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/26/linux/%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-IPv6%E7%8E%AF%E5%A2%83%E4%B8%8BVIP%E5%9C%B0%E5%9D%80%E4%B8%8D%E9%80%9A/" class="post-title-link" itemprop="url">网络问题排查-IPv6环境下VIP地址不通</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-26 09:15:21" itemprop="dateCreated datePublished" datetime="2021-09-26T09:15:21+00:00">2021-09-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>IPv6环境下，在浏览器中通过<code>http://[vip:port]</code>访问<code>web</code>业务，提示无法访问此网站，<code>[vip]</code>的响应时间过长。</p>
<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>之前碰到过多次在PC浏览器上无法访问<code>vip</code>的情况，排查方法也很明确：</p>
<ol>
<li>在集群的<code>vip</code>所在节点上访问是否正常；</li>
<li>在集群范围内其他节点上访问是否正常；</li>
<li>在集群之外的同网段<code>linux</code>环境上访问是否正常；</li>
<li>在其他环境的PC浏览器上访问是否正常；</li>
</ol>
<p>验证发现，直接在<code>vip</code>所在节点上访问竟然不通！登录<code>vip</code>所在节点执行<code>ip addr</code>可以看到该地址确实是正确配置了，但 <code>ping6</code>该地址无回应，对应的<code>ipv4</code>地址 <code>ping</code>有回应。按说<code>ping</code>本机的地址不应该和链路的状态有关系，那会是什么原因呢？在仔细检查地址配置情况后发现该地址有个标记<code>tentative dadfailed </code>；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">17: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 0c:da:41:1d:a8:62 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.10.10.17/16 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 2000::10:18/128 scope global tentative dadfailed</span><br><span class="line">       valid_lft forever preferred_lft 0sec</span><br><span class="line">    inet6 fe80::eda:41ff:fe1d:a862/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<p><em><a target="_blank" rel="noopener" href="https://manpages.debian.org/ip-address(8)">ip-address(8)</a></em> 查到对该标记的解释如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tentative</span><br><span class="line">   (IPv6 only) only list addresses which have not yet passed duplicate address detection.</span><br></pre></td></tr></table></figure>

<p>显然该地址没有通过地址重复探测（<code>duplicate address detection</code>，简称<code>dad</code>），而且这种检查机制只针对<code>IPv6</code>。<strong>经确认，该环境的<code>IPv6</code>网段只有自己在用，且未手工配置过<code>IPv6</code>地址，但该环境曾经发生过切主</strong>；</p>
<p>至此问题基本明确了，切主时会把老的主节点上的<code>vip</code>删除，再到新的主节点上把<code>vip</code>添加上去。如果一切正常，按照这个顺序切主没有问题，但也存在某些异常情况（比如老主上的<code>vip</code>没有及时删掉，而新主上已经添加好了），此时就会触发<code>dad</code>机制。经过验证，一旦出现<code>dadfailed</code>，即使地址冲突解决了，该地址依然无法访问；</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>方案1：在<code>sysctl</code>配置中增加如下内核参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">net.ipv6.conf.all.accept_dad = 0</span><br><span class="line">net.ipv6.conf.default.accept_dad = 0</span><br><span class="line">net.ipv6.conf.eth0.accept_dad = 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">IPv6 Privacy Extensions (RFC 4941)</span></span><br><span class="line">net.ipv6.conf.all.use_tempaddr = 0</span><br><span class="line">net.ipv6.conf.default.use_tempaddr = 0</span><br></pre></td></tr></table></figure>

<p>方案2：在<code>ip addr add</code>命令执行时增加<code>nodad</code>标识：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip addr add 2000::10:18/128 dev eth0 nodad</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://blog.clanzx.net/network/ipv6-dad.html">https://blog.clanzx.net/network/ipv6-dad.html</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2021/09/25/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E9%99%84%E5%8A%A0%E7%BD%91%E7%BB%9CPod%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/25/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E9%99%84%E5%8A%A0%E7%BD%91%E7%BB%9CPod%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/" class="post-title-link" itemprop="url">K8S问题排查-附加网络Pod无法启动</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-25 19:21:50" itemprop="dateCreated datePublished" datetime="2021-09-25T19:21:50+00:00">2021-09-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>使用附加网络的Pod在服务器重启后启动异常，报错信息如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">Type 		Reason 				  Age 		From 			Message</span><br><span class="line">Normal 		Scheduled 			  53m 		default-scheduler Successfully assigned xxx/xxx1-64784c458b-q67tx to node001</span><br><span class="line">Warning 	FailedCreatePodSandBox 53m 		 kubelet, node001   Failed to create pod sandbox: rpc er or: code = Unknown desc = failed to set up sandbox container &quot;xxx&quot; network for pod &quot;xxxl-64784c458b-q67tx&quot;: NetworkPlugin cni failed to set up pod &quot;xxx1-64784c458b-q67tx_xxx&quot; network: Multus: Err adding pod to network &quot;net-netl-nodeOOl&quot;: Multus: error in invoke Delegate add - &quot;macvlan&quot;: failed to create macvlan: device or resource busy</span><br><span class="line">Warning 	FailedCreatePodSandBox 53m 		 kubelet, node001   Failed to create pod sandbox: rpc er or: code = Unknown desc = failed to set up sandbox container &quot;xxx&quot; network for pod &quot;xxxl-64784c458b-q67tx&quot;: NetworkPlugin cni failed to set up pod &quot;xxx1-64784c458b-q67tx_xxx&quot; network: Multus: Err adding pod to network &quot;net-netl-nodeOOl&quot;: Multus: error in invoke Delegate add - &quot;macvlan&quot;: failed to create macvlan: device or resource busy</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>从日志初步看，创建Pod的<code>sandbox</code>异常，具体是Multus无法将Pod添加到<code>net-netl-nodeOOl</code>网络命名空间内，再具体点是Multus无法创建<code>macvlan</code>网络，原因是<code>device or resource busy</code>；</p>
<p>最后的这个错误信息还是比较常见的，从字面理解，就是设备或资源忙，常见于共享存储的卸载场景。那这里也应该类似，有什么设备或资源处于被占用状态，所以执行<code>macvlan</code>的创建失败，既然是附加网络的问题，那优先查看了下附加网络相关的CRD资源，没什么异常；</p>
<p>网上根据日志搜索一番，也没有什么比较相关的问题，那就看代码吧，首先找到Multus的源码，根据上述日志找相关处理逻辑，没有找到。再一想，Multus实现<code>macvlan</code>网络使用的是<code>macvlan</code>插件，再下载插件代码，找到了相关处理逻辑：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">plugins/main/macvlan/macvlan.<span class="keyword">go</span>:<span class="number">169</span></span><br><span class="line"><span class="keyword">if</span> err := netlink.LinkAdd(mv); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;failed to create macvlan: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LinkAdd adds a new link device. The type and features of the device</span></span><br><span class="line"><span class="comment">// are taken from the parameters in the link object.</span></span><br><span class="line"><span class="comment">// Equivalent to: `ip link add $link`</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">LinkAdd</span><span class="params">(link Link)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> pkgHandle.LinkAdd(link)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LinkAdd adds a new link device. The type and features of the device</span></span><br><span class="line"><span class="comment">// are taken from the parameters in the link object.</span></span><br><span class="line"><span class="comment">// Equivalent to: `ip link add $link`</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *Handle)</span></span> LinkAdd(link Link) <span class="type">error</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> h.linkModify(link, unix.NLM_F_CREATE|unix.NLM_F_EXCL|unix.NLM_F_ACK)</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>根据上述代码和注释简单的看，是在执行<code>ip link add $link</code>命令时报错，实际验证看看：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~] ip link add link bond1 name macvlan1 type macvlan mode bridge</span><br><span class="line">RTNETLINK answers: Device or resource busy</span><br></pre></td></tr></table></figure>

<p>确实如此，在<code>bond1</code>接口上无法配置<code>macvlan</code>，那换一个接口试试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~] ip link add link bond0 name macvlan1 type macvlan mode bridge</span><br><span class="line">[root@node001 ~] ip link show</span><br><span class="line">...</span><br><span class="line">110: macvlan1@bond0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/ether ea:31:c9:7f:d9:a4 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>配置成功，说明<code>bond1</code>接口有什么问题，看看这俩接口有没有差异：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~] ip addr show</span><br><span class="line">...</span><br><span class="line">2: bond0: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 0c:da:41:1d:6f:ca brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet x.x.x.x/16 brd x.x.255.255 scope global bond0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::eda:41ff:fe1d:6fca/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">...</span><br><span class="line">17: bond1: &lt;BROADCAST,MULTICAST,MASTER,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 0c:da:41:1d:a8:62 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>对比两个接口可以发现两个差异点：</p>
<ol>
<li><code>bond0</code>配置了IP地址，而<code>bond1</code>没有配置；</li>
<li><code>bond0</code>是MASTER角色，<code>bond1</code>既是MASTER，又是SLAVE角色；</li>
</ol>
<p>考虑到<code>bond0</code>接口是用来建集群的，<code>bond1</code>接口是给<code>Multus</code>创建<code>macvlan</code>网络用的，所以第一个差异点属于正常现象。第二个是什么情况呢？一般来说，配置<code>bond</code>的目的是把几个物理接口作为SLAVE角色聚合成<code>bond</code>接口，这样既能增加服务器的可靠性，又增加了可用网络宽带，为用户提供不间断的网络服务。配置后，实际的物理接口应该是SLAVE角色，而聚合后的<code>bond</code>接口应该是MASTER角色，所以正常来说，不会同时出现两个角色才对；</p>
<p>查看两个<code>bond</code>的相关配置，没有发现什么异常，反过来讲，如果配置的有问题，那初次部署就应该报错了，而不是重启节点才发现。所以，<strong>问题的关键是重启导致的</strong>。也就是说，可能是在重启后的启动脚本里加了什么配置影响的；</p>
<p>搜索相关资料[1]，发现在配置过程中可能有这么一个操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4、在/etc/rc.d/rc.local文件中加入如下语句，使系统启动自动运行</span><br><span class="line">ifenslave  bond0  eth0  eth1</span><br></pre></td></tr></table></figure>

<p>查看问题环境上怎么配置的：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~] cat /etc/rc.local</span><br><span class="line">...</span><br><span class="line">touch /var/lock/subsys/local</span><br><span class="line">ifenslave bond0 bond1 enp661s0f0 enp661s0f1 ens1f0 ens1f1</span><br></pre></td></tr></table></figure>

<p>发现有类似的配置，但不同的是，问题环境上配置了两个<code>bond</code>，并且配置在了一个命令里。感觉不是太对，个人理解这么配置应该会把<code>bond1</code>也认为是<code>bond0</code>的SLAVE，修改一下试试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~] cat /etc/rc.local</span><br><span class="line">...</span><br><span class="line">touch /var/lock/subsys/local</span><br><span class="line">ifenslave bond0 enp661s0f0 enp661s0f1</span><br><span class="line">ifenslave bond1 ens1f0 ens1f1</span><br><span class="line">[root@node001 ~] systemctl restart network</span><br></pre></td></tr></table></figure>

<p>再观察两个bond接口的角色，发现恢复正常，再看看异常Pod，也都起来了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~] kubectl get pod -A |grep -v Running</span><br><span class="line">NAMESPACE		NAME		READY		STATUS		RESTARTS		AGE</span><br></pre></td></tr></table></figure>

<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>将<code>rc.local</code>里的两个<code>bond</code>的命令拆开分别配置即可。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/geaozhang/p/6763876.html">https://www.cnblogs.com/geaozhang/p/6763876.html</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2021/08/14/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E5%88%A0%E9%99%A4Pod%E5%90%8E%E5%A4%84%E4%BA%8ETerminating%E7%8A%B6%E6%80%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/14/k8s/K8S%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5-%E5%88%A0%E9%99%A4Pod%E5%90%8E%E5%A4%84%E4%BA%8ETerminating%E7%8A%B6%E6%80%81/" class="post-title-link" itemprop="url">K8S问题排查-删除Pod后处于Terminating状态</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-14 17:20:51" itemprop="dateCreated datePublished" datetime="2021-08-14T17:20:51+00:00">2021-08-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-08-04 11:40:00" itemprop="dateModified" datetime="2024-08-04T11:40:00+00:00">2024-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>通过<code>kubectl delete</code>命令删除某个业务Pod后，该Pod一直处于<code>Terminating</code>状态。</p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>根据现象看，应该是删除过程中有哪个流程异常，导致最终的删除卡在了<code>Terminating</code>状态。先<code>describe</code>看一下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl describe pod -n xxx cam1-78b6fc6bc8-cjsw5</span><br><span class="line">// 没有发现什么异常信息，这里就不贴日志了</span><br></pre></td></tr></table></figure>

<p><code>Event</code>事件中未见明显异常，那就看负责删除Pod的<code>kubelet</code>组件日志（已过滤出关键性日志）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">I0728 16:24:57.339295    9744 kubelet.go:1904] SyncLoop (DELETE, &quot;api&quot;): &quot;cam1-78b6fc6bc8-cjsw5_cam(5c948341-c030-4996-b888-f032577d97b0)&quot;</span><br><span class="line">I0728 16:24:57.339720    9744 kuberuntime_container.go:581] Killing container &quot;docker://a73082a4a9a4cec174bb0d1c256cc11d804d93137551b9bfd3e6fa1522e98589&quot; with 60 second grace period</span><br><span class="line">I0728 16:25:18.259418    9744 kubelet.go:1904] SyncLoop (DELETE, &quot;api&quot;): &quot;cam1-78b6fc6bc8-cjsw5_cam(5c948341-c030-4996-b888-f032577d97b0)&quot;</span><br><span class="line">2021-07-28 16:25:19.247 [INFO][394011] ipam.go 1173: Releasing all IPs with handle &#x27;cam.cam1-78b6fc6bc8-cjsw5&#x27;</span><br><span class="line">2021-07-28 16:25:19.254 [INFO][393585] k8s.go 498: Teardown processing complete.</span><br><span class="line"></span><br><span class="line">// 可疑点1：没有获取到pod IP</span><br><span class="line">W0728 16:25:19.303513    9744 docker_sandbox.go:384] failed to read pod IP from plugin/docker: NetworkPlugin cni failed on the status hook for pod &quot;cam1-78b6fc6bc8-cjsw5_cam&quot;: Unexpected command output Device &quot;eth0&quot; does not exist.</span><br><span class="line"> with error: exit status 1</span><br><span class="line"> </span><br><span class="line">I0728 16:25:19.341068    9744 kubelet.go:1933] SyncLoop (PLEG): &quot;cam1-78b6fc6bc8-cjsw5_cam(5c948341-c030-4996-b888-f032577d97b0)&quot;, event: &amp;pleg.PodLifecycleEvent&#123;ID:&quot;5c948341-c030-4996-b888-f032577d97b0&quot;, Type:&quot;ContainerDied&quot;, Data:&quot;a73082a4a9a4cec174bb0d1c256cc11d804d93137551b9bfd3e6fa1522e98589&quot;&#125;</span><br><span class="line">I0728 16:25:20.578095    9744 kubelet.go:1933] SyncLoop (PLEG): &quot;cam1-78b6fc6bc8-cjsw5_cam(5c948341-c030-4996-b888-f032577d97b0)&quot;, event: &amp;pleg.PodLifecycleEvent&#123;ID:&quot;5c948341-c030-4996-b888-f032577d97b0&quot;, Type:&quot;ContainerDied&quot;, Data:&quot;c3b992465cd2085300995066526a36665664558446ff6e1756135c3a5b6df2e6&quot;&#125;</span><br><span class="line"></span><br><span class="line">I0728 16:25:20.711967    9744 kubelet_pods.go:1090] Killing unwanted pod &quot;cam1-78b6fc6bc8-cjsw5&quot;</span><br><span class="line"></span><br><span class="line">// 可疑点2：Unmount失败</span><br><span class="line">E0728 16:25:20.939400    9744 nestedpendingoperations.go:301] Operation for &quot;&#123;volumeName:kubernetes.io/glusterfs/5c948341-c030-4996-b888-f032577d97b0-cam-pv-50g podName:5c948341-c030-4996-b888-f032577d97b0 nodeName:&#125;&quot; failed. No retries permitted until 2021-07-28 16:25:21.439325811 +0800 CST m=+199182.605079651 (durationBeforeRetry 500ms). Error: &quot;UnmountVolume.TearDown failed for volume \&quot;diag-log\&quot; (UniqueName: \&quot;kubernetes.io/glusterfs/5c948341-c030-4996-b888-f032577d97b0-cam-pv-50g\&quot;) pod \&quot;5c948341-c030-4996-b888-f032577d97b0\&quot; (UID: \&quot;5c948341-c030-4996-b888-f032577d97b0\&quot;) : Unmount failed: exit status 32\nUnmounting arguments: /var/lib/kubelet/pods/5c948341-c030-4996-b888-f032577d97b0/volumes/kubernetes.io~glusterfs/cam-pv-50g\nOutput: umount: /var/lib/kubelet/pods/5c948341-c030-4996-b888-f032577d97b0/volumes/kubernetes.io~glusterfs/cam-pv-50g：目标忙。\n        (有些情况下通过 lsof(8) 或 fuser(1) 可以\n         找到有关使用该设备的进程的有用信息。)\n\n&quot;</span><br></pre></td></tr></table></figure>

<p>从删除Pod的日志看，有2个可疑点：</p>
<ol>
<li><code>docker_sandbox.go:384</code>打印的获取<code>pod IP</code>错误；</li>
<li><code>nestedpendingoperations.go:301</code>打印的<code>Unmount</code>失败错误；</li>
</ol>
<p>先看第1点，根据日志定位到代码[1]位置如下，<code>IP</code>没有拿到所以打印了个告警并返回空<code>IP</code>地址；</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">pkg/kubelet/dockershim/docker_sandbox.<span class="keyword">go</span>:<span class="number">348</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ds *dockerService)</span></span> getIP(podSandboxID <span class="type">string</span>, sandbox *dockertypes.ContainerJSON) <span class="type">string</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> sandbox.NetworkSettings == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> networkNamespaceMode(sandbox) == runtimeapi.NamespaceMode_NODE &#123;</span><br><span class="line">		<span class="comment">// For sandboxes using host network, the shim is not responsible for</span></span><br><span class="line">		<span class="comment">// reporting the IP.</span></span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Don&#x27;t bother getting IP if the pod is known and networking isn&#x27;t ready</span></span><br><span class="line">	ready, ok := ds.getNetworkReady(podSandboxID)</span><br><span class="line">	<span class="keyword">if</span> ok &amp;&amp; !ready &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	ip, err := ds.getIPFromPlugin(sandbox)</span><br><span class="line">	<span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> ip</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">if</span> sandbox.NetworkSettings.IPAddress != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> sandbox.NetworkSettings.IPAddress</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> sandbox.NetworkSettings.GlobalIPv6Address != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> sandbox.NetworkSettings.GlobalIPv6Address</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 错误日志在这里</span></span><br><span class="line">	klog.Warningf(<span class="string">&quot;failed to read pod IP from plugin/docker: %v&quot;</span>, err)</span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>继续看<code>getIP</code>方法的调用处代码，这里如果没有拿到<code>IP</code>，也没有什么异常，直接把空值放到<code>PodSandboxStatusResponse</code>中并返回；</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">pkg/kubelet/dockershim/docker_sandbox.<span class="keyword">go</span>:<span class="number">404</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ds *dockerService)</span></span> PodSandboxStatus(ctx context.Context, req *runtimeapi.PodSandboxStatusRequest) (*runtimeapi.PodSandboxStatusResponse, <span class="type">error</span>) &#123;</span><br><span class="line">	podSandboxID := req.PodSandboxId</span><br><span class="line"></span><br><span class="line">	r, metadata, err := ds.getPodSandboxDetails(podSandboxID)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Parse the timestamps.</span></span><br><span class="line">	createdAt, _, _, err := getContainerTimestamps(r)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;failed to parse timestamp for container %q: %v&quot;</span>, podSandboxID, err)</span><br><span class="line">	&#125;</span><br><span class="line">	ct := createdAt.UnixNano()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Translate container to sandbox state.</span></span><br><span class="line">	state := runtimeapi.PodSandboxState_SANDBOX_NOTREADY</span><br><span class="line">	<span class="keyword">if</span> r.State.Running &#123;</span><br><span class="line">		state = runtimeapi.PodSandboxState_SANDBOX_READY</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 调用getIP方法的位置</span></span><br><span class="line">	<span class="keyword">var</span> IP <span class="type">string</span></span><br><span class="line">	<span class="keyword">if</span> IP = ds.determinePodIPBySandboxID(podSandboxID); IP == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">		IP = ds.getIP(podSandboxID, r)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    labels, annotations := extractLabels(r.Config.Labels)</span><br><span class="line">	status := &amp;runtimeapi.PodSandboxStatus&#123;</span><br><span class="line">		Id:          r.ID,</span><br><span class="line">		State:       state,</span><br><span class="line">		CreatedAt:   ct,</span><br><span class="line">		Metadata:    metadata,</span><br><span class="line">		Labels:      labels,</span><br><span class="line">		Annotations: annotations,</span><br><span class="line">		Network: &amp;runtimeapi.PodSandboxNetworkStatus&#123;</span><br><span class="line">			Ip: IP,</span><br><span class="line">		&#125;,</span><br><span class="line">		Linux: &amp;runtimeapi.LinuxPodSandboxStatus&#123;</span><br><span class="line">			Namespaces: &amp;runtimeapi.Namespace&#123;</span><br><span class="line">				Options: &amp;runtimeapi.NamespaceOption&#123;</span><br><span class="line">					Network: networkNamespaceMode(r),</span><br><span class="line">					Pid:     pidNamespaceMode(r),</span><br><span class="line">					Ipc:     ipcNamespaceMode(r),</span><br><span class="line">				&#125;,</span><br><span class="line">			&#125;,</span><br><span class="line">		&#125;,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &amp;runtimeapi.PodSandboxStatusResponse&#123;Status: status&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>到此看不出这个错误会不会中断删除流程，那就本地构造一下试试。修改上面的代码，在调用<code>getIP</code>方法的位置后面增加调试日志（从本地验证结果看，Pod正常删除，说明异常问题与此处无关）；</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 调用getIP方法的位置</span></span><br><span class="line"><span class="keyword">var</span> IP <span class="type">string</span></span><br><span class="line"><span class="keyword">if</span> IP = ds.determinePodIPBySandboxID(podSandboxID); IP == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">	IP = ds.getIP(podSandboxID, r)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 新加调试日志，如果是指定的Pod，强制将IP置空</span></span><br><span class="line">isTestPod := strings.Contains(metadata.GetName(), <span class="string">&quot;testpod&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> isTestPod &#123;</span><br><span class="line">	IP = <span class="string">&quot;&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再看第2点，这个是<code>ERROR</code>级别的错误，问题出在<code>Unmount</code>挂载点时失败。那么卸载挂载点失败会导致卸载流程提前终止吗？网上关于Pod删除流程的源码分析文章很多，我们就直接找几篇[2,3,4]看看能不能解答上面的问题。</p>
<p><strong>简单总结来说，删除一个Pod的流程如下：</strong></p>
<ol>
<li>调用<code>kube-apiserver</code>的<code>DELETE</code>接口（默认带<code>grace-period=30s</code>）；</li>
<li>第一次的删除只是更新Pod对象的元信息（<code>DeletionTimestamp</code>字段和<code>DeletionGracePeriodSeconds</code>字段），并没有在<code>Etcd</code>中删除记录；</li>
<li><code>kubectl</code>命令的执行会阻塞并显示正在删除Pod；</li>
<li><code>kubelet</code>组件监听到Pod对象的更新事件，执行<code>killPod()</code>方法；</li>
<li><code>kubelet</code>组件监听到pod的删除事件，第二次调用<code>kube-apiserver</code>的<code>DELETE</code>接口（带<code>grace-period=0</code>）</li>
<li><code>kube-apiserver</code>的<code>DELETE</code>接口去<code>etcd</code>中删除Pod对象；</li>
<li><code>kubectl</code>命令的执行返回，删除Pod成功；</li>
</ol>
<p>从前面<code>kubelet</code>删除异常的日志看，确实有两次<code>DELETE</code>操作，并且中间有个<code>Killing container</code>的日志，但从上面的删除流程看，两次<code>DELETE</code>操作之间应该是调用<code>killPod()</code>方法，通过查看源码，对应的日志应该是<code>Killing unwanted pod</code>，所以，实际上第二次的<code>DELETE</code>操作并没有触发。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">pkg/kubelet/kubelet_pods.<span class="keyword">go</span>:<span class="number">1073</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> podKiller() &#123;</span><br><span class="line">	killing := sets.NewString()</span><br><span class="line">	<span class="comment">// guard for the killing set</span></span><br><span class="line">	lock := sync.Mutex&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> podPair := <span class="keyword">range</span> kl.podKillingCh &#123;</span><br><span class="line">		runningPod := podPair.RunningPod</span><br><span class="line">		apiPod := podPair.APIPod</span><br><span class="line"></span><br><span class="line">		lock.Lock()</span><br><span class="line">		exists := killing.Has(<span class="type">string</span>(runningPod.ID))</span><br><span class="line">		<span class="keyword">if</span> !exists &#123;</span><br><span class="line">			killing.Insert(<span class="type">string</span>(runningPod.ID))</span><br><span class="line">		&#125;</span><br><span class="line">		lock.Unlock()</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 这里在调用killPod方法前会打印v2级别的日志</span></span><br><span class="line">		<span class="keyword">if</span> !exists &#123;</span><br><span class="line">			<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(apiPod *v1.Pod, runningPod *kubecontainer.Pod)</span></span> &#123;</span><br><span class="line">				klog.V(<span class="number">2</span>).Infof(<span class="string">&quot;Killing unwanted pod %q&quot;</span>, runningPod.Name)</span><br><span class="line">				err := kl.killPod(apiPod, runningPod, <span class="literal">nil</span>, <span class="literal">nil</span>)</span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					klog.Errorf(<span class="string">&quot;Failed killing the pod %q: %v&quot;</span>, runningPod.Name, err)</span><br><span class="line">				&#125;</span><br><span class="line">				lock.Lock()</span><br><span class="line">				killing.Delete(<span class="type">string</span>(runningPod.ID))</span><br><span class="line">				lock.Unlock()</span><br><span class="line">			&#125;(apiPod, runningPod)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>怎么确认第二次的<code>DELETE</code>操作有没有触发呢？很简单，看代码或者实际验证都可以。这里我就在测试环境删除个Pod看下相关日志：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# kubectl delete pod -n xxx  testpodrc2-7b749f6c9c-qh68l</span><br><span class="line">pod &quot;testpodrc2-7b749f6c9c-qh68l&quot; deleted</span><br><span class="line"></span><br><span class="line">// 已过滤出关键性日志</span><br><span class="line">[root@node2 ~]# tailf kubelet.log</span><br><span class="line">I0730 13:27:31.854178   24588 kubelet.go:1904] SyncLoop (DELETE, &quot;api&quot;): &quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span><br><span class="line">I0730 13:27:31.854511   24588 kuberuntime_container.go:581] Killing container &quot;docker://e2a1cd5f2165e12cf0b46e12f9cd4d656d593f75e85c0de058e0a2f376a5557e&quot; with 30 second grace period</span><br><span class="line">I0730 13:27:32.203167   24588 kubelet.go:1904] SyncLoop (DELETE, &quot;api&quot;): &quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span><br><span class="line"></span><br><span class="line">I0730 13:27:32.993294   24588 kubelet.go:1933] SyncLoop (PLEG): &quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;, event: &amp;pleg.PodLifecycleEvent&#123;ID:&quot;85ee282f-a843-4f10-a99c-79d447f83f2a&quot;, Type:&quot;ContainerDied&quot;, Data:&quot;e2a1cd5f2165e12cf0b46e12f9cd4d656d593f75e85c0de058e0a2f376a5557e&quot;&#125;</span><br><span class="line">I0730 13:27:32.993428   24588 kubelet.go:1933] SyncLoop (PLEG): &quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;, event: &amp;pleg.PodLifecycleEvent&#123;ID:&quot;85ee282f-a843-4f10-a99c-79d447f83f2a&quot;, Type:&quot;ContainerDied&quot;, Data:&quot;c6a587614976beed0cbb6e5fabf70a2d039eec6c160154fce007fe2bb1ba3b4f&quot;&#125;</span><br><span class="line"></span><br><span class="line">I0730 13:27:34.072494   24588 kubelet_pods.go:1090] Killing unwanted pod &quot;testpodrc2-7b749f6c9c-qh68l&quot;</span><br><span class="line"></span><br><span class="line">I0730 13:27:40.084182   24588 kubelet.go:1904] SyncLoop (DELETE, &quot;api&quot;): &quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span><br><span class="line">I0730 13:27:40.085735   24588 kubelet.go:1898] SyncLoop (REMOVE, &quot;api&quot;): &quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span><br></pre></td></tr></table></figure>

<p>对比正常和异常场景下的日志可以看出，正常的删除操作下，<code>Killing unwanted pod</code>日志之后会有<code>DELETE</code>和<code>REMOVE</code>的操作，这也就说明问题出在第二次<code>DELETE</code>操作没有触发。查看相关代码：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">pkg/kubelet/status/status_manager.<span class="keyword">go</span>:<span class="number">470</span></span><br><span class="line"><span class="comment">//kubelet组件有一个statusManager模块，它会for循环调用syncPod()方法</span></span><br><span class="line"><span class="comment">//方法内部有机会调用kube-apiserver的DELETE接口(强制删除，非平滑)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *manager)</span></span> syncPod(uid types.UID, status versionedPodStatus) &#123;</span><br><span class="line">	...</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//当pod带有DeletionTimestamp字段，并且其内容器已被删除、持久卷已被删除等的多条件下，才会进入if语句内部</span></span><br><span class="line">    <span class="keyword">if</span> m.canBeDeleted(pod, status.status) &#123;</span><br><span class="line">        deleteOptions := metav1.NewDeleteOptions(<span class="number">0</span>)</span><br><span class="line">        deleteOptions.Preconditions = metav1.NewUIDPreconditions(<span class="type">string</span>(pod.UID))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//强制删除pod对象：kubectl delete pod podA --grace-period=0</span></span><br><span class="line">        err = m.kubeClient.CoreV1().Pods(pod.Namespace).Delete(pod.Name, deleteOptions) </span><br><span class="line">	...</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从源码可以看出，第二次<code>DELETE</code>操作是否触发依赖于<code>canBeDeleted</code>方法的校验结果，而这个方法内会检查持久卷是否已经被删除：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">pkg/kubelet/status/status_manager.<span class="keyword">go</span>:<span class="number">538</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *manager)</span></span> canBeDeleted(pod *v1.Pod, status v1.PodStatus) <span class="type">bool</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> pod.DeletionTimestamp == <span class="literal">nil</span> || kubepod.IsMirrorPod(pod) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> m.podDeletionSafety.PodResourcesAreReclaimed(pod, status)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pkg/kubelet/kubelet_pods.<span class="keyword">go</span>:<span class="number">900</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> PodResourcesAreReclaimed(pod *v1.Pod, status v1.PodStatus) <span class="type">bool</span> &#123;</span><br><span class="line">	...</span><br><span class="line">    </span><br><span class="line">	<span class="comment">// 这里会判断挂载卷是否已卸载</span></span><br><span class="line">	<span class="keyword">if</span> kl.podVolumesExist(pod.UID) &amp;&amp; !kl.keepTerminatedPodVolumes &#123;</span><br><span class="line">		<span class="comment">// We shouldnt delete pods whose volumes have not been cleaned up if we are not keeping terminated pod volumes</span></span><br><span class="line">		klog.V(<span class="number">3</span>).Infof(<span class="string">&quot;Pod %q is terminated, but some volumes have not been cleaned up&quot;</span>, format.Pod(pod))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> kl.kubeletConfiguration.CgroupsPerQOS &#123;</span><br><span class="line">		pcm := kl.containerManager.NewPodContainerManager()</span><br><span class="line">		<span class="keyword">if</span> pcm.Exists(pod) &#123;</span><br><span class="line">			klog.V(<span class="number">3</span>).Infof(<span class="string">&quot;Pod %q is terminated, but pod cgroup sandbox has not been cleaned up&quot;</span>, format.Pod(pod))</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结合出问题的日志，基本能确认是<code>Unmount</code>挂载点失败导致的异常。那么，挂载点为啥会<code>Unmount</code>失败？</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// umount失败关键日志</span><br><span class="line">Unmount failed: exit status 32\nUnmounting arguments: /var/lib/kubelet/pods/xxx/volumes/kubernetes.io~glusterfs/cam-pv-50g\nOutput: umount: /var/lib/kubelet/pods/xxx/volumes/kubernetes.io~glusterfs/cam-pv-50g：目标忙。\n        (有些情况下通过 lsof(8) 或 fuser(1) 可以\n         找到有关使用该设备的进程的有用信息。)\n\n&quot;</span><br></pre></td></tr></table></figure>

<p>仔细看卸载失败的日志，可以看到这个挂载点的后端存储是<code>glusterfs</code>，而<code>目标忙</code>一般来说是存储设备侧在使用，所以无法卸载。那就找找看是不是哪个进程使用了这个挂载目录（以下定位由负责<code>glusterfs</code>的同事提供）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# fuser -mv /var/lib/kubelet/pods/xxx/volumes/kubernetes.io~glusterfs/cam-pv-50g</span><br><span class="line">用户  进程号  权限  命令</span><br><span class="line">root  kernel mount /var/lib/kubelet/pods/xxx/volumes/kubernetes.io~glusterfs/cam-dialog-gl.uster-pv-50g</span><br><span class="line">root  94549  f.... glusterfs</span><br></pre></td></tr></table></figure>

<p>除了内核的<code>mount</code>，还有个<code>pid=94549</code>的<code>glusterfs</code>进程在占用挂载点所在目录，看看是什么进程：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# ps -ef| grep 94549</span><br><span class="line">root 94549 1 0 7月26 ? 00:01:13 /usr/sbin/glusterfs --log-level=ERR0R --log-file=/var/lib/kubelet/plugins/kubernetes.io/glusterfs/global-diaglog-pv/web-fddf96444-stxpf-glusterfs.log --fuse-mountopts=auto_unmount --process-name fuse --volfile-server=xxx --volfile-server=xxx --tfolfile-server=xxx --volfile-id=global-diaglog --fuse-mountopts=auto_unmount /var/lib/kubelet/pods/xxx/volumes/kubernetef.io-glusterfs/global-diaglog-pv</span><br></pre></td></tr></table></figure>

<p>发现这个进程维护的是<code>web-xxx</code>的挂载信息，而<code>web-xxx</code>和<code>cam-xxx</code>没有任何关联。由此推断出是<code>glusterfs</code>管理的挂载信息发送错乱导致，具体错乱原因就转给相关负责的同事看了。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>从分析结果看，是共享存储卷未正常卸载导致的删除Pod异常，非K8S问题。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/tree/v1.15.12">Kubernetes v1.15.12源码</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/nangonghen/article/details/109305635">kubernetes删除pod的流程的源码简析</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903842321039368">Kubernetes源码分析之Pod的删除</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/608727">kubernetes grace period 失效问题排查</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LeaoYao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">93</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LeaoYao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
