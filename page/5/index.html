<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lyyao09.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="云原生知识星球">
<meta property="og:url" content="https://lyyao09.github.io/page/5/index.html">
<meta property="og:site_name" content="云原生知识星球">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="LeaoYao">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://lyyao09.github.io/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>云原生知识星球</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">云原生知识星球</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/28/k8s/Kubernetes-Patterns-The-Init-Container-Pattern/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/28/k8s/Kubernetes-Patterns-The-Init-Container-Pattern/" class="post-title-link" itemprop="url">Kubernetes模式：initContainer使用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-28 21:48:10" itemprop="dateCreated datePublished" datetime="2020-12-28T21:48:10+00:00">2020-12-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Init模式"><a href="#Init模式" class="headerlink" title="Init模式"></a>Init模式</h2><p>初始化逻辑通常在编程语言中很常见。在面向对象编程语言中，我们有构造函数的概念。构造函数是一个函数（或方法），每当对象被实例化时都会被调用。构造器的目的是“准备”对象以完成它应该做的工作。例如，它设置变量的默认值，创建数据库连接对象，确保对象正确运行所需的先决条件的存在。例如，如果创建了一个user对象，那么它至少需要用户的用户名、名和姓，这样它才能正常工作。不同语言之间的构造函数实现是不同的。但是，所有这些都只被调用一次，并且只在对象实例化时调用。</p>
<p>初始化模式的目的是将对象与其初始化逻辑解耦。因此，如果一个对象需要一些种子数据输入到数据库中，这就属于构造函数逻辑而不是应用程序逻辑。这允许我们更改对象的“启动”方式，而不影响其“工作”方式。</p>
<p>Kubernetes使用相同的模式。虽然对象是面向对象语言的原子单元，但是Kubernetes有Pods。因此，如果我们有一个应用程序在需要一些初始化逻辑的容器上运行，那么将此工作交给另一个容器是一个很好的做法。Kubernetes有一种用于特定作业的容器类型：init containers。</p>
<h2 id="Init-Containers"><a href="#Init-Containers" class="headerlink" title="Init Containers"></a>Init Containers</h2><p>在Kubernetes中，init容器是在同一个Pod中的其他容器之前启动和执行的容器。它的目的是<strong>为Pod上托管的主应用程序执行初始化逻辑</strong>。例如，创建必要的用户帐户、执行数据库迁移、创建数据库模式等等。</p>
<h2 id="Init-Containers设计注意事项"><a href="#Init-Containers设计注意事项" class="headerlink" title="Init Containers设计注意事项"></a>Init Containers设计注意事项</h2><p>在创建init容器时，我们应该考虑一些注意事项：</p>
<ul>
<li>它们总是比Pod里的其他容器先执行。因此，它们不应该包含需要很长时间才能完成的复杂逻辑。启动脚本通常很小而且简洁。如果我们发现在init容器中添加了太多的逻辑，那就应该考虑将它的一部分移到应用程序容器本身。</li>
<li>Init容器按顺序启动和执行。除非成功完成其前置容器，否则不会调用init容器。因此，如果启动任务很长，可以考虑将其分成若干步骤，每个步骤都由init容器处理，以便知道哪些步骤失败。</li>
<li>如果任何init容器失败，整个Pod将重新启动（除非将restartPolicy设置为Never）。重新启动Pod意味着重新执行所有容器，包括任何init容器。因此，我们可能需要确保启动逻辑能够容忍多次执行而不会导致重复。例如，如果数据库迁移已经完成，那么应该忽略再次执行迁移命令。</li>
<li>在一个或多个依赖项可用之前，init容器是延迟应用程序初始化的一个很好的候选者。例如，如果我们的应用程序依赖于一个施加了API请求速率限制的API，可能需要等待一段时间才能从该API接收响应。在应用程序容器中实现此逻辑可能很复杂；因为它需要与运行状况和准备状态探测相结合。一种更简单的方法是创建一个init容器，该容器等待API准备好后才能成功退出。只有在init容器成功完成其工作之后，应用程序容器才会启动。</li>
<li>Init容器不能像应用程序容器那样使用liveness和readiness探针。原因是它们注定要成功启动和退出，就像Jobs和CronJobs的行为一样。</li>
<li>同一个Pod内的所有容器共享相同的卷和网络。我们可以使用此特性在应用程序及其init容器之间共享数据。</li>
</ul>
<h2 id="Init-Containers的“请求”和“限制”行为"><a href="#Init-Containers的“请求”和“限制”行为" class="headerlink" title="Init Containers的“请求”和“限制”行为"></a>Init Containers的“请求”和“限制”行为</h2><p>正如我们刚刚讨论的，init容器总是在同一个Pod上的其他应用程序容器之前启动。因此，调度程序为init容器的资源和限制提供了更高的优先级。这种行为必须被彻底考虑，因为它可能会导致不期望的结果。例如，如果我们有一个init容器和一个应用程序容器，并且将init容器的资源和限制设置为高于应用程序容器的资源和限制，那么只有在存在满足init容器要求的可用节点时，才会调度整个Pod。换句话说，即使有一个未使用的节点可以运行应用程序容器，如果init容器具有该节点可以处理的更高的资源先决条件，那么Pod也不会部署到该节点。因此，在定义init容器的请求和限制时，应该尽可能严格。<strong>作为最佳实践，除非绝对需要，否则不要将这些参数设置为高于应用程序容器的值。</strong></p>
<h2 id="场景01-初始化数据库"><a href="#场景01-初始化数据库" class="headerlink" title="场景01:初始化数据库"></a>场景01:初始化数据库</h2><p>在这个场景中，我们为MySQL数据库提供服务。此数据库用于测试应用程序。它不一定要包含真实的数据，但是它必须有足够的数据种子，这样我们就可以测试应用程序的查询速度。我们使用init容器来处理下载SQL转储文件并将其还原到数据库中，该数据库托管在另一个容器中。这种情况可以说明如下：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-Patterns-The-Init-Container-Pattern/init.png" alt="init"></p>
<p>yaml定义文件可能如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mydb</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">db</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fetch</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">mwendler/wget</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&quot;wget&quot;</span>,<span class="string">&quot;--no-check-certificate&quot;</span>,<span class="string">&quot;https://sample-videos.com/sql/Sample-SQL-File-1000rows.sql&quot;</span>,<span class="string">&quot;-O&quot;</span>,<span class="string">&quot;/docker-entrypoint-initdb.d/dump.sql&quot;</span>]</span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/docker-entrypoint-initdb.d</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">dump</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">mysql</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;example&quot;</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/docker-entrypoint-initdb.d</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">dump</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">      <span class="attr">name:</span> <span class="string">dump</span></span><br></pre></td></tr></table></figure>

<p>上面的定义创建了一个Pod，它承载两个容器：init容器和application容器。让我们看看这个定义有趣的方面：</p>
<ul>
<li><p>init容器负责下载包含数据库转储的SQL文件。我们使用mwendler&#x2F;wget映像，因为我们只需要wget命令。</p>
</li>
<li><p>下载的SQL的目标目录是MySQL镜像用来执行SQL文件的目录（&#x2F;docker-entrypoint-initdb.d）。此行为内置到我们在应用程序容器中使用的MySQL镜像中。</p>
</li>
<li><p>init容器将&#x2F;docker-entrypoint-initdb.d挂载到一个emptyDir卷。因为两个容器托管在同一个Pod上，所以它们共享相同的卷。因此，数据库容器可以访问emptyDir卷上的SQL文件。</p>
</li>
</ul>
<p><strong>如果没有Init Containers会发生什么</strong></p>
<p>在这个例子中，我们使用初始化模式作为最佳实践。如果我们在不使用init模式的情况下实现相同的逻辑，那么我们必须基于mysql基本镜像创建一个新映像，安装wget，然后使用它下载SQL文件。这种方法的缺点是：</p>
<ul>
<li><p>如果需要对下载逻辑进行任何更改，则需要创建一个新镜像，将其推送到定义文件中并更改其引用。这增加了维护自定义镜像的负担。</p>
</li>
<li><p>它在DB容器及其启动逻辑之间创建了一个紧密耦合的关系，这使得应用程序更难管理，并且增加了引入错误和bug的可能性。</p>
</li>
</ul>
<h2 id="场景02：延迟应用程序启动"><a href="#场景02：延迟应用程序启动" class="headerlink" title="场景02：延迟应用程序启动"></a>场景02：延迟应用程序启动</h2><p>init容器的另一个常见用例是当我们需要应用程序等待另一个服务完全运行（响应请求）时。以下定义演示了这种情况：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-pod</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.28</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>]</span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.28</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>所以，假设在myapp容器上运行的应用程序必须依赖myservice正常后才能正常工作。我们需要延迟myapp直到myservice准备好。我们通过使用一个简单的nslookup命令（第11行）来实现这一点，该命令不断检查“myservice”的成功名称解析。如果nslookup能够解析“myservice”，则服务将启动。使用一个成功的退出代码，init容器终止，让位于应用程序容器开始。否则，容器将在重试之前休眠两秒钟，从而延迟应用程序容器的启动。</p>
<p>为了完整起见，这是myservice的定义文件：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myservice</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><ul>
<li>Init模式是设计需要启动逻辑的应用程序时必须遵循的重要实践。</li>
<li>Kubernetes提供init容器作为将应用程序逻辑与其启动过程分离的一种方法。</li>
<li>将应用程序初始化逻辑放在init容器中有许多优点：<ul>
<li>我们将实施关注点分离原则。应用程序可以有自己的工程师团队，而其初始化逻辑由另一个团队编写。</li>
<li>在授权和访问控制方面，拥有一个独立的团队来处理应用程序的初始化步骤，可以给公司带来更大的灵活性。例如，如果启动应用程序需要使用需要安全许可的资源（例如，修改防火墙规则），则可以由具有适当凭据的人员来完成。应用程序团队不参与操作。</li>
<li>如果涉及太多的初始化步骤，可以将它们分解为多个init容器，然后依次执行。如果一个步骤失败，init容将报告一个错误，这将使我们更好地了解逻辑的哪一部分不成功。</li>
</ul>
</li>
<li>在使用init容器时，应该考虑以下几点：<ul>
<li>初始化容器在失败时重新启动。因此，它们的代码必须是幂等的。</li>
<li>Init容器的请求和限制会先被调度程序用于调度判断。错误的值可能会对调度器决定将整个Pod（包括应用程序容器）放置在哪里产生负面影响。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/26/k8s/Kubernetes-InitContainers-Volume-Pre-Population/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/26/k8s/Kubernetes-InitContainers-Volume-Pre-Population/" class="post-title-link" itemprop="url">Kubernetes使用InitContainers和Volume预填充数据</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-26 21:55:32" itemprop="dateCreated datePublished" datetime="2020-12-26T21:55:32+00:00">2020-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Kubernetes中的<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/">InitContainer资源</a>是一个有趣且非常有用的资源。在许多情况下，我们会看到它曾用于在Pod部署时，创建容器之前在卷中预填充数据，因此在业务容器启动时，卷数据已被初始化。</p>
<p>就我而言，我有一个带有单个静态页面的简单Web前端，它使用标准的nginx基础镜像：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> index.html /usr/share/nginx/html/index.html</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> smartos.ipxe /usr/share/nginx/html/smartos.ipxe</span></span><br></pre></td></tr></table></figure>

<p>该镜像的构建和下载速度非常快，这非常棒，但是部分原因是它是无状态的。例如，smartos.ipxe文件中需要一些数据，这些数据在启动应用程序时需要可用，否则这些引用将无法按预期工作（抽象为404 HTTP响应）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!ipxe</span><br><span class="line">dhcp</span><br><span class="line">set base-url http://sdc-ipxe.east.gourmet.yoga</span><br><span class="line">kernel $&#123;base-url&#125;/smartos/smartos/platform/i86pc/kernel/amd64/unix -B smartos=true,console=ttyb,ttyb-mode=&quot;115200,8,n,1,-&quot;</span><br><span class="line">module $&#123;base-url&#125;/smartos/smartos/platform/i86pc/amd64/boot_archive type=rootfs name=ramdisk</span><br><span class="line">boot</span><br></pre></td></tr></table></figure>

<p>但是，这些文件不是应用程序的一部分，因为它们经常更新。因此，每次推出新版本时，我们都希望该卷中包含最新版本，并且由于我们不需要维护镜像中的这些文件，否则在我们的Registry中存储起来会非常大且昂贵，我们可以在Pod中的容器上挂载一个Volume来提供它们。</p>
<p>因此，基本上，我们需要一种方法来预填充要装入到&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;smartos的卷。</p>
<p>使用InitContainer资源，我们可以指定要运行的命令，并且像Pod中的任何其他容器一样，我们可以分配要挂载的卷，因此让我们从这样的Kubernetes清单开始：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sdc-ipxe-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">sdc-ipxe</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">sdc-ipxe</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">sdc-ipxe</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-data</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">ubuntu:xenial</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>]</span><br><span class="line">        <span class="attr">args:</span> [<span class="string">&quot;apt update; apt install -y wget tar; wget https://us-east.manta.joyent.com/Joyent_Dev/public/SmartOS/platform-latest.tgz; tar xvf platform-latest.tgz -C /data; mkdir /data/smartos; mv /data/platform* /data/smartos/platform&quot;</span>]</span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">sdc-data</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sdc-data</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/mnt/kube-data/sdc-ipxe/</span></span><br><span class="line">          <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>因此，在这一点上，我们正在准备卷sdc数据，将其挂载到initContainer的&#x2F;data目录上并运行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt update; apt install -y wget tar; wget https://us-east.manta.joyent.com/Joyent_Dev/public/SmartOS/platform-latest.tgz; tar xvf platform-latest.tgz -C /data; mkdir /data/smartos; mv /data/platform* /data/smartos/platform</span><br></pre></td></tr></table></figure>

<p>上述命令下载数据并将其提取到卷中。现在，我们向yaml中添加一个container，然后再次附加该Volume，将可以使用预填充的数据：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sdc-ipxe-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">sdc-ipxe</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sdc-ipxe</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">coolregistryusa.bix/jmarhee/sdc-ipxe:latest</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html/smartos</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">sdc-data</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>在业务容器中配置相同名称的卷，则业务容器就可以通过&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;smartos目录获取sdc数据。</p>
<p>如果我们的应用程序依赖于具有可变需求的配置，则这种模式是有用的。可能是我们需要获得令牌，或者地址是动态的，并且需要通过磁盘上的文件而不是环境（比如负载平衡器，Web服务器或具有配置文件的数据库客户端，不容易通过它处理）传递文件（因为它们更改的频率不同）（Secret或ConfigMap），这种方法提供了一个易于编程的界面，用于预先填充或完成传递给容器的数据的模板化。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/26/k8s/Updating-Kubernetes-Raspberry-Pi-Cluster-To-Containerd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/26/k8s/Updating-Kubernetes-Raspberry-Pi-Cluster-To-Containerd/" class="post-title-link" itemprop="url">将Kubernetes群集的Docker切换到为Containerd</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-26 20:35:20" itemprop="dateCreated datePublished" datetime="2020-12-26T20:35:20+00:00">2020-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>由于Docker在Kubernetes v1.20中已弃用，最近几天在Twitter上发生了很多讨论。</p>
<h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>Kubernetes v1.20的废弃说明：</p>
<p>如果想了解更多，强烈建议查看此<a target="_blank" rel="noopener" href="https://twitter.com/Dixie3Flatline/status/1334188913724850177?s=19">Twitter</a>。</p>
<p>考虑到最近部署了一个Raspberry Pi Kubernetes集群，因此想就地进行更新，以使用Containerd代替Docker作为容器运行时。</p>
<blockquote>
<p>免责声明–不要在生产集群中这样做。对于这些集群，只需删除现有节点，然后滚动引入新节点。这个博客只是关于Raspberry Pi集群的一个有趣的话题，看看是否可以在无需重建节点的情况下就地完成更新。</p>
</blockquote>
<p>因此，要做的第一件事是drain需要更新的节点（我的节点称为k8s-node-1）并且cordon它：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl drain k8s-node-1 --ignore-daemonsets</span><br></pre></td></tr></table></figure>

<p>然后ssh进入节点并停止kubelet：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop kubelet</span><br></pre></td></tr></table></figure>

<p>然后删除Docker：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get remove docker.io</span><br></pre></td></tr></table></figure>

<p>删除旧的依赖项：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get autoremove</span><br></pre></td></tr></table></figure>

<p>现在unmask现有的containerd服务（Docker使用containerd，这就是为什么它已经存在的原因）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl unmask containerd</span><br></pre></td></tr></table></figure>

<p>安装所需的依赖项：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install unzip make golang-go libseccomp2 libseccomp-dev btrfs-progs libbtrfs-dev</span><br></pre></td></tr></table></figure>

<p>完成以上步骤后，现在我们按照<a target="_blank" rel="noopener" href="https://github.com/containerd/containerd/blob/master/BUILDING.md">官方说明</a>开始安装containerd。</p>
<p>无论如何，以root身份进行所有操作，获取containerd的源代码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go get -d github.com/containerd/containerd</span><br></pre></td></tr></table></figure>

<p>获取protoc 并安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget -c https://github.com/google/protobuf/releases/download/v3.11.4/protoc-3.11.4-linux-x86_64.zip</span><br><span class="line">sudo unzip protoc-3.11.4-linux-x86_64.zip -d /usr/local</span><br></pre></td></tr></table></figure>

<p>获取runc 的源代码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go get -d github.com/opencontainers/runc</span><br></pre></td></tr></table></figure>

<p>进入到下载的包目录（检查$ GOPATH变量），使用make进行构建和安装runc和containerd：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd ~/go/src/github.com/opencontainers/runc</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">cd ~/go/src/github.com/containerd/containerd</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>

<p>现在，将containerd.service文件复制到systemd以创建containerd的服务、启动服务并查看启动状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cp containerd.service /etc/systemd/system/</span><br><span class="line">chmod 644 /etc/systemd/system/containerd.service</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start containerd</span><br><span class="line">systemctl enable containerd</span><br><span class="line">systemctl status containerd</span><br></pre></td></tr></table></figure>

<p>差不多完成了，现在我们需要更新kubelet，将默认使用的docker改为containerd（参考<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">flag设置</a>）。我们可以通过运行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/3.2/3.2 --container-runtime=remote --container-runtime-endpoint=unix:\/\/\/run\/containerd\/containerd.sock/g&#x27; /var/lib/kubelet/kubeadm-flags.env</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果上面的命令不起作用，请直接修改kubeadm-flags.env文件。</p>
</blockquote>
<p>重启kubelet并查看服务状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start kubelet</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure>

<p>最后，uncordon节点，并查看节点信息中的Runtime已变为containerd：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl uncordon k8s-node-1</span><br><span class="line">kubectl get nodes -o wide</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/25/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/25/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/" class="post-title-link" itemprop="url">为什么Helm可以解决Kubernetes原生回滚问题？</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-25 22:15:35" itemprop="dateCreated datePublished" datetime="2020-12-25T22:15:35+00:00">2020-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题引出"><a href="#问题引出" class="headerlink" title="问题引出"></a>问题引出</h2><p>Helm是将应用程序部署到Kubernetes的绝佳工具。我们可以打包所有deployment和service等yaml文件，并使用一个简单的命令将它们部署到集群中。</p>
<p>但是Helm的另一个非常酷的功能是能够轻松升级和回滚版本（在集群中运行的Helm Chart实例的术语）的功能。</p>
<p>现在，我们可以使用kubectl进行此操作。如果我们使用<code>kubectl apply</code>升级deployment资源，则可以使用<code>kubectl rollout undo</code>来回滚该升级。这很棒！这是Kubernetes的最佳功能之一。</p>
<p>升级deployment时，将为该deployment创建一个新的replicaset，该replicaset将在一组新的Pod中运行升级后的应用程序。</p>
<p>如果使用<code>kubectl rollout undo</code>进行回滚，会删除最新replicaset中的容器，并回滚到旧replicaset的容器。</p>
<p><strong>但是这里有一个潜在的问题。如果删除旧的replicaset会怎样？</strong>如果发生这种情况，我们将无法回滚升级。好吧，我们无法使用<code>kubectl rollout undo</code>将其回滚，但是如果我们使用Helm，会发生什么？</p>
<p>让我们来看一个演示。</p>
<h2 id="Helm环境准备"><a href="#Helm环境准备" class="headerlink" title="Helm环境准备"></a>Helm环境准备</h2><p>创建一个称为testchart的Chart：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm create testchart	</span><br></pre></td></tr></table></figure>

<p>删除模板目录中所有不必要的文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ./testchart/templates/*</span><br></pre></td></tr></table></figure>

<p>创建一个deployment yaml文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment nginx \</span><br><span class="line">--image=nginx:1.17 \</span><br><span class="line">--dry-run=client \</span><br><span class="line">--output=yaml &gt; ./testchart/templates/deployment.yaml</span><br></pre></td></tr></table></figure>

<p>这将创建以下yaml并将其另存为templates目录中的deployment.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">strategy:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>创建deployment：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment nginx --image=nginx:1.17 </span><br></pre></td></tr></table></figure>

<p>为service生成yaml：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nginx \</span><br><span class="line">--type=LoadBalancer \</span><br><span class="line">--port=80 \</span><br><span class="line">--dry-run=client \</span><br><span class="line">--output=yaml &gt; ./testchart/templates/service.yaml</span><br></pre></td></tr></table></figure>

<p>这将为我们提供以下yaml并将其另存为模板目录中的service.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>删除deployment，模板化values.yaml 和deployment.yaml文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete deployment nginx</span><br><span class="line">rm ./testchart/values.yaml</span><br><span class="line">echo &quot;containerImage: nginx:1.17&quot; &gt; ./testchart/values.yaml</span><br><span class="line">sed -i &#x27;s/nginx:1.17/&#123;&#123; .Values.containerImage &#125;&#125;/g&#x27; ./testchart/templates/deployment.yaml</span><br></pre></td></tr></table></figure>

<p>最终，deployment.yaml文件如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">strategy:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> &#123;&#123; <span class="string">.Values.containerImage</span> &#125;&#125;</span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>改造后的yaml中容器镜像不再是硬编码的。它将从values.yaml文件中获取nginx:1.17的值，或者我们可以使用set标志来覆盖它（我们将在一分钟内完成）。</p>
<h2 id="Helm部署示例"><a href="#Helm部署示例" class="headerlink" title="Helm部署示例"></a>Helm部署示例</h2><p>首先，将Chart部署到Kubernetes集群中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install testchart ./testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-install-1.png" alt="helm-install-1"></p>
<p>该应用程序版本是Chart.yaml文件中设置的默认版本（尚未更新）</p>
<p>检查部署中运行的镜像版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment -o jsonpath=&#x27;&#123; .items[*].spec.template.spec.containers[*].image &#125;&#123;&quot;\n&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-history-updated.png" alt="get-container-image-1"></p>
<p>查看到的容器镜像就是Chart中values.yaml文件中定义的镜像版本。</p>
<p>现在升级Release，将默认的容器镜像值替换为set标志指定的值：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade testchart ./testchart --set containerImage=nginx:1.18</span><br></pre></td></tr></table></figure>

<p>确认版本已升级（检查版本号）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm list</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-container-image-1.png" alt="helm-upgrade-1"></p>
<p>另外，请确认Release历史：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm history testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-upgrade-1.png" alt="helm-history-updated"></p>
<p>这样我们就可以看到该Release的初始部署，然后是升级。应用版本保持不变，因为我没有更改Chart.yaml文件中的值。但是，镜像版本已更改，我们可以通过以下方式看到：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment -o jsonpath=&#x27;&#123; .items[*].spec.template.spec.containers[*].image &#125;&#123;&quot;\n&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-rollout-undo.png" alt="get-container-image-2"></p>
<p>因此，我们已经升级了在deployment中容器运行的镜像版本。</p>
<p>让我们看一下deployment的replicasets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get replicasets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-replicasets-2.png" alt="get-replicasets-1"></p>
<p>因此，我们为Helm版本创建的deployment有两个replicasets。最初的一个运行nginx v1.17，最新的一个运行nginx v1.18。</p>
<p>如果我们想使用kubectl回退升级，则可以使用（不要运行此代码！）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-replicasets-1.png" alt="kubectl-rollout-undo"></p>
<p>这里将发生的是，删除最新replicasets下的Pod，并创建旧replicasets下的Pod，将nginx回滚到v1.17。</p>
<p>但是我们不会那样做，因为我们正在使用Helm。</p>
<h2 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h2><p>继续在当前环境中获取最旧的replicasets名称，并删除它：：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">REPLICA_SET=$(kubectl get replicasets -o jsonpath=&#x27;&#123;.items[0].metadata.name &#125;&#x27; --sort-by=.metadata.creationTimestamp)</span><br><span class="line">kubectl delete replicasets $REPLICA_SET</span><br></pre></td></tr></table></figure>

<p>因此，我们现在只有一个replicasets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get replicasets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-container-image-2.png" alt="get-replicasets-2"></p>
<p>现在尝试使用<code>kubectl rollout undo</code>命令进行回滚：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-rollout-undo-2.png" alt="kubectl-rollout-undo-2"></p>
<p>失败的原因是我们删除了旧的replicasets，因此该deployment没有历史记录，可以通过以下方式查看：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout history deployment nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-rollout-history.png" alt="kubectl-rollout-history"></p>
<h2 id="使用Helm回滚"><a href="#使用Helm回滚" class="headerlink" title="使用Helm回滚"></a>使用Helm回滚</h2><p>虽然旧的replicasets被删除了，但是Helm的实现机制决定了使用Helm部署的Release会保留历史：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm history testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-history-2.png" alt="helm-history-2"></p>
<p>所以，我们可以使用Helm回滚：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm rollback testchart 1</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-rollback.png" alt="helm-rollback"></p>
<p>查看Release状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm list</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-list-rollback.png" alt="helm-list-rollback"></p>
<p>查看Release历史：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm history testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-replicasets-3.png" alt="helm-rollback-history"></p>
<p>查看replicasets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get replicasets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-rollback-history.png" alt="get-replicasets-3"></p>
<p>旧的replicasets又回来了！怎么样？</p>
<h2 id="原理探究"><a href="#原理探究" class="headerlink" title="原理探究"></a>原理探究</h2><p>让我们看一下集群中的secrets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secrets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-get-secrets.png" alt="kubectl-get-secrets"></p>
<p>可以看出，这些secrets中会存储Helm发布所有历史记录！初始版本（v1），升级（v2）和回滚（v3）。</p>
<p>让我们仔细看看v1版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.testchart.v1 -o json</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-get-secrets-2.png" alt="kubectl-get-secrets-2"></p>
<p>嗯，这个Release内容看起来很有趣。我们可以做的是对base64进行解码，然后通过<a target="_blank" rel="noopener" href="http://www.txtwizard.net/compression%E8%BF%9B%E8%A1%8C%E8%A7%A3%E5%8E%8B%E7%BC%A9%EF%BC%8C%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9C%E5%A6%82%E4%B8%8B%EF%BC%9A">http://www.txtwizard.net/compression进行解压缩，得到结果如下：</a></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">&quot;name&quot;</span><span class="string">:&quot;testchart&quot;</span>,</span><br><span class="line"><span class="attr">&quot;info&quot;:</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;first_deployed&quot;</span><span class="string">:&quot;2020-08-09T11:21:20.4665817+01:00&quot;</span>,</span><br><span class="line">        <span class="string">&quot;last_deployed&quot;</span><span class="string">:&quot;2020-08-09T11:21:20.4665817+01:00&quot;</span>,</span><br><span class="line">        <span class="string">&quot;deleted&quot;</span><span class="string">:&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span><span class="string">:&quot;Install</span> <span class="string">complete&quot;</span>,</span><br><span class="line">        <span class="string">&quot;status&quot;</span><span class="string">:&quot;superseded&quot;</span>&#125;,</span><br><span class="line">        <span class="string">&quot;chart&quot;</span><span class="string">:</span>&#123;<span class="attr">&quot;metadata&quot;:</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span><span class="string">:&quot;testchart&quot;</span>,</span><br><span class="line">        <span class="string">&quot;version&quot;</span><span class="string">:&quot;0.1.0&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span><span class="string">:&quot;A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Kubernetes&quot;</span>,</span><br><span class="line">        <span class="string">&quot;apiVersion&quot;</span><span class="string">:&quot;v2&quot;</span>,</span><br><span class="line">        <span class="string">&quot;appVersion&quot;</span><span class="string">:&quot;1.16.0&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span><span class="string">:&quot;application&quot;</span>&#125;,</span><br><span class="line">        <span class="string">&quot;lock&quot;</span><span class="string">:null</span>,</span><br><span class="line">        <span class="string">&quot;templates&quot;</span><span class="string">:</span>[</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">&quot;name&quot;:</span></span><br><span class="line">                <span class="string">&quot;templates/deployment.yaml&quot;</span>,</span><br><span class="line">                <span class="string">&quot;data&quot;</span><span class="string">:&quot;YXBpVmVyc2lvbjogYXBwcy92MQpraW5kOiBEZXBsb3ltZW50Cm1ldGFkYXRhOgogIGNyZWF0aW9uVGltZXN0YW1wOiBudWxsCiAgbGFiZWxzOgogICAgYXBwOiBuZ2lueAogIG5hbWU6IG5naW54CnNwZWM6CiAgcmVwbGljYXM6IDEKICBzZWxlY3RvcjoKICAgIG1hdGNoTGFiZWxzOgogICAgICBhcHA6IG5naW54CiAgc3RyYXRlZ3k6IHt9CiAgdGVtcGxhdGU6CiAgICBtZXRhZGF0YToKICAgICAgY3JlYXRpb25UaW1lc3RhbXA6IG51bGwKICAgICAgbGFiZWxzOgogICAgICAgIGFwcDogbmdpbngKICAgIHNwZWM6CiAgICAgIGNvbnRhaW5lcnM6CiAgICAgIC0gaW1hZ2U6IHt7IC5WYWx1ZXMuY29udGFpbmVySW1hZ2UgfX0KICAgICAgICBuYW1lOiBuZ2lueAogICAgICAgIHJlc291cmNlczoge30Kc3RhdHVzOiB7fQo=&quot;</span>&#125;,&#123;<span class="string">&quot;name&quot;</span><span class="string">:&quot;templates/service.yaml&quot;</span>,<span class="string">&quot;data&quot;</span><span class="string">:&quot;YXBpVmVyc2lvbjogdjEKa2luZDogU2VydmljZQptZXRhZGF0YToKICBjcmVhdGlvblRpbWVzdGFtcDogbnVsbAogIGxhYmVsczoKICAgIGFwcDogbmdpbngKICBuYW1lOiBuZ2lueApzcGVjOgogIHBvcnRzOgogIC0gcG9ydDogODAKICAgIHByb3RvY29sOiBUQ1AKICAgIHRhcmdldFBvcnQ6IDgwCiAgc2VsZWN0b3I6CiAgICBhcHA6IG5naW54CiAgdHlwZTogTG9hZEJhbGFuY2VyCnN0YXR1czoKICBsb2FkQmFsYW5jZXI6IHt9Cg==&quot;</span>&#125;],<span class="string">&quot;values&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;containerImage&quot;</span><span class="string">:&quot;nginx:1.17&quot;</span>&#125;,<span class="string">&quot;schema&quot;</span><span class="string">:null</span>,<span class="string">&quot;files&quot;</span><span class="string">:</span>[&#123;<span class="string">&quot;name&quot;</span><span class="string">:&quot;.helmignore&quot;</span>,<span class="string">&quot;data&quot;</span><span class="string">:&quot;IyBQYXR0ZXJucyB0byBpZ25vcmUgd2hlbiBidWlsZGluZyBwYWNrYWdlcy4KIyBUaGlzIHN1cHBvcnRzIHNoZWxsIGdsb2IgbWF0Y2hpbmcsIHJlbGF0aXZlIHBhdGggbWF0Y2hpbmcsIGFuZAojIG5lZ2F0aW9uIChwcmVmaXhlZCB3aXRoICEpLiBPbmx5IG9uZSBwYXR0ZXJuIHBlciBsaW5lLgouRFNfU3RvcmUKIyBDb21tb24gVkNTIGRpcnMKLmdpdC8KLmdpdGlnbm9yZQouYnpyLwouYnpyaWdub3JlCi5oZy8KLmhnaWdub3JlCi5zdm4vCiMgQ29tbW9uIGJhY2t1cCBmaWxlcwoqLnN3cAoqLmJhawoqLnRtcAoqLm9yaWcKKn4KIyBWYXJpb3VzIElERXMKLnByb2plY3QKLmlkZWEvCioudG1wcm9qCi52c2NvZGUvCg==&quot;</span>&#125;]&#125;,</span><br><span class="line">                <span class="string">&quot;manifest&quot;</span><span class="string">:&quot;---\n#</span> </span><br><span class="line">                    <span class="attr">Source:</span> <span class="string">testchart/templates/service.yaml\n</span></span><br><span class="line">                    <span class="attr">apiVersion:</span> <span class="string">v1\n</span></span><br><span class="line">                    <span class="attr">kind:</span> <span class="string">Service\nmetadata:\n</span>  </span><br><span class="line">                    <span class="attr">creationTimestamp:</span> <span class="literal">null</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">labels:\n</span>    </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">name:</span> <span class="string">nginx\n</span></span><br><span class="line">                    <span class="string">spec:\n</span>  </span><br><span class="line">                    <span class="string">ports:\n</span>  </span><br><span class="line">                    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span><span class="string">\n</span>    </span><br><span class="line">                    <span class="attr">protocol:</span> <span class="string">TCP\n</span>    </span><br><span class="line">                    <span class="attr">targetPort:</span> <span class="number">80</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">selector:\n</span>    </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">type:</span> <span class="string">LoadBalancer\n</span></span><br><span class="line">                    <span class="string">status:\n</span>  <span class="attr">loadBalancer:</span> &#123;&#125;<span class="string">\n---\n#</span> </span><br><span class="line">                     </span><br><span class="line">                    <span class="attr">Source:</span> <span class="string">testchart/templates/deployment.yaml\n</span></span><br><span class="line">                    <span class="attr">apiVersion:</span> <span class="string">apps/v1\n</span></span><br><span class="line">                    <span class="attr">kind:</span> <span class="string">Deployment\n</span></span><br><span class="line">                    <span class="string">metadata:\n</span>  </span><br><span class="line">                    <span class="attr">creationTimestamp:</span> <span class="literal">null</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">labels:\n</span>    </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">name:</span> <span class="string">nginx\nspec:\n</span>  </span><br><span class="line">                    <span class="attr">replicas:</span> <span class="number">1</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">selector:\n</span>    </span><br><span class="line">                    <span class="string">matchLabels:\n</span>      </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">strategy:</span> &#123;&#125;<span class="string">\n</span>  </span><br><span class="line">                    <span class="string">template:\n</span>    </span><br><span class="line">                    <span class="string">metadata:\n</span>      </span><br><span class="line">                    <span class="attr">creationTimestamp:</span> <span class="literal">null</span><span class="string">\n</span>      </span><br><span class="line">                    <span class="string">labels:\n</span>        </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>    </span><br><span class="line">                    <span class="string">spec:\n</span>      </span><br><span class="line">                    <span class="string">containers:\n</span>      </span><br><span class="line">                    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17\n</span>        </span><br><span class="line">                    <span class="attr">name:</span> <span class="string">nginx\n</span>        </span><br><span class="line">                    <span class="attr">resources:</span> &#123;&#125;<span class="string">\n</span></span><br><span class="line">                    <span class="attr">status:</span> &#123;&#125;<span class="string">\n&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;version&quot;</span><span class="string">:1</span>,</span><br><span class="line">                    <span class="string">&quot;namespace&quot;</span><span class="string">:&quot;default&quot;</span></span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>

<p>BOOM！看起来就像我们的deployment和service清单！我们可以看到最初的Helm版本中包含的所有信息（确认容器镜像为nginx:1.17）！</p>
<p>因此，通过将这些信息作为secrets存储在目标Kubernetes集群中，即使已删除了旧的replicasets，Helm也可以回滚升级！太酷了！</p>
<p>不过结果还不是很清晰，查看data字段……看起来像是加密信息。</p>
<p>让我们解密吧！这次在命令行上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.testchart.v1 -o jsonpath=&quot;&#123; .data.release &#125;&quot; | base64 -d | gunzip -c | jq &#x27;.chart.templates[].data&#x27; | tr -d &#x27;&quot;&#x27; | base64 -d</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/decode-helm-secret.png" alt="decode-helm-secret"></p>
<p>哈！这里有deployment和service的yaml文件！</p>
<p>通过使用Helm，即使已删除deployment的旧replicasets，我们也可以回滚，因为Helm将Release历史记录在secrets并存储在目标Kubernetes集群中。通过使用上面的代码，我们可以解密这些secrets并查看其中包含的信息。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/25/k8s/Decoding-A-Helm-Chart-Releases/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/25/k8s/Decoding-A-Helm-Chart-Releases/" class="post-title-link" itemprop="url">解析Helm Char Release内容</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-25 21:05:35" itemprop="dateCreated datePublished" datetime="2020-12-25T21:05:35+00:00">2020-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>如果我们在集群中安装了Helm Chart，可能会想知道Release的存储位置。</p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>让我们从一些背景开始。安装一个简单的Nginx Helm Chart：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm install --name my-release stable/nginx-ingress</span></span><br></pre></td></tr></table></figure>

<p>现在，要获取已安装Helm的详细信息，可以使用四个命令。</p>
<p><strong>helm ls</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm <span class="built_in">ls</span></span> </span><br><span class="line">NAME        REVISION	UPDATED                 	STATUS  	</span><br><span class="line">my-release  1      	    Wed Sep 12 07:41:48 2018	DEPLOYED</span><br></pre></td></tr></table></figure>

<p>通常，我们要运行的第一个命令是helm ls。执行此操作是为了了解我们的集群中当前安装了哪些Helm Chart。无论它们是否失败，<code>STATUS</code>会展示出部署结果是成功还是失败。</p>
<p><strong>helm get</strong></p>
<p>一旦获得安装Chart的名称。下一步通常是尝试更详细地了解安装了什么。<code>helm get</code>命令可以为我们提供帮助。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm get my-release</span></span><br><span class="line">REVISION: 1</span><br><span class="line">RELEASED: Thu Mar 23 15:59:14 2017</span><br><span class="line">CHART: nginx-1.0</span><br><span class="line">USER-SUPPLIED VALUES:</span><br><span class="line">foo: bar</span><br><span class="line"></span><br><span class="line">COMPUTED VALUES:</span><br><span class="line">foo: bar</span><br><span class="line">image: nginx</span><br><span class="line">imagePullPolicy: IfNotPresent</span><br><span class="line">ingress:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">**....**</span>  </span><br></pre></td></tr></table></figure>



<p><strong>helm status</strong></p>
<p>如果我们遇到任何问题，并且希望获得Chart开发人员写下的一些说明。<code>helm status</code>可以通过呈现NOTES.txt文件来帮助我们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ helm status my-release</span><br><span class="line">The nginx-ingress controller has been installed. </span><br><span class="line">Get the application URL by running these commands:</span><br><span class="line">export NODE_IP=$(kubectl --namespace &#123;&#123; .Release.Namespace &#125;&#125; get nodes -o jsonpath=&quot;&#123;.items[0].status.addresses[1].address&#125;&quot;)   </span><br><span class="line">echo &quot;Visit http://10.10.10.10:80 to access your application via HTTP.&quot;  </span><br><span class="line">echo &quot;Visit https://10.10.10.10:443 to access your application via HTTPS.&quot;</span><br></pre></td></tr></table></figure>

<p>上面的Helm状态可以通过values.yaml或–set修改。这是从NOTES.txt呈现的帮助者文本。</p>
<p><strong>helm history</strong></p>
<p>最后，我们还可以获得Chart部署的修订历史记录。当运行<code>helm upgrade</code>命令时会更新版本。假设我们要使用override.yaml覆盖某些值。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm upgrade --install my-release --values override.yaml --<span class="built_in">set</span> foo=notbar nginx</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm <span class="built_in">history</span> my-release</span></span><br><span class="line">REVISION    UPDATED                     STATUS      CHART           DESCRIPTION</span><br><span class="line">1           Thu Mar 23 15:57:40 2020    SUPERSEDED  nginx-0.4.3 Install complete</span><br><span class="line">2           Thu Mar 23 15:59:14 2020    DEPLOYED    nginx-0.4.3 Upgrade complete</span><br></pre></td></tr></table></figure>

<p>所有这些信息都存储在哪里？</p>
<ul>
<li><p>Helm v2版本，默认位置在<code>configmap</code>中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get configmap -n kube-system -l <span class="string">&quot;OWNER=TILLER&quot;</span></span></span><br><span class="line">NAME                     DATA      AGE</span><br><span class="line">my-release.v1          1         7m</span><br><span class="line">my-release.v2          1         6m</span><br></pre></td></tr></table></figure>


</li>
<li><p>Helm v3版本，默认位置在<code>secrets</code>中。<strong>强烈建议这样做</strong>，因为这些数据包含许多有关我们部署的信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get secrets -n kube-system</span></span><br><span class="line">NAME                     DATA      AGE</span><br><span class="line">my-release.v1          1         7m</span><br><span class="line">my-release.v2          1         6m</span><br><span class="line">default-token-43hfuds  1         1d</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="解析Configmap内容"><a href="#解析Configmap内容" class="headerlink" title="解析Configmap内容"></a>解析Configmap内容</h2><p>步骤1. 获取Configmap数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get configmap -n kube-system my-release.v1 -o=jsonpath=<span class="string">&#x27;&#123;.data.release&#125;&#x27;</span> &gt; release-encoded</span></span><br></pre></td></tr></table></figure>

<p>步骤2. 确保编码后的Release包含如下字符串：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">H4sIAAAAAAAC/+w6TY8cS.....</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">you should see a long block of string like above</span></span><br></pre></td></tr></table></figure>

<p>步骤3. 解析数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat release-encoded | base64 -d | gzip -cd &gt; release-decoded</span><br></pre></td></tr></table></figure>

<p>步骤4. 查看数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat release-decoded</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">you should see a whole bunch of data <span class="keyword">for</span> the chart similar to above when you did helm get.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">but also this data contains a lot more like. the actual template. Value rendered.. etc...</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">try it :) i already gave you the commands 🤠⽕😁🏃🏼‍</span></span><br></pre></td></tr></table></figure>

<p>将Chart存储在<code>configmaps</code>中的问题在于，一旦黑客进入我们的集群，它就会成为黑客的金钥匙。将其存储为<code>secrets</code>可以提供某种保护（假设我们对机密信息进行了加密）。☸️</p>
<h2 id="解析Secrets内容"><a href="#解析Secrets内容" class="headerlink" title="解析Secrets内容"></a>解析Secrets内容</h2><p>步骤1. 解析指定版本的Release所有内容（Template内容依然是编码格式）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.my-release.v1 -o jsonpath=&quot;&#123; .data.release &#125;&quot; | base64 -d | gunzip -c | jq .</span><br></pre></td></tr></table></figure>

<p>步骤2. 解析指定版本的Release中的Template内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.my-release.v1 -o jsonpath=&quot;&#123; .data.release &#125;&quot; | base64 -d | gunzip -c | jq &#x27;.chart.templates[].data&#x27; | tr -d &#x27;&quot;&#x27; | base64 -d</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：该方法同样适用于解析Configmap内容。</p>
</blockquote>
<h2 id="一些建议"><a href="#一些建议" class="headerlink" title="一些建议"></a>一些建议</h2><p>还有一些保护<code>tiller</code>的方法，例如使用https连接。但是，按照设计，<code>tiller</code>仍然需要大量特权才能在我们的集群中运行。并且仍然违反<strong>最小特权原则</strong>。<strong>我的建议是尽快移至helm3</strong>。</p>
<p>Helm3完全删除了tiller，而是依靠本地计算机的身份验证在群集中工作。默认情况下，它还将Chart数据作为<code>secrets</code>存储在群集中。<strong>Helm2将在2020年12月停止提供安全修复程序</strong>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/11/12/k8s/Kubernetes-Production-Best-Practices/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/12/k8s/Kubernetes-Production-Best-Practices/" class="post-title-link" itemprop="url">Kubernetes生产环境最佳实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-12 22:10:44" itemprop="dateCreated datePublished" datetime="2020-11-12T22:10:44+00:00">2020-11-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本文提供了在Kubernetes上部署安全，可伸缩和弹性服务的最佳实践。内容开源在<a target="_blank" rel="noopener" href="https://github.com/learnk8s/kubernetes-production-best-practices">github仓库</a>。如果有缺少或不足之处，欢迎提issue。</p>
<h2 id="Part1-应用开发"><a href="#Part1-应用开发" class="headerlink" title="Part1 应用开发"></a>Part1 应用开发</h2><h3 id="健康检测"><a href="#健康检测" class="headerlink" title="健康检测"></a><strong>健康检测</strong></h3><ul>
<li><strong>为容器配置Readiness探针</strong><ul>
<li>如果未设置readiness探针，则kubelet会假定该应用程序已准备就绪，可以在容器启动后立即接收流量。</li>
<li>如果容器需要2分钟才能启动，则这2分钟内对容器的所有请求将失败。</li>
</ul>
</li>
<li><strong>发生致命错误时允许容器崩溃</strong><ul>
<li><p>如果应用程序遇到不可恢复的错误，则应使其崩溃。</p>
</li>
<li><p>此类不可恢复的错误的示例是：</p>
<ol>
<li>未捕获的异常</li>
<li>代码中的错字（动态语言）</li>
<li>无法加载标头或依赖项</li>
</ol>
</li>
<li><p>上述错误不应发信号通知Liveness探针失败。相反，应该立即退出该进程，并让kubelet重新启动容器。</p>
</li>
</ul>
</li>
<li><strong>配置被动的Liveness探针</strong><ul>
<li>Liveness探针旨在容器卡住时重新启动容器。</li>
<li>考虑以下情形：如果应用程序正在处理无限循环，则无法退出。当该进程消耗100％的CPU时，将没有时间回复（其他）Readiness探针检查，并且最终将其从服务中删除。但是，该Pod仍被注册为当前Deployment的活动副本。如果没有Liveness探针，它将保持运行状态，但与服务分离。换句话说，该进程不仅不处理任何请求，而且也在消耗资源。</li>
<li>请注意，不应该使用Liveness探针来处理应用程序中的致命错误，并要求Kubernetes重新启动应用程序。相反，应该让应用程序崩溃。仅在过程无响应的情况下，才应将“liveness”探针用作恢复机制。</li>
</ul>
</li>
<li><strong>两个探针的值不同</strong><ul>
<li>当“liveness”和“readiness”探针指向相同的端点时，探针的作用会合并在一起。当应用程序发出信号表明尚未准备就绪或尚待运行时，kubelet会将容器与服务分离并同时将其删除。这时可能会注意到连接断开，因为容器没有足够的时间耗尽当前连接或处理传入的连接。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://freecontent.manning.com/handling-client-requests-properly-with-kubernetes/">handling-client-requests-properly-with-kubernetes&#x2F;</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>请注意，readiness和liveness没有默认值。</p>
</blockquote>
<h3 id="应用独立"><a href="#应用独立" class="headerlink" title="应用独立"></a><strong>应用独立</strong></h3><ul>
<li><p><strong>Readiness探针是独立的</strong></p>
<ul>
<li>Readiness不包括对服务的依赖性，例如：数据库、数据库的迁移、API、第三方服务（<a target="_blank" rel="noopener" href="https://blog.colinbreck.com/kubernetes-liveness-and-readiness-probes-how-to-avoid-shooting-yourself-in-the-foot/#shootingyourselfinthefootwithreadinessprobes">反例</a>）</li>
</ul>
</li>
<li><p><strong>应用重试连接到依赖服务</strong></p>
<ul>
<li>应用启动时，它不应该因为数据库等依赖项尚未就绪而崩溃。相反，应用程序应继续尝试重新连接数据库，直到成功为止。</li>
<li>Kubernetes希望可以以任何顺序启动应用程序。当确保应用程序可以重新连接到诸如数据库之类的依赖项时，便知道可以提供更强大，更灵活的服务。</li>
</ul>
</li>
</ul>
<h3 id="友好关闭"><a href="#友好关闭" class="headerlink" title="友好关闭"></a><strong>友好关闭</strong></h3><ul>
<li><strong>应用程序未通过SIGTERM关闭，但可以正常终止连接</strong><ul>
<li>可能需要一些时间才能感知到诸如kube-proxy或Ingress控制器之类的组件endpoint更改。因此，尽管标记为已终止，流量仍可能流向Pod。</li>
<li>应用程序应停止在所有剩余连接上接受新请求，并在耗尽传出队列后将其关闭。</li>
<li>如果想回顾endpoint在群集中的传播方式，请参考：<a target="_blank" rel="noopener" href="https://freecontent.manning.com/handling-client-requests-properly-with-kubernetes/">handling-client-requests-properly-with-kubernetes&#x2F;</a></li>
</ul>
</li>
<li><strong>应用程序仍在宽限期内处理传入的请求</strong><ul>
<li>可能要考虑使用容器生命周期事件（例如preStop处理程序）来自定义Pod删除之前发生的情况。</li>
</ul>
</li>
<li><strong>Dockerfile中的CMD将SIGTERM转发到进程</strong><ul>
<li>通过在应用中捕获SIGTERM信号，可以在Pod即将终止时收到通知。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://pracucci.com/graceful-shutdown-of-kubernetes-pods.html">graceful-shutdown-of-kubernetes-pods</a></li>
</ul>
</li>
<li><strong>关闭所有空闲的keep-alive套接字</strong><ul>
<li>如果应用程序调用未关闭TCP连接（例如使用TCP保持活动状态或连接池），它将连接到一个Pod，而不使用该服务中的其他Pod。</li>
<li>不应该突然终止长期存在的连接。相反，应该在关闭应用程序之前终止它们。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="http://dillonbuchanan.com/programming/gracefully-shutting-down-a-nodejs-http-server/">gracefully-shutting-down-a-nodejs-http-server</a></li>
</ul>
</li>
</ul>
<h3 id="失败容忍"><a href="#失败容忍" class="headerlink" title="失败容忍"></a><strong>失败容忍</strong></h3><ul>
<li><strong>为Deployment部署运行多个副本</strong><ul>
<li>切勿单独运行一个Pod类型的资源，而是考虑将Pod作为Deployment，DaemonSet，ReplicaSet或StatefulSet的一部分进行部署。</li>
<li>示例参考：<a target="_blank" rel="noopener" href="https://cloudmark.github.io/Node-Management-In-GKE/#replicas">Node-Management-In-GKE</a></li>
</ul>
</li>
<li><strong>避免将Pod放置在单个节点中</strong><ul>
<li>即使运行Pod的多个副本，也无法保证丢失节点不会影响服务。</li>
<li>应该将反关联性规则应用于部署，以便Pod分布在群集的所有节点中。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinit">inter-pod-affinity-and-anti-affinit</a></li>
</ul>
</li>
<li><strong>设定Pod中断预算</strong><ul>
<li>drain节点后，该节点上的所有Pod都将被删除并重新安排。</li>
<li>为了保护Deployment免受可能同时摧毁多个Pod的意外事件的影响，可以定义Pod中断预算。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">pod-disruptions</a></li>
</ul>
</li>
</ul>
<h3 id="资源使用"><a href="#资源使用" class="headerlink" title="资源使用"></a><strong>资源使用</strong></h3><ul>
<li><strong>为所有容器设置内存限制和请求</strong><ul>
<li>资源限制用于限制容器可以使用多少CPU和内存，并使用containerSpec的resources属性设置。</li>
<li>调度程序将这些用作度量标准之一，以确定哪个节点最适合当前Pod。</li>
<li>根据调度程序，没有内存限制的容器的内存利用率为零。</li>
<li>如果可调度在任何节点上的Pod数量不受限制，则会导致资源超负荷使用并可能导致节点（和kubelet）崩溃。</li>
<li>如果容器进程超出内存限制，则该进程将终止。由于CPU是可压缩的资源，因此如果容器超出限制，则将限制该过程。即使它可以使用当时可用的某些CPU。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-memory-6b41e9a955f9">understanding-resource-limits-in-kubernetes-memory</a>，<a target="_blank" rel="noopener" href="https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-cpu-time-9eff74d3161b">understanding-resource-limits-in-kubernetes-cpu</a></li>
</ul>
</li>
<li><strong>将CPU请求设置为1个CPU或以下</strong><ul>
<li>除非有计算密集型作业，否则建议将请求设置为1个CPU或更低.</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xjpHggHKm78">YouTube视频</a></li>
</ul>
</li>
<li><strong>禁用CPU限制—除非有很好的用例</strong><ul>
<li>CPU 资源以 <em>CPU</em> 单位度量。</li>
<li>cpu：1表示每秒1个CPU单位。如果有1个线程，则每秒消耗的CPU时间不能超过1秒。如果有2个线程，则可以在0.5秒内消耗1个CPU单位。8个线程可以在0.125秒内消耗1个CPU单位。此后，请求将受到限制。</li>
<li>如果不确定最佳应用设置，最好不要设置CPU限制。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-cpu-time-9eff74d3161b">understanding-resource-limits-in-kubernetes-cpu</a></li>
</ul>
</li>
<li><strong>命名空间具有LimitRange</strong><ul>
<li>如果我们认为可能忘记设置内存和CPU限制，则应考虑使用LimitRange对象为当前名称空间中部署的容器定义标准大小。</li>
<li>设置方法参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/policy/limit-range/">limit-range</a></li>
</ul>
</li>
<li><strong>为Pod设置适当的服务质量（QoS）</strong><ul>
<li>当节点进入过量使用状态（即使用过多资源）时，Kubernetes会尝试驱逐该节点中的某些Pod。</li>
<li>Kubernetes根据定义明确的逻辑对Pod进行排名和逐出。</li>
<li>设置方法参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/">quality-service-pod</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>请注意，如果不确定如何配置正确的CPU或内存限制，则可以使用Kubernetes中的Vertical Pod Autoscaler。自动缩放器会分析应用并给出建议的值。</p>
</blockquote>
<h3 id="标签资源"><a href="#标签资源" class="headerlink" title="标签资源"></a><strong>标签资源</strong></h3><ul>
<li><strong>定义技术标签</strong></li>
<li><strong>定义业务标签</strong></li>
<li><strong>定义安全标签</strong></li>
</ul>
<h3 id="日志配置"><a href="#日志配置" class="headerlink" title="日志配置"></a><strong>日志配置</strong></h3><ul>
<li><strong>将应用程序日志记录到stdout和stderr</strong><ul>
<li>有两种日志记录策略：被动和主动。使用被动日志记录的应用程序不了解日志记录基础结构，而是将消息记录到标准输出中。</li>
<li>在主动日志记录中，该应用程序与中间聚合器建立网络连接，将数据发送到第三方日志记录服务，或直接写入数据库或索引。主动日志记录被视为反模式，应避免使用它。</li>
<li>最佳实践参考：<a target="_blank" rel="noopener" href="https://12factor.net/logs">logs</a></li>
</ul>
</li>
<li><strong>避免使用sidecar记录日志（如果可以的话）</strong><ul>
<li>如果希望将日志转换应用于具有非标准日志事件模型的应用程序，则可能需要使用sidecar容器。</li>
<li>使用Sidecar容器，可以在将日志条目运送到其他地方之前对其进行规范化。例如，先将Apache日志转换为Logstash JSON格式，然后再将其发送到日志基础结构。但是，如果可以控制应用程序，则可以从一开始就输出正确的格式。这样可以节省为集群中的每个Pod运行额外的容器的时间。</li>
</ul>
</li>
</ul>
<h3 id="Pod扩缩容"><a href="#Pod扩缩容" class="headerlink" title="Pod扩缩容"></a><strong>Pod扩缩容</strong></h3><ul>
<li><strong>容器在其本地文件系统中不存储任何状态</strong><ul>
<li>容器可以访问本地文件系统，用户可能会想使用它来持久化数据。</li>
<li>但是，将持久性数据存储在容器的本地文件系统中会阻止Pod进行水平缩放（即通过添加或删除Pod的副本）。</li>
<li>这是因为，通过使用本地文件系统，每个容器都维护自己的“状态”，这意味着Pod副本的状态可能会随时间而变化。从用户的角度来看，这会导致行为不一致（例如，当请求命中一个Pod时，一条特定的用户信息可用，但当请求命中另一个Pod时，则不可用）。</li>
<li>相反，任何持久性信息都应保存在Pod外部的集中位置。例如，在集群中的PersistentVolume中，或者在集群外部的某些存储服务中甚至更好。</li>
</ul>
</li>
<li><strong>对具有可变使用模式的应用程序使用HPA</strong><ul>
<li>HPA是内置的Kubernetes功能，可监视应用程序并根据当前使用情况自动添加或删除Pod副本。</li>
<li>配置HPA可使应用在任何流量情况下（包括意外的高峰）保持可用并响应。</li>
<li>配置HPA时必须创建一个HorizontalPodAutoscaler资源，该资源定义要监视的应用程序的度量。</li>
<li>HPA可以监视内置资源指标（Pod的CPU和内存使用情况）或自定义指标。对于自定义指标，还负责收集和公开这些指标，例如，可以使用Prometheus和Prometheus Adapter进行此操作。</li>
</ul>
</li>
<li><strong>Vertical Pod Autoscaler仍处于Beta版，请勿使用</strong><ul>
<li>类似于HPA，还有VPA。</li>
<li>VPA可以自动调整Pod的资源请求和限制，以便当Pod需要更多资源时可以获取它们（增加&#x2F;减少单个Pod的资源称为垂直缩放，与水平缩放相对）。</li>
<li>这对于缩放无法水平缩放的应用程序很有用。</li>
<li>但是，HPA当前处于beta版本，它具有一些已知的局限性（例如，通过更改其资源要求来扩展Pod，要求终止Pod并重新启动它）。</li>
<li>考虑到这些限制以及Kubernetes上大多数应用程序都可以水平扩展的事实，建议不要在生产环境中使用VPA（至少要等到稳定的版本才能使用）。</li>
</ul>
</li>
<li><strong>如果工作负载差异很大，请使用群集自动伸缩放器</strong><ul>
<li>群集自动缩放器是“自动缩放器”的另一种类型（HAP和VPA除外）。</li>
<li>群集自动缩放器可以通过添加或删除工作节点来自动缩放群集的大小。</li>
<li>当由于现有工作节点上的资源不足而无法调度Pod时，会进行放大操作。在这种情况下，Cluster Autoscaler将创建一个新的工作节点，以便可以调度Pod。同样，当现有工作节点的利用率较低时，群集自动伸缩程序可以通过从一个工作节点中逐出所有工作负载并将其删除来进行缩减。</li>
<li>对于高度可变的工作负载，例如当Pods的数量可能在短时间内成倍增长然后返回到先前的值时，使用Cluster Autoscaler是有意义的。在这种情况下，群集自动伸缩器可以满足需求高峰，而不会通过过度配置工作节点来浪费资源。</li>
<li>但是，如果工作负载变化不大，则可能不值得设置Cluster Autoscaler，因为它可能永远不会触发。如果工作负载缓慢且单调地增长，则足以监视现有工作节点的利用率并在达到临界值时手动添加其他工作节点。</li>
</ul>
</li>
</ul>
<h3 id="配置原则"><a href="#配置原则" class="headerlink" title="配置原则"></a><strong>配置原则</strong></h3><ul>
<li><strong>外部化所有配置</strong><ul>
<li>配置应在应用程序代码之外进行维护。</li>
<li>这有几个好处。首先，更改配置不需要重新编译应用程序。其次，可以在应用程序运行时更新配置。第三，相同的代码可以在不同的环境中使用。</li>
<li>在Kubernetes中，可以将配置保存在ConfigMaps中，然后可以在将卷作为环境变量传入时将其安装到容器中。</li>
<li>在ConfigMap中仅保存非敏感配置。对于敏感信息（例如凭据），请使用Secret资源。</li>
</ul>
</li>
<li><strong>将Secrets作为卷而不是环境变量安装</strong><ul>
<li>Secret资源的内容应作为卷装入容器中，而不应作为环境变量传递。</li>
<li>这是为了防止秘密值出现在用于启动容器的命令中，该命令可能由不应该访问秘密值的人员看到。</li>
</ul>
</li>
</ul>
<h2 id="Part2-集群管理"><a href="#Part2-集群管理" class="headerlink" title="Part2 集群管理"></a>Part2 集群管理</h2><h3 id="命名空间限制"><a href="#命名空间限制" class="headerlink" title="命名空间限制"></a><strong>命名空间限制</strong></h3><ul>
<li><strong>命名空间具有LimitRange</strong><ul>
<li>没有限制的容器可能导致与其他容器的资源争用以及计算资源的消耗。</li>
<li>Kubernetes具有两个限制资源利用的功能：ResourceQuota和LimitRange。</li>
<li>使用LimitRange对象，可以定义资源请求的默认值以及名称空间内单个容器的限制。</li>
<li>在该命名空间内创建的，未明确指定请求和限制值的任何容器都将分配为默认值。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">resource-quotas</a></li>
</ul>
</li>
<li><strong>命名空间具有ResourceQuotas</strong><ul>
<li>使用ResourceQuotas，可以限制命名空间内所有容器的总资源消耗。</li>
<li>定义命名空间的资源配额会限制属于该名称空间的所有容器可以消耗的CPU，内存或存储资源的总量。</li>
<li>还可以为其他Kubernetes对象设置配额，例如当前名称空间中的Pod数量。</li>
<li>如果存在他人使用群集并创建20000 ConfigMap，则可以使用LimitRange来防止这种情况。</li>
</ul>
</li>
</ul>
<h3 id="Pod安全策略"><a href="#Pod安全策略" class="headerlink" title="Pod安全策略"></a><strong>Pod安全策略</strong></h3><ul>
<li><p><strong>启用Pod安全策略</strong></p>
<ul>
<li>例如，可以使用Kubernetes Pod安全策略来限制：<ol>
<li>访问主机进程或网络名称空间；</li>
<li>运行特权容器容器；</li>
<li>运行的用户；</li>
<li>访问主机文件系统；</li>
<li>Linux功能，Seccomp或SELinux配置文件</li>
</ol>
</li>
<li>选择正确的策略取决于集群的性质。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://resources.whitesourcesoftware.com/blog-whitesource/kubernetes-pod-security-policy">kubernetes-pod-security-policy</a></li>
</ul>
</li>
<li><p><strong>禁用特权容器</strong></p>
<ul>
<li>在Pod中，容器可以以“特权”模式运行，并且对主机系统上的资源的访问几乎不受限制。</li>
<li>尽管在某些特定的用例中，必须具有这种级别的访问权限，但总的来说，让容器执行此操作存在安全风险。</li>
<li>特权Pod的有效使用案例包括在节点上使用硬件，例如GPU。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">security-context</a></li>
</ul>
</li>
<li><p><strong>在容器中使用只读文件系统</strong></p>
<ul>
<li>在容器中运行只读文件系统会强制容器不可变。</li>
<li>这不仅减轻了一些旧的（且有风险的）做法（例如热修补），而且还帮助防止了恶意进程在容器内存储或操作数据的风险。</li>
<li>使用只读文件系统运行容器听起来可能很简单，但是可能会带来一些复杂性。</li>
<li>如果需要写日志或将文件存储在临时文件夹中怎么办？</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@axbaretto/running-docker-containers-securely-in-production-98b8104ef68">running-docker-containers-securely-in-production</a></li>
</ul>
</li>
<li><p><strong>防止容器以root身份运行</strong></p>
<ul>
<li>在容器中运行的进程与主机上的任何其他进程没有什么不同，只不过它有一小部分元数据声明它在容器中。</li>
<li>因此，容器中的根与主机上的根（uid 0）相同。</li>
<li>如果用户设法脱离了以root用户身份在容器中运行的应用程序，则他们可能能够使用同一root用户获得对主机的访问权限。</li>
<li>配置容器以使用非特权用户是防止特权升级攻击的最佳方法。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b">processes-in-containers-should-not-run-as-root</a></li>
</ul>
</li>
<li><p><strong>限制capabilities</strong></p>
<ul>
<li><p>Linux capabilities使进程能够执行许多特权操作，其中只有root用户默认可以执行。</p>
</li>
<li><p>例如，CAP_CHOWN允许进程“对文件UID和GID进行任意更改”。</p>
</li>
<li><p>即使进程不是以root身份运行，进程也有可能通过提升特权来使用那些类似root的功能。</p>
</li>
<li><p>换句话说，如果不想受到损害，则应仅启用所需的功能。</p>
</li>
<li><p>但是应该启用什么功能？为什么？以下两篇文章探讨了有关Linux内核功能的理论和最佳实践：</p>
<p><a target="_blank" rel="noopener" href="https://blog.container-solutions.com/linux-capabilities-why-they-exist-and-how-they-work">Linux Capabilities: Why They Exist and How They Work</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.container-solutions.com/linux-capabilities-in-practice">Linux Capabilities In Practice</a></p>
</li>
</ul>
</li>
<li><p><strong>防止特权升级</strong></p>
<ul>
<li>应该在关闭特权升级的情况下运行容器，以防止使用setuid或setgid二进制文件提升特权。</li>
</ul>
</li>
</ul>
<h3 id="网络策略"><a href="#网络策略" class="headerlink" title="网络策略"></a><strong>网络策略</strong></h3><ul>
<li><strong>启用网络策略</strong><ul>
<li>Kubernetes网络策略指定Pod组的访问权限，就像云中的安全组用于控制对VM实例的访问一样。</li>
<li>换句话说，它在Kubernetes集群上运行的Pod之间创建了防火墙。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://ahmet.im/blog/kubernetes-network-policy/">Securing Kubernetes Cluster Networking</a></li>
</ul>
</li>
<li><strong>每个命名空间中都有一个保守的NetworkPolicy</strong><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ahmetb/kubernetes-network-policy-recipes">存储库</a>包含Kubernetes网络策略的各种用例和示例YAML文件。</li>
<li>如果想知道如何丢弃&#x2F;限制在Kubernetes上运行的应用程序的流量，请阅读<a target="_blank" rel="noopener" href="https://github.com/ahmetb/kubernetes-network-policy-recipes">how to drop&#x2F;restrict traffic to applications running on Kubernetes</a>。</li>
</ul>
</li>
</ul>
<h3 id="RBAC策略"><a href="#RBAC策略" class="headerlink" title="RBAC策略"></a><strong>RBAC策略</strong></h3><ul>
<li><strong>禁用默认服务帐户的自动挂载RBAC策略</strong><ul>
<li>请注意，默认的ServiceAccount将自动安装到所有Pod的文件系统中，详见<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server">use-the-default-service-account-to-access-the-api-server</a></li>
<li>可能要禁用它并提供更详细的策略。</li>
</ul>
</li>
<li><strong>设置为所需的最少特权</strong><ul>
<li>寻找有关如何设置RBAC规则的好的建议是一项挑战。</li>
<li>在<a target="_blank" rel="noopener" href="https://thenewstack.io/three-realistic-approaches-to-kubernetes-rbac/">Kubernetes RBAC的3种现实方法</a>中，可以找到三种实用场景和有关如何入门的实用建议。</li>
</ul>
</li>
<li><strong>RBAC策略是精细的，不能共享</strong><ul>
<li>Zalando有一个简洁的策略来定义角色和ServiceAccounts。</li>
<li>首先，他们描述他们的要求：<ol>
<li>用户应该能够部署，但不应允许他们查看如“secret”这类资源</li>
<li>管理员应拥有对所有资源的完全访问权限</li>
<li>默认情况下，应用程序不应获得对Kubernetes API的写访问权限</li>
<li>对于某些用途，可以有Kubernetes API写权限。</li>
</ol>
</li>
<li>四个要求转化为五个单独的角色：<ol>
<li>ReadOnly</li>
<li>PowerUser</li>
<li>Operator</li>
<li>Controller</li>
<li>Admin</li>
</ol>
</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes-on-aws.readthedocs.io/en/latest/dev-guide/arch/access-control/adr-004-roles-and-service-accounts.html">access-control-roles-and-service-accounts</a></li>
</ul>
</li>
</ul>
<h3 id="自定义策略"><a href="#自定义策略" class="headerlink" title="自定义策略"></a><strong>自定义策略</strong></h3><ul>
<li><strong>只允许从已知registry部署容器</strong><ul>
<li>可能要考虑的最常见的自定义策略之一是限制可以在群集中部署的镜像。</li>
<li><a target="_blank" rel="noopener" href="https://blog.openpolicyagent.org/securing-the-kubernetes-api-with-open-policy-agent-ce93af0552c3#3c6e">参考文档</a>说明了如何使用开放策略代理来限制未批准的镜像。</li>
</ul>
</li>
<li><strong>强制Ingress主机名唯一</strong><ul>
<li>用户创建Ingress清单时，可以使用其中的任何主机名。</li>
<li>但是，可能希望阻止用户多次使用相同的主机名并互相覆盖。</li>
<li>Open Policy Agent的<a target="_blank" rel="noopener" href="https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/#4-define-a-policy-and-load-it-into-opa-via-kubernetes">官方文档</a>包含有关如何在validation Webhook中检查Ingress资源的教程。</li>
</ul>
</li>
<li><strong>仅在Ingress主机名中使用批准的域名</strong><ul>
<li>用户创建Ingress清单时，可以使用其中的任何主机名。</li>
<li>但是，可能希望阻止用户使用无效的主机名。</li>
<li>Open Policy Agent的<a target="_blank" rel="noopener" href="https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/#4-define-a-policy-and-load-it-into-opa-via-kubernetes">官方文档</a>包含有关如何在validation Webhook中检查Ingress资源的教程。</li>
</ul>
</li>
</ul>
<h2 id="Part3-集群配置"><a href="#Part3-集群配置" class="headerlink" title="Part3 集群配置"></a>Part3 集群配置</h2><blockquote>
<p>该部分还在进行中。如果对这部分内容有意见，欢迎提issue。</p>
</blockquote>
<h3 id="集群要求"><a href="#集群要求" class="headerlink" title="集群要求"></a><strong>集群要求</strong></h3><ul>
<li><p><strong>集群通过CIS基准测试</strong></p>
<ul>
<li>互联网安全中心提供了一些准则和基准测试，以确保代码安全的最佳做法</li>
<li>他们还维护了Kubernetes的基准，可以从<a target="_blank" rel="noopener" href="https://www.cisecurity.org/benchmark/kubernetes/">官方网站</a>上下载该基准。</li>
<li>虽然可以阅读冗长的指南并手动检查集群是否符合要求，但更简单的方法是下载并执行<a target="_blank" rel="noopener" href="https://github.com/aquasecurity/kube-bench">kube-bench</a>。</li>
<li>kube-bench是一个工具，用于自动执行CIS Kubernetes基准测试并报告集群中的错误配置。</li>
</ul>
<blockquote>
<p>请注意，无法使用kube-bench检查托管集群（例如GKE，EKS和AKS）的主节点。主节点由云提供商控制。</p>
</blockquote>
</li>
<li><p><strong>禁用云提供商的元数据API</strong></p>
<ul>
<li>云平台（AWS，Azure，GCE等）通常将本地元数据服务公开给实例。</li>
<li>默认情况下，实例上运行的Pod可以访问这些API，并且可以包含该节点的云凭据或诸如kubelet凭据之类的置备数据。</li>
<li>这些凭据可用于在群集内升级或升级到同一帐户下的其他云服务。</li>
</ul>
</li>
<li><p><strong>限制对Alpha或Beta功能的访问</strong></p>
<ul>
<li>Alpha和Beta Kubernetes功能正在积极开发中，可能会存在限制或错误，从而导致安全漏洞。</li>
<li>始终评估Alpha或Beta功能可能提供的价值，以防对安全状况造成潜在风险。</li>
<li>如有疑问，请禁用不使用的功能。</li>
</ul>
</li>
</ul>
<h3 id="身份认证"><a href="#身份认证" class="headerlink" title="身份认证"></a><strong>身份认证</strong></h3><ul>
<li><p><strong>使用OpenID（OIDC）令牌作为用户身份验证策略</strong></p>
<ul>
<li>Kubernetes支持各种身份验证方法，包括OpenID Connect（OIDC）。</li>
<li>OpenID Connect允许单点登录（SSO）（例如Google身份）连接到Kubernetes集群和其他开发工具。</li>
<li>无需单独记住或管理凭据。</li>
<li>可能有多个群集连接到同一OpenID提供程序。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://thenewstack.io/kubernetes-single-sign-one-less-identity/">kubernetes-single-sign-one-less-identity</a></li>
</ul>
</li>
<li><p><strong>ServiceAccount令牌仅适用于应用程序和控制器</strong></p>
<ul>
<li>ServiceAccount不应用于尝试与Kubernetes群集进行交互的最终用户，但对于在Kubernetes上运行的应用程序和工作负载，它们是首选的身份验证策略。</li>
</ul>
</li>
</ul>
<h3 id="日志设置"><a href="#日志设置" class="headerlink" title="日志设置"></a><strong>日志设置</strong></h3><ul>
<li><strong>有一个日志保留和归档策略</strong><ul>
<li>应该保留30-45天的历史日志。</li>
</ul>
</li>
<li><strong>从节点，控制平面，审计中收集日志</strong><ul>
<li>从哪些地方收集日志：<ol>
<li>节点 (kubelet, container runtime)</li>
<li>控制平面 (API server, scheduler, controller manager)</li>
<li>Kubernetes审计 (all requests to the API server)</li>
</ol>
</li>
<li>应该收集什么：<ol>
<li>应用名称。从元数据标签中检索。</li>
<li>应用程序实例。从元数据标签中检索。</li>
<li>应用程序版本。从元数据标签中检索。</li>
<li>集群ID。从Kubernetes集群检索。</li>
<li>容器名称。从Kubernetes API检索。</li>
<li>运行此容器的群集节点。从Kubernetes集群检索。</li>
<li>运行容器的Pod名称。从Kubernetes集群检索。</li>
<li>命名空间。从Kubernetes集群检索。</li>
</ol>
</li>
</ul>
</li>
<li><strong>在每个节点上最好有一个守护程序来收集日志，而不是sidecar</strong><ul>
<li>应用程序日志应输出到标准输出，而不是文件。</li>
<li>每个节点上的守护程序可以从容器运行时收集日志（如果记录到文件，则可能需要每个pod的sidecar容<strong>器）。</strong></li>
</ul>
</li>
<li><strong>提供日志聚合工具</strong><ul>
<li>使用日志聚合工具，例如EFK技术栈（Elasticsearch，Fluentd，Kibana），DataDog，Sumo Logic，Sysdig，GCP Stackdriver，Azure Monitor，AWS CloudWatch。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/10/21/docker/Create-Tag-Retention-Rules/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/21/docker/Create-Tag-Retention-Rules/" class="post-title-link" itemprop="url">Harbor中如何创建tag保留规则</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-21 20:26:07" itemprop="dateCreated datePublished" datetime="2020-10-21T20:26:07+00:00">2020-10-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="创建Tag保留规则"><a href="#创建Tag保留规则" class="headerlink" title="创建Tag保留规则"></a>创建Tag保留规则</h2><p>一个repository可以快速积累大量镜像tag，在给定时间之后或一旦它们被后续镜像构建取代后，可能不需要许多镜像tag。这些多余的tag显然会消耗大量的存储容量。作为Harbor系统管理员，可以定义规则来管理给定repository中要保留多少个tag，或将某些tag保留多长时间。</p>
<h2 id="Tag保留规则如何工作"><a href="#Tag保留规则如何工作" class="headerlink" title="Tag保留规则如何工作"></a>Tag保留规则如何工作</h2><p>在repositories上而不是projects上定义tag保留规则（<em>repository属于project内的概念</em>）。在定义保留规则时，这可以提供更大的粒度。顾名思义，当我们为repositories定义保留规则时，也即在定义要保留的tag。我们没有定义规则来显式删除tag，而是当设置规则时，repositories中任何未标识为可保留的标记都将被丢弃。</p>
<p>tag保留规则具有3个按顺序应用的过滤器，如下表所述。</p>
<table>
<thead>
<tr>
<th align="left">Order</th>
<th align="left">Filter</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">First</td>
<td align="left">一个或多个repository</td>
<td align="left">标识要在其上应用规则的一个或多个repository。可以标识具有特定名称或名称片段的repository，或者不具有该名称或名称片段的repository。允许使用通配符（例如* repo，repo *和**）。首先使用repository filter以标记要对其应用保留规则的repository。根据标签标准，将识别出的repository指定用于进一步匹配。在此阶段，对没有指定的repository不采取任何措施。</td>
</tr>
<tr>
<td align="left">Second</td>
<td align="left">保留数量</td>
<td align="left">通过指定最大数量的标签或指定最大保留标签的时间来设置要保留的标签。</td>
</tr>
<tr>
<td align="left">Third</td>
<td align="left">要保留的标签</td>
<td align="left">标识要应用规则的一个或多个标签。可以标识具有特定名称或名称片段的标签，或者不具有该名称或名称片段的标签。允许使用通配符（例如* tag，tag *和**）。</td>
</tr>
</tbody></table>
<p>有关如何应用**通配符的信息，请参见<a target="_blank" rel="noopener" href="https://github.com/bmatcuk/doublestar#patterns%E3%80%82">https://github.com/bmatcuk/doublestar#patterns。</a></p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h3><ul>
<li>在一个project中有5个repositories，repositories A到E。<ul>
<li>repository A具有100个镜像tag，所有这些镜像tag均已在上周有pull操作。</li>
<li>repository B到E每个都有6个镜像，上个月都没有pull操作。</li>
</ul>
</li>
<li>将repositories过滤器设置为**，这意味着包括了project中的所有repositories。</li>
<li>设置保留策略，以在每个repositories中保留最近提取的10个映像。</li>
<li>将标签过滤器设置为**，这意味着包括repositories中的所有标签。</li>
</ul>
<p>在此示例中，规则在repository A中保留了10个最近有pull操作的镜像，并且在repository B至E中的每一个中都保留了所有6个镜像。因此，project中总共保留了34个镜像tag。换句话说，该规则不会将repository A到E中的所有镜像都视为单个池，然后从中选择10个最新镜像。因此，即使repository A中的第11至第100个标签比repository B至E中的任何标签相比都有pull操作，也将保留repository B至E中的所有标签，因为每个repository中的标签少于10个。</p>
<h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h3><p>本示例使用与示例1相同的project和repositories，但设置了保留策略以保留每个repository中最近7天内有pull操作的镜像。</p>
<p>在这种情况下，保留了repository A中的所有镜像，因为它们是最近7天内有pull操作的。repository B到E中的任何镜像都不会保留，因为它们在上周都没有发生pull操作。在此示例中，保留了100个镜像，而示例1中则保留了34个镜像。</p>
<h2 id="Tag保留规则和原生Docker-Tag删除问题"><a href="#Tag保留规则和原生Docker-Tag删除问题" class="headerlink" title="Tag保留规则和原生Docker Tag删除问题"></a>Tag保留规则和原生Docker Tag删除问题</h2><p><strong>警告</strong>：由于本机Docker tag删除行为，当前的保留策略实施存在问题。如果有多个tag引用相同的SHA摘要，并且如果这些tag的子集被配置的保留策略标记为要删除，则所有其余tag也将被删除。这违反了保留策略，因此在这种情况下，所有tag都将保留。在以后的更新版本中将解决此问题，以便tag保留策略可以删除tag而不删除摘要和其他共享tag。</p>
<p>例如，我们有以下tag，这些tag根据其推送时间列出，并且它们都引用相同的SHA摘要：</p>
<ul>
<li><code>harbor-1.8</code>, pushed 8&#x2F;14&#x2F;2019 12:00am</li>
<li><code>harbor-release</code>, pushed 8&#x2F;14&#x2F;2019 03:00am</li>
<li><code>harbor-nightly</code>, pushed 8&#x2F;14&#x2F;2019 06:00am</li>
<li><code>harbor-latest</code>, pushed 8&#x2F;14&#x2F;2019 09:00am</li>
</ul>
<p>如果配置了保留策略，以保留与Harbor- *匹配的两个最新标记，以便删除Harbor-rc和Harbor-latest。但是，由于所有tag都引用相同的SHA摘要，因此此策略还将删除标签Harbor-1.8和Harbor-release，因此将保留所有标签。（时间和删除的tag有点对不上）</p>
<h2 id="在一个Repository上合并规则"><a href="#在一个Repository上合并规则" class="headerlink" title="在一个Repository上合并规则"></a>在一个Repository上合并规则</h2><p>每个project最多可以定义15条规则。我们可以将多个规则应用于一个repository或一组repositories。在将多个规则应用于repository 时，它们将使用OR逻辑而不是AND逻辑来应用。这样，就不会在给定的repository 上优先应用规则。规则在后台同时运行，每个规则的结果集在运行结束时合并。</p>
<h3 id="Example-3"><a href="#Example-3" class="headerlink" title="Example 3"></a>Example 3</h3><p>本示例使用与示例1和2相同的project和repositories，但是设置了两个规则：</p>
<ul>
<li>规则1：保留每个repository中最近7天内pull操作的所有镜像。</li>
<li>规则2：每个repository中最多保留10个镜像。</li>
</ul>
<p>对于repository A，规则1保留所有镜像，因为它们都是在上周发生pull操作的。规则2保留最近发生pull操作的10个镜像。因此，由于这两个规则是通过OR关系应用的，所有100个镜像都保留在repository A中。</p>
<p>对于repositories B-E，规则1将保留0个镜像，因为上周未发生pull操作。规则2将保留所有6个镜像，因为6 &lt;10。因此，由于这两个规则以OR关系应用，对于repositories B-E，每个repository将保留所有6个图像。</p>
<p>在此示例中，所有镜像均被保留。</p>
<h3 id="Example-4"><a href="#Example-4" class="headerlink" title="Example 4"></a>Example 4</h3><p>本示例使用与先前示例不同的repository。</p>
<ul>
<li><p>包含12个tag的repository：</p>
<table>
<thead>
<tr>
<th align="left">Production</th>
<th align="left">Release Candidate</th>
<th align="left">Release</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>2.1-your_repo-prod</code></td>
<td align="left"><code>2.1-your_repo-rc</code></td>
<td align="left"><code>2.1-your_repo-release</code></td>
</tr>
<tr>
<td align="left"><code>2.2-your_repo-prod</code></td>
<td align="left"><code>2.2-your_repo-rc</code></td>
<td align="left"><code>2.2-your_repo-release</code></td>
</tr>
<tr>
<td align="left"><code>3.1-your_repo-prod</code></td>
<td align="left"><code>3.1-your_repo-rc</code></td>
<td align="left"><code>3.1-your_repo-release</code></td>
</tr>
<tr>
<td align="left"><code>4.4-your_repo-prod</code></td>
<td align="left"><code>4.4-your_repo-rc</code></td>
<td align="left"><code>4.4-your_repo-release</code></td>
</tr>
</tbody></table>
</li>
<li><p>在此repository上定义了3个tag保留规则：</p>
<ul>
<li><p>保留以2开头的10个最近发生pull操作的镜像tag。</p>
</li>
<li><p>保留以-prod结尾的10个最近发生pull操作的镜像tag。</p>
</li>
<li><p>保留所有不包含2.1-your_repo-prod的tag。</p>
</li>
</ul>
</li>
</ul>
<p>在此示例中，规则将应用于以下7个tag（与预期不符，官方收到反馈后已修改）：</p>
<ul>
<li><code>2.1-your_repo-rc</code></li>
<li><code>2.1-your_repo-release</code></li>
<li><code>2.2-your_repo-prod</code></li>
<li><code>2.2-your_repo-rc</code></li>
<li><code>2.2-your_repo-release</code></li>
<li><code>3.1-your_repo-prod</code></li>
<li><code>4.4-your_repo-prod</code></li>
</ul>
<h2 id="Tag保留规则如何与项目配额搭配使用"><a href="#Tag保留规则如何与项目配额搭配使用" class="headerlink" title="Tag保留规则如何与项目配额搭配使用"></a>Tag保留规则如何与项目配额搭配使用</h2><p>Harbor系统管理员可以设置一个project可以包含的tag数量及其可以使用的存储量的最大值。有关project配额的信息，请参阅<a target="_blank" rel="noopener" href="https://goharbor.io/docs/1.10/administration/configure-project-quotas/">配置project配额</a>。</p>
<p>如果在project上设置配额，则不能超过该配额。即使设置的保留规则超过配额，配额也将应用于project。换句话说，不能使用保留规则来绕过配额。</p>
<h2 id="配置Tag保留规则实例"><a href="#配置Tag保留规则实例" class="headerlink" title="配置Tag保留规则实例"></a>配置Tag保留规则实例</h2><ol>
<li><p>使用至少具有项目管理员特权的帐户登录到Harbor界面。</p>
</li>
<li><p>转到”project”，选择一个project，然后选择tag保留。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention1.png" alt="tag-retention"></p>
</li>
<li><p>单击”添加规则”以添加规则。</p>
</li>
<li><p>在“repositories”下拉菜单中，选择匹配或排除。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention3.png" alt="tag-retention"></p>
</li>
<li><p>在“repositories”文本框中，标识要在其上应用规则的repository。</p>
<p>可以通过输入以下信息来定义要在哪些repositories上应用规则：</p>
</li>
</ol>
<ul>
<li><p>repository名称，例如my_repo_1。</p>
</li>
<li><p>以逗号分隔的repository名称列表，例如my_repo_1，my_repo_2，your_repo_3。</p>
</li>
<li><p>带通配符的部分repository名称，例如my _ <em>，</em> _ 3或*<em>repo</em>*。</p>
</li>
<li><p>**将规则应用于project中的所有repositories。</p>
<p> 如果选择<strong>匹配</strong>，则规则将应用于标识的repository。如果选择<strong>排除</strong>，则该规则将应用于project中除已标识的repositories之外的所有repositories。</p>
</li>
</ul>
<ol start="6">
<li><p>在“按镜像或天数计数”下拉菜单中，定义要保留的tag数量或保留的时间。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention4.png" alt="tag-retention"></p>
</li>
</ol>
<table>
<thead>
<tr>
<th align="left">Option</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>retain the most recently pushed # images</strong></td>
<td align="left">输入要保留的最大镜像个数，保留最近发生push操作的镜像。不考虑镜像的时间。</td>
</tr>
<tr>
<td align="left"><strong>retain the most recently pulled # images</strong></td>
<td align="left">输入要保留的最大镜像个数，保留最近发生pull操作的镜像。不考虑镜像的时间。</td>
</tr>
<tr>
<td align="left"><strong>retain the images pushed within the last # days</strong></td>
<td align="left">输入保留镜像的天数，仅保留在此期间发生push操作的镜像。不考虑镜像数量。</td>
</tr>
<tr>
<td align="left"><strong>retain the images pulled within the last # days</strong></td>
<td align="left">输入保留镜像的天数，仅保留在此期间发生pull操作的镜像。不考虑镜像数量。</td>
</tr>
<tr>
<td align="left"><strong>retain always</strong></td>
<td align="left">始终保留此规则标识的镜像。</td>
</tr>
</tbody></table>
<ol start="7">
<li><p>在”tag”下拉菜单中，选择匹配或排除。  </p>
</li>
<li><p>在“标签”文本框中，标识要在其上应用规则的tag。</p>
<p>可以通过输入以下信息来定义要在其上应用规则的tag：</p>
</li>
</ol>
<ul>
<li>tag名称，例如my_tag_1。</li>
<li>tag名称的逗号分隔列表，例如my_tag_1，my_tag_2，your_tag_3。</li>
<li>带通配符的部分tag名称，例如my _ <em>，</em> _ 3或* <em>tag</em> *。</li>
<li>**将规则应用于project中的所有tag。</li>
</ul>
<ol start="9">
<li><p>单击”添加”以保存规则。</p>
</li>
<li><p>（可选）单击“添加规则”以添加更多规则，每个project最多15条。</p>
</li>
<li><p>（可选）在“计划”下，单击“编辑”，然后选择运行规则的频率。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention2.png" alt="tag-retention"></p>
<p>如果选择“自定义”，请输入cron job命令以配置规则。</p>
<p>注意：如果定义多个规则，则计划将应用于所有规则。不能配置不同的规则在不同的时间运行。</p>
</li>
<li><p>单击“模拟运行”以测试定义的一个或多个规则。</p>
</li>
<li><p>单击“立即运行”以立即运行规则。</p>
</li>
</ol>
<p><strong>警告</strong>：运行规则后，将无法还原它。强烈建议先执行模拟运行，然后再运行规则。</p>
<p>要修改现有规则，请使用规则旁边的操作下拉菜单来禁用，编辑或删除该规则。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention5.png" alt="tag-retention"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/08/24/k8s/Determine-best-networking-option/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/24/k8s/Determine-best-networking-option/" class="post-title-link" itemprop="url">Calico中的网络模式选择最佳实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-24 22:09:22" itemprop="dateCreated datePublished" datetime="2020-08-24T22:09:22+00:00">2020-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Big-picture"><a href="#Big-picture" class="headerlink" title="Big picture"></a>Big picture</h3><p>了解Calico支持的各种网络选项，以便可以根据需要选择最佳选项。</p>
<h3 id="Value"><a href="#Value" class="headerlink" title="Value"></a>Value</h3><p>Calico灵活的模块化体系结构支持广泛的部署选项，因此可以根据自己的特定环境和需求选择最佳的网络方案。这包括在BGP和非BGP的情况下，以underlying或overlay模式与各种CNI和IPAM插件以及基础网络类型一起运行的能力。</p>
<h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><p>如果想完全了解可用的网络选项，我们建议确保自己熟悉并理解以下概念。如果希望跳过学习并直接获得选择和建议，则可以跳至“网络选项”。</p>
<h4 id="Kubernetes网络基础知识"><a href="#Kubernetes网络基础知识" class="headerlink" title="Kubernetes网络基础知识"></a>Kubernetes网络基础知识</h4><p>Kubernetes网络模型定义了一个“扁平”网络，其中：</p>
<ul>
<li>每个Pod都有自己的IP地址。	</li>
<li>无需NAT，任何节点上的Pod均可与所有其他节点上的所有Pod通信。</li>
</ul>
<p>这将创建一个干净的，向后兼容的模型，从端口分配，命名，服务发现，负载平衡，应用程序配置和迁移的角度来看，可以将Pod像VM或物理主机一样对待。可以使用网络策略来定义网络分段，以将流量限制在这些基本网络功能内。</p>
<p>在此模型中，可以灵活地支持不同的网络方案和环境。确切地如何实现网络的详细信息取决于所使用的CNI，网络和云提供商插件的组合。</p>
<h4 id="CNI插件"><a href="#CNI插件" class="headerlink" title="CNI插件"></a>CNI插件</h4><p>CNI（容器网络接口）是一个标准API，允许将不同的网络实现插入Kubernetes。每当创建或销毁Pod时，Kubernetes都会调用API。CNI插件有两种类型：</p>
<ul>
<li>CNI网络插件：负责向Kubernetes Pod网络中添加Pod或从Kubernetes Pod网络中删除Pod。这包括创建&#x2F;删除每个Pod的网络接口，以及将其连接&#x2F;断开与其他网络实现的连接。</li>
<li>CNI IPAM插件：负责在Pod创建或删除时分配和释放Pod的IP地址。根据插件的不同，这可能包括为每个节点分配一个或多个IP地址（CIDR）范围，或从底层公共云网络获取IP地址以分配给Pod。</li>
</ul>
<h4 id="云提供商集成"><a href="#云提供商集成" class="headerlink" title="云提供商集成"></a>云提供商集成</h4><p>Kubernetes云提供商集成是特定于云的控制器，可以配置基础云网络以帮助提供Kuberenetes网络。根据云提供商的不同，这可能包括自动将路由编程到基础云网络中，以便它本机知道如何路由Pod流量。</p>
<h4 id="Kubenet"><a href="#Kubenet" class="headerlink" title="Kubenet"></a>Kubenet</h4><p>Kubenet是Kubernetes中内置的一个非常基本的网络插件。它没有实现跨节点通信或网络策略。它通常与云提供商集成一起使用，后者在云提供商网络中设置路由以在节点之间或在单节点环境中进行通信。Kubenet与Calico不兼容。</p>
<h4 id="Overlay网络"><a href="#Overlay网络" class="headerlink" title="Overlay网络"></a>Overlay网络</h4><p>overlay网络是位于另一个网络之上的网络。在Kubernetes的上下文中，overlay网络可用于处理基础网络顶部节点之间的Pod到Pod流量，这些节点不知道Pod IP地址或哪些Pod在哪些节点上运行。overlay网络通过将基础网络不知道如何处理（例如使用Pod IP地址）的网络数据包封装在基础网络确实知道如何处理的外部数据包（例如节点IP地址）中。用于封装的两种常见网络协议是VXLAN和IP-in-IP。</p>
<p>使用overlay网络的主要优点是它减少了对基础网络的依赖性。例如，可以在几乎任何基础网络之上运行VXLAN，而无需与基础网络集成或对其进行任何更改。</p>
<p>使用overlay网络的主要缺点是：</p>
<ul>
<li>对性能有轻微影响。封装数据包的过程占用少量CPU，并且数据包中用于编码封装（VXLAN或IP-in-IP标头）所需的额外字节减少了可以发送的内部数据包的最大大小，这意味着需要为相同数量的总数据发送更多数据包。</li>
<li>Pod IP地址无法在集群外部路由。</li>
</ul>
<h4 id="跨子网Overlay网络"><a href="#跨子网Overlay网络" class="headerlink" title="跨子网Overlay网络"></a>跨子网Overlay网络</h4><p>除了标准的VXLAN或IP-in-IP overlay外，Calico还支持VXLAN和IP-in-IP的“cross-subnet”模式。在这种模式下，在每个子网中，基础网络充当L2网络。在单个子网内发送的数据包不进行封装，因此可以获得非overlay网络的性能。跨子网发送的数据包像普通的overlay网络一样被封装，从而减少了对基础网络的依赖（无需与基础网络集成或对其进行任何更改）。</p>
<p>就像使用标准overlay网络一样，基础网络也不知道Pod IP地址，并且Pod IP地址无法在集群外部路由。</p>
<h4 id="Pod-IP路由到集群外部的能力"><a href="#Pod-IP路由到集群外部的能力" class="headerlink" title="Pod IP路由到集群外部的能力"></a>Pod IP路由到集群外部的能力</h4><p>不同的Kubernetes网络实现的一个重要区别特征是Pod IP地址是否可在整个较宽网络的集群外部路由。</p>
<p><strong>不可路由</strong>	</p>
<p>如果Pod IP地址无法在集群外部路由，则当Pod尝试建立与集群外部IP地址的网络连接时，Kubernetes将使用一种称为SNAT（源网络地址转换）的技术来更改源IP从Pod的IP地址到托管Pod的节点的IP地址。连接上的所有返回数据包都会自动映射回Pod IP地址。因此，Pod不知道发生了SNAT，连接的目的地将节点视为连接的源，而底层的更广泛的网络不会看到Pod IP地址。</p>
<p>对于相反方向的连接，其中集群外部的某些设备需要连接到Pod，这只能通过Kubernetes service或Kubernetes ingress来完成。集群之外的任何人都无法直接连接到Pod IP地址，因为更广泛的网络不知道如何将数据包路由到Pod IP地址。</p>
<p><strong>可路由</strong></p>
<p>如果Pod IP地址可以在集群外部路由，则Pod可以不使用SNAT即可连接到外部世界，并且集群外部可以直接连接到Pod，而无需通过Kubernetes service或Kubernetes ingress。</p>
<p>Pod IP可路由到集群外部的优点是：</p>
<ul>
<li>避免将SNAT用于出站连接对于与现有更广泛的安全要求进行集成可能至关重要。它还可以简化操作日志的调试和易懂性。</li>
<li>如果有专门的工作负载，这意味着某些Pod需要直接访问而不需要通过Kubernetes service或Kubernetes ingress，那么可路由的Pod IP在操作上可能更简单。</li>
</ul>
<p>Pod IP地址可路由到集群外的主要缺点是，Pod IP在整个网络中必须是唯一的。因此，例如，如果运行多个群集，则需要为每个群集中的Pod使用不同的IP地址范围（CIDR）。当大规模运行时，或者如果现有其他企业对IP地址空间有大量重要需求，这又可能导致IP地址范围耗尽的挑战。</p>
<p><strong>决定可路由性的因素是什么？</strong></p>
<p>如果集群使用overlay网络，则Pod IP通常无法路由到集群外。</p>
<p>如果集群不使用overlay网络，那么Pod IP是否路由到集群外取决于所用的CNI插件，云提供商集成或与物理网络（对于本地）BGP对等连接。</p>
<h4 id="BGP"><a href="#BGP" class="headerlink" title="BGP"></a>BGP</h4><p>BGP（边界网关协议）是用于跨网络共享路由的基于标准的网络协议。它是互联网的基本组成部分之一，具有出色的扩展特性。</p>
<p>Calico内置了对BGP的支持。在本地部署中，这使Calico可以与物理网络（通常连接到Top或Rack路由器）建立对等关系以交换路由，从而形成一个none-overlay网络，其中Pod IP地址可以在更广泛的网络中路由，就像附加的任何其他工作负载一样到网络。</p>
<h3 id="关于Calico网络"><a href="#关于Calico网络" class="headerlink" title="关于Calico网络"></a>关于Calico网络</h3><p>Calico网络灵活的模块化架构包括以下内容。</p>
<p><strong>Calico CNI网络插件</strong></p>
<p>Calico CNI网络插件使用一对虚拟以太网设备（一对）将Pod连接到主机网络名称空间的L3路由。这种L3架构避免了许多其他Kubernetes网络解决方案中附加的L2桥不必要的复杂性和性能开销。</p>
<p><strong>Calico CNI IPAM插件</strong></p>
<p>Calico CNI IPAM插件为一个或多个可配置IP地址范围之外的Pod分配IP地址，并根据需要为每个节点动态分配IP块。与许多其他CNI IPAM插件（包括在许多网络解决方案中使用的主机本地IPAM插件）相比，具有更有效的IP地址空间使用。</p>
<p><strong>Overlay网络模式</strong></p>
<p>Calico可以提供VXLAN或IP-in-IP网络，包括cross-subnet模式。</p>
<p><strong>Non-overlay网络模式</strong></p>
<p>Calico可以提供在任何基础L2网络之上运行的non-overlay网络，或者是具有适当的云提供商集成的公共云网络或支持BGP的L3网络（通常是具有标准Top-of-Rack路由器）。</p>
<p><strong>网络策略</strong></p>
<p>Calico的网络策略执行引擎实现了Kubernetes网络策略的全部功能，以及Calico Network Policy的扩展功能。这可以与Calico的内置网络模式或任何其他Calico兼容的网络插件和云提供商集成结合使用。</p>
<h3 id="与Calico兼容的CNI插件和云提供商集成"><a href="#与Calico兼容的CNI插件和云提供商集成" class="headerlink" title="与Calico兼容的CNI插件和云提供商集成"></a>与Calico兼容的CNI插件和云提供商集成</h3><p>除Calico CNI插件和内置网络模式外，Calico还与许多第三方CNI插件和云提供商集成兼容。</p>
<p><strong>Amazon VPC CNI</strong></p>
<p>Amazon VPC CNI插件从基础AWS VPC分配Pod IP，并使用AWS弹性网络接口提供VPC本机Pod网络（可在集群外部路由的Pod IP）。它是Amazon EKS中使用的默认网络，并与Calico一起用于网络策略实施。</p>
<p><strong>Azure CNI</strong></p>
<p>Azure CNI插件从基础Azure VNET分配Pod IP，将Azure虚拟网络配置为提供VNET本机Pod网络（可在群集外部路由的Pod IP）。它是Microsoft AKS中使用的默认网络，可与Calico一起执行网络策略。</p>
<p><strong>Azure cloud provider</strong></p>
<p>Azure云提供商集成可以用作Azure CNI插件的替代方法。它使用host-local IPAM插件分配Pod IP，并使用相应的路由对基础Azure VNET子网进行编程。Pod IP仅可在VNET子网内路由（这通常意味着它们无法路由到群集外部）。</p>
<p><strong>Google cloud provider</strong></p>
<p>Google云提供商集成使用host-local IPAM插件分配Pod IP，并对Google Cloud网络Alias IP范围进行编程，以在Google Cloud上提供VPC本机Pod网络（可在集群外部路由的Pod IP）。它是Google Kubernetes Engine（GKE）的默认设置，并带有Calico来执行网络策略。</p>
<p><strong>Host local IPAM</strong></p>
<p>host-local IPAM插件是常用的IP地址管理CNI插件，它为每个节点分配固定大小的IP地址范围（CIDR），然后从该范围内分配Pod IP地址。默认地址范围大小是256个IP地址（a&#x2F;24），其中两个IP地址是为特殊目的保留的，未分配给Pod。host-local IPAM插件的简单性使其易于理解，但与Calico CNI IPAM插件相比，其IP地址空间使用效率较低。</p>
<p><strong>Flannel</strong></p>
<p>Flannel使用从host-local IPAM插件获得的静态CIDR路由pod间的通信。Flannel提供了许多网络后端，但主要与VXLAN后端一起使用。Calico CNI和Calico网络策略可以与flannel和host-local IPAM插件结合使用，以提供具有策略实施功能的VXLAN网络。这种组合有时称为“Canal”。</p>
<blockquote>
<p>注意：Calico现在内置了对VXLAN的支持，为了简化起见，我们通常建议优先使用Calico + Flannel组合。</p>
</blockquote>
<h3 id="网络选择"><a href="#网络选择" class="headerlink" title="网络选择"></a>网络选择</h3><h4 id="本地"><a href="#本地" class="headerlink" title="本地"></a><strong>本地</strong></h4><p>Calico本地部署最常见的网络设置是non-overlay模式，该模式使用BGP与物理网络（通常是机架路由器的顶部）对等，以使Pod IP可在集群外部路由。（当然，可以根据需要配置其余的本地部署网络，以限制群集外的Pod IP路由的范围。）此设置提供了丰富的Calico高级功能，包括公告Kubernetes serviceIP的能力（cluster IPs or external IPs），以及在Pod，名称空间或节点级别控制IP地址管理的能力，以支持与现有企业网络和安全要求集成的各种可能性。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>No</td>
<td>BGP</td>
</tr>
</tbody></table>
<p>如果不能将BGP对等连接到物理网络，并且群集在单个L2网络中，则还可以运行non-overlay模式，而Calico只能在群集中的节点之间对等BGP。即使这不是严格的overlay网络，也无法在集群外部路由Pod IP，因为基础网络没有Pod IP的路由。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>No</td>
<td>BGP</td>
</tr>
</tbody></table>
<p>或者，可以在VXLAN或IP-in-IP模式下运行Calico，并使用cross-subnet模式来优化每个L2子网内的性能。</p>
<p>推荐方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>替代方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>IPIP</td>
<td>BGP</td>
</tr>
</tbody></table>
<h4 id="AWS"><a href="#AWS" class="headerlink" title="AWS"></a>AWS</h4><p>如果希望在集群外部可路由Pod IP地址，则必须使用Amazon VPC CNI插件。这是EKS的默认网络模式，并使用Calico的网络策略。Pod IP地址是从基础VPC分配的，每个节点的Pod的最大数量取决于实例类型。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>AWS</td>
<td>AWS</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果希望避免依赖特定的云提供商，或者由于IP地址范围耗尽的挑战，或者如果Amazon VPC CNI插件每个节点支持的最大Pod数量不足以从基础VPC分配Pod IP，则存在问题。根据需求，我们建议使用Calico的overlay + cross-subnet模式。Pod IP将无法在集群外部路由，但是可以在不依赖基础云网络的情况下将集群扩展到Kubernetes的极限。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>在这个简短的视频中，可以了解有关AWS上的Kubernetes Networking的更多信息，包括上述每个选项的工作原理。<a target="_blank" rel="noopener" href="https://www.projectcalico.org/everything-you-need-to-know-about-kubernetes-pod-networking-on-aws/">Everything you need to know about Kubernetes networking on AWS</a>。</p>
<h4 id="Azure"><a href="#Azure" class="headerlink" title="Azure"></a>Azure</h4><p>如果希望在群集外部可以路由Pod IP地址，则必须使用Azure CNI插件。这由AKS和Calico进行网络策略支持。Pod IP地址是从基础VNET分配的。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Azure</td>
<td>Azure</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果要使用AKS，但由于IP地址范围耗尽的问题而无法从基础VNET分配Pod IP，则可以将Calico与Azure云提供商集成一起使用。它使用host-local IPAM为每个节点分配&#x2F;24地址段，并为这些&#x2F;24地址段在群集的基础VNET子网中编程路由。在群集&#x2F;VNET子网外部无法路由Pod IP，因此如果需要，可以在多个群集中使用相同的Pod IP地址范围（CIDR）。</p>
<blockquote>
<p>注意：在某些AKS文档中将其称为kubenet + Calico，但实际上是带有Azure云提供程序的Calico CNI，并且不使用kubenet插件。</p>
</blockquote>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Host Local</td>
<td>Calico</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果不使用AKS，而是希望避免依赖于特定的云提供商，或者由于IP地址范围耗尽的问题而无法从基础VNET分配Pod IP，那么我们建议使用Calico的overlay + cross-subnet模式。Pod IP将无法在集群外部路由，但是可以在不依赖基础云网络的情况下将集群扩展到Kubernetes的极限。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>可以在此短视频中了解有关Azure上Kubernetes Networking的更多信息，包括上述每个选项的工作原理：<a target="_blank" rel="noopener" href="https://www.projectcalico.org/everything-you-need-to-know-about-kubernetes-pod-networking-on-azure/">Everything you need to know about Kubernetes networking on Azure</a></p>
<h4 id="Google-Cloud"><a href="#Google-Cloud" class="headerlink" title="Google Cloud"></a>Google Cloud</h4><p>如果想在集群外部路由Pod IP地址，则必须将Google云提供商集成与host-local IPAM CNI插件结合使用。GKE和Calico都为网络策略提供了支持。从基础VPC分配Pod IP地址，并自动将相应的Alias IP地址分配给节点。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Host Local</td>
<td>Calico</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果希望避免依赖特定的云提供商，或者由于IP地址范围耗尽的挑战而无法从基础VPC分配Pod IP，那么我们建议使用Calico的overlay模式。由于Google云网络是纯L3网络，因此不支持cross-subnet模式。Pod IP将无法在集群外部路由，但是可以在不依赖基础云网络的情况下将集群扩展到Kubernetes的极限。</p>
<p>推荐方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>替代方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>IPIP</td>
<td>BGP</td>
</tr>
</tbody></table>
<p>可以在此短片中了解有关Google云上的Kubernetes Networking的更多信息，包括上述每个选项的工作原理：<a target="_blank" rel="noopener" href="https://www.projectcalico.org/everything-you-need-to-know-about-kubernetes-pod-networking-on-google-cloud/">Everything you need to know about Kubernetes networking on Google cloud</a></p>
<h4 id="IBM-Cloud"><a href="#IBM-Cloud" class="headerlink" title="IBM Cloud"></a>IBM Cloud</h4><p>如果使用的是IBM Cloud，则建议使用IKS，该产品具有内置Calico的功能，可提供cross-subnet +IPIP模式的网络模式。除了为Pod提供网络策略外，IKS还使用Calico网络策略来保护群集中的主机节点。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>IPIP</td>
<td>BGP</td>
</tr>
</tbody></table>
<h4 id="Anywhere"><a href="#Anywhere" class="headerlink" title="Anywhere"></a>Anywhere</h4><p>上面的环境列表显然并不详尽。理解本指南中的概念和解释有助于确定适合的环境。如果仍然不确定，则可以通过Calico用户的Slack或Discourse论坛寻求建议。记住，如果要使用，而不想担心各种选项，则可以在几乎任何环境中以VXLAN + overlay模式运行Calico。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/30/linux/Intro-to-BGP-with-BIRD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/30/linux/Intro-to-BGP-with-BIRD/" class="post-title-link" itemprop="url">BGP路由Bird介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-30 22:58:22" itemprop="dateCreated datePublished" datetime="2020-06-30T22:58:22+00:00">2020-06-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>边界网关协议（BGP）是互联网涉及的核心技术之一，它使网络能够相互通信。了解如何使用此工具来定义网络拓扑，不仅可以让我们更好地了解互联网络，还可以将这种鲁棒性应用到自己的网络。</p>
<p>在本教程结束时，我们将熟悉BGP的核心概念，并能够把相关的术语传达给其他人。此外，我们还将学会使用BIRD的用户界面建立对等会话并开始发布路由。</p>
<p>本文使用docker容器实现这一目标。为了完成本教程，需要确保已安装<code>docker</code>和<code>docker-compose</code>。</p>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>首先，需要克隆bird_examples_docker项目。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/ncatelli/bird_examples_docker.git</span></span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash"><span class="built_in">cd</span> bird_examples_docker</span></span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose up -d</span>	</span><br></pre></td></tr></table></figure>

<p>上述命令将创建三个容器（<code>peer1</code>，<code>peer2</code>和<code>peer3</code>），所有这些容器均已安装BIRD并已建立对等会话。如果还不知道这意味着什么，请不要担心，我们将在设置好BGP并准备就绪后对其进行介绍。</p>
<p>首先连接到peer1并检查所有设置是否正确。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose <span class="built_in">exec</span> peer1 bash</span></span><br><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:03    </span><br><span class="line">device1  Device   master   up     02:36:03    </span><br><span class="line">direct1  Direct   master   up     02:36:03    </span><br><span class="line">peer2    BGP      master   up     02:36:08    Established   </span><br><span class="line">peer3    BGP      master   up     02:36:07    Established    	</span><br></pre></td></tr></table></figure>

<p>如果发现<code>peer2</code>和<code>peer3</code>已经显示<code>Established</code>，则说明一切正常，我们已准备就绪。在开始使用之前，将简要介绍BGP的工作原理。</p>
<h2 id="原理概述"><a href="#原理概述" class="headerlink" title="原理概述"></a>原理概述</h2><p>边界网关协议（BGP）是一种外部网关协议，用于在自治系统之间交换路由信息。自治系统（AS）是路由前缀和策略的组织单位。这些AS由唯一的16位（后来扩展到32位）自治系统编号（ASN）标识。例如，Facebook的ASN为32934或通常显示为AS32934。BGP的强大之处在于其在成千上万个分散式AS之间传递路由协议和策略的能力。</p>
<p>互联网以及许多其他网络由相互之间进行通信的许多自治系统组成。对等会话促进了这种通信，该会话允许两个AS交换策略，路由和链接状态。所有这些信息都在两个BGP守护程序之间交换，这两个守护程序在TCP的179端口上进行侦听。</p>
<p>虽然BGP被认为是用于在Internet上的大型组织之间进行路由的外部网关协议，但它也可以在AS中使用，以使网络工程师能够控制其内部网络的拓扑。这是eBGP和iBGP术语的来源。iBGP将是本教程其余部分的重点。现在，我们将开始使用BIRD及其交互式命令行工具<code>birdc</code>尝试这些对等会话。</p>
<h3 id="BIRD简介"><a href="#BIRD简介" class="headerlink" title="BIRD简介"></a>BIRD简介</h3><p>BIRD是功能齐全的路由守护程序，它支持许多不同的路由协议，包括BGP。BIRD提供了一种简单的配置格式和命令行，用于与会话进行交互。BIRD还内置了对IPv4和IPv6的支持，以及与这两种协议一起使用的相应工具。</p>
<h3 id="检查BGP会话"><a href="#检查BGP会话" class="headerlink" title="检查BGP会话"></a><strong>检查BGP会话</strong></h3><p>与我们验证是否正确配置了docker环境的方式类似，我们可以通过运行以下命令查看正在运行的会话：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:02    </span><br><span class="line">device1  Device   master   up     02:36:02    </span><br><span class="line">direct1  Direct   master   up     02:36:02    </span><br><span class="line">peer2    BGP      master   up     02:36:07    Established   </span><br><span class="line">peer3    BGP      master   up     02:36:06    Established         	</span><br></pre></td></tr></table></figure>

<p>这给了我们很多信息。但是，让我们关注最后两个条目，<code>peer2</code>和<code>peer3</code>。我们可以看到它们都是BGP协议，并且info字段显示已经<code>Established</code>。这些条目中的每一个都对应于<code>peer1</code>与<code>peer2</code>和<code>peer3</code>打开的BGP会话。为了演示这些值与正在运行的会话之间的关系，让我们在peer2上停止Bird服务。在新的终端窗口中，运行以下命令来停止<code>peer2</code>，模拟网络故障。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose stop peer2</span></span><br><span class="line">Stopping bird_examples_peer2_1 ... done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:02    </span><br><span class="line">device1  Device   master   up     02:36:02    </span><br><span class="line">direct1  Direct   master   up     02:36:02    </span><br><span class="line">peer2    BGP      master   start  02:43:38    Connect       Socket: Connection closed</span><br><span class="line">peer3    BGP      master   up     02:36:06    Established  </span><br></pre></td></tr></table></figure>

<p>通过重新启动<code>peer2</code>，BIRD应该重新启动，并且随后应重新建立对等会话。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose start peer2</span></span><br><span class="line">Starting peer2 ... done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:02    </span><br><span class="line">device1  Device   master   up     02:36:02    </span><br><span class="line">direct1  Direct   master   up     02:36:02    </span><br><span class="line">peer2    BGP      master   up     02:46:29    Established   </span><br><span class="line">peer3    BGP      master   up     02:36:06    Established    </span><br></pre></td></tr></table></figure>

<p>通过停止<code>peer2</code>上的<code>bird</code>守护程序，我们使端口179上的TCP连接在<code>peer1</code>和<code>peer2</code>之间关闭。这样做会将我们的对等会话从<code>Established</code>更改为<code>Connect</code>。这两个状态对应于许多BGP状态中的两个，但是出于本教程的考虑，我们将仅关注<code>Established</code>，并将所有其他值视为未建立。对于那些更好奇的人，可以在Wikipedia上有关<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol#Finite-state_machines">BGP</a>的文章中找到有关会话状态的更多信息。</p>
<h3 id="配置BGP会话"><a href="#配置BGP会话" class="headerlink" title="配置BGP会话"></a><strong>配置BGP会话</strong></h3><p>尽管现在知道了如何检查会话是否已经建立，但了解这些会话的配置也很重要。为此，我们需要深入研究bird配置文件。让我们看一下<code>peer1</code>上的&#x2F;etc&#x2F;bird下的配置文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:~# cat /etc/bird/bird.conf</span><br><span class="line">router id 10.0.0.10;</span><br><span class="line"></span><br><span class="line">protocol kernel &#123;</span><br><span class="line">  metric 0;</span><br><span class="line">  import none;</span><br><span class="line">  learn;</span><br><span class="line">  export all;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol device &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol direct &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol bgp peer2 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.0.11 as 64513;</span><br><span class="line">  import all;</span><br><span class="line">  export all;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol bgp peer3 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.100.11 as 64514;</span><br><span class="line">  import all;</span><br><span class="line">  export all;</span><br></pre></td></tr></table></figure>

<p>我们可以看到建立这些初始会话所需的配置非常少。为了更深入地了解这项工作的真正作用，我们将专注于一个特定块：<code>bgp peer2</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">protocol bgp peer2 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.0.11 as 64513;</span><br><span class="line">  import all;</span><br><span class="line">  export none;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在本教程的前面，我们讨论了eBGP和iBGP之间的区别以及大型AS如何使用唯一的ASN标识自己。但是，一小部分可用的ASN已保留给专用iBGP使用。这个范围是<code>64512-65534</code>。知道了这一点，我们可以看到我们已经将私有范围中的ASN分配给了<code>peer2</code>，<code>peer1</code>被分配了ASN 64512。</p>
<p>查看下一条语句，我们可以看到具有IP和附加AS的邻居语句。该IP对应于我们尝试与之建立会话的主机或BGP术语中的邻居，而64513对应于我们分配给<code>peer2</code>主机的AS。可以通过查看<code>peer2</code>上的配置文件来确认这一点。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# grep -A4 peer1 /etc/bird/bird.conf</span><br><span class="line">protocol bgp peer1 &#123;</span><br><span class="line">  local as 64513;</span><br><span class="line">  neighbor 10.0.0.10 as 64512;</span><br><span class="line">  export none;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>协议BGP块中的这两个指令处理会话的初始建立。</p>
<p>虽然建立和维护会话对于BGP的运行至关重要，但仅建立会话无法路由任何流量。在下一节中，我们将探讨配置文件中的其他一些元素，以及如何使用它们来发现和宣布节点之间的路由。在继续进行此操作之前，先回顾一下我们当前的拓扑。</p>
<p>当前，我们的网络中有三个节点，<code>peer1</code>（AS64512），<code>peer2</code>（AS64513）和<code>peer3</code>（AS64514）。这些配置在同一广播域中，但是对等的结构类似于<code>peer3</code> &lt;-&gt; <code>peer1</code> &lt;-&gt; <code>peer2</code>。这种结构允许通过我们的路由服务器<code>peer1</code>从<code>peer2</code>或<code>peer3</code>进行路由通信。在继续进行本教程的下一步，即发布路由时，请牢记此拓扑。</p>
<table>
<thead>
<tr>
<th align="left">IP地址</th>
<th>节点名</th>
<th>AS号</th>
</tr>
</thead>
<tbody><tr>
<td align="left">10.0.0.10</td>
<td>peer1</td>
<td>64512</td>
</tr>
<tr>
<td align="left">10.0.0.11</td>
<td>peer2</td>
<td>64513</td>
</tr>
<tr>
<td align="left">10.0.100.11</td>
<td>peer3</td>
<td>64514</td>
</tr>
</tbody></table>
<h3 id="BGP发布路由"><a href="#BGP发布路由" class="headerlink" title="BGP发布路由"></a><strong>BGP发布路由</strong></h3><p><strong>内核协议</strong></p>
<p>在开始发布Bird守护程序之间的路由之前，我们应该首先了解BIRD如何在Linux内核和BIRD守护程序之间传递路由。这就是我们前面看到的内核协议块起作用的地方。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">protocol kernel &#123;</span><br><span class="line">  metric 0;</span><br><span class="line">  learn;</span><br><span class="line">  import none;</span><br><span class="line">  export all; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>kernel块中可以指定许多选项，并且可以在<a target="_blank" rel="noopener" href="http://bird.network.cz/?get_doc&f=bird-6.html#ss6.6">此处</a>找到关于这些选项的更多信息，但是我们要执行的大部分操作由导入&#x2F;导出定义。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import none;</span><br></pre></td></tr></table></figure>

<p>告诉BIRD不要将路由从内核路由表中读取到BIRD中。我们将通过直接协议（即配置）获取路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export all;</span><br></pre></td></tr></table></figure>

<p>告诉BIRD将其他公告了解的所有路由导出到内核的路由表中。这使我们可以实际利用此主机上的任何已获取的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">metric 0;</span><br></pre></td></tr></table></figure>

<p>度量标准值由内核用来确定路由的优先级，并选择优先级最低的路由。在这种情况下，我们将其设置为0或未定义，以便我们首选本地路由。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn;</span><br></pre></td></tr></table></figure>

<p>最后，我们将设置学习指令，该指令将允许其他守护程序从内核路由表中学习路由。</p>
<p><strong>发现直接路由</strong></p>
<p>现在，我们已经配置了BIRD守护程序以将路由直接推送到内核路由表，我们将需要配置对等端以发现本地直接路由。由于我们会将这些路由直接添加到我们的环回接口，因此在选择的编辑器中，将直接协议配置为仅使用<code>lo</code>接口。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">grep -A2 direct conf/peer2/etc/bird/bird.conf</span></span><br><span class="line">protocol direct &#123;</span><br><span class="line">  interface &quot;lo&quot;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose restart peer2</span></span><br><span class="line">Restarting bird_examples_peer2_1 ... done</span><br></pre></td></tr></table></figure>

<p>由于我们的网络上也有<code>peer3</code>，因此在此主机上进行相同操作，以防止宣布其他任何路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">grep -A2 direct conf/peer3/etc/bird/bird.conf</span></span><br><span class="line">protocol direct &#123;</span><br><span class="line">  interface &quot;lo&quot;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose restart peer3</span></span><br><span class="line">Restarting bird_examples_peer3_1 ... done</span><br></pre></td></tr></table></figure>

<p>此时，除了默认的10.0.0.0子网（可以使用<code>birdc</code>进行验证）以外，我们将没有其他路由学习和发布。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# birdc show route all</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">10.0.0.0/24        via 10.0.0.10 on eth0 [peer1 03:05:02] ! (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.0.10</span><br><span class="line">        BGP.local_pref: 100</span><br><span class="line">10.0.100.0/24      via 10.0.0.10 on eth0 [peer1 03:05:02] * (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.0.10</span><br><span class="line">        BGP.local_pref: 100</span><br></pre></td></tr></table></figure>

<p><strong>过滤引用和导出</strong></p>
<p>与内核模块类似，导出和导入可用于控制BGP对等方导入和导出的内容。首先，我们探讨过滤的概念以及如何将其用于控制将宣布或导出哪些路由。</p>
<p>BIRD中的过滤器基本上是在路由上执行的函数，返回接受或拒绝。这使我们能够应用一种简单的编程语言来为我们的路由策略添加逻辑。过滤器可以包含任何内容，从单个语句到非常复杂的逻辑。首先，让我们将none和all指令重新实现为过滤器，然后将它们添加到include指令上方的bird.conf文件中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filter accept_all &#123;</span><br><span class="line">  accept;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filter reject_all &#123;</span><br><span class="line">  reject;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>现在我们已经有了过滤器，让我们在我们的协议块之一的导入&#x2F;导出指令中实现它们。在主机<code>peer1</code>上，让我们看一下<code>peer2</code>块。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">protocol bgp peer2 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.0.11 as 64513;</span><br><span class="line">  import filter accept_all;</span><br><span class="line">  export filter accept_all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从功能上讲，这与我们的原始配置相同，但是现在我们可以使用进一步的逻辑扩展这些设置。通过进一步研究过滤器脚本语言，可以了解这些过滤器的功能。为了扩展我们所学的知识，让我们在<code>peer2</code>上的bird.conf中创建一个过滤器，以控制要向<code>peer1</code>发布的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter export_subnets &#123;</span><br><span class="line">  if net ~ [ 192.168.5.5/32 ] then &#123;</span><br><span class="line">    accept;</span><br><span class="line">  &#125;</span><br><span class="line">  reject;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后，我们需要在<code>peer2</code>上更新<code>peer1</code>以使用此导出过滤器。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# grep -A4 peer1 /etc/bird/bird.conf</span><br><span class="line">protocol bgp peer1 &#123;</span><br><span class="line">  local as 64513;</span><br><span class="line">  neighbor 10.0.0.10 as 64512;</span><br><span class="line">  export filter export_subnets; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose restart peer1 peer2</span></span><br><span class="line">Restarting bird_examples_peer2_1 ... done</span><br><span class="line">Restarting bird_examples_peer1_1 ... done</span><br></pre></td></tr></table></figure>

<p><strong>发布路由</strong></p>
<p>现在，我们有了开始发布<code>peer1</code>和<code>peer2</code>之间的路由所需的所有构造块。在此之前，让我们回顾一下我们所做的事情。首先，我们已将BIRD守护程序配置为使用我们的内核协议在其内部路由表和内核路由表之间进行通信。我们已将BIRD守护程序配置为从具有直接协议的环回接口中学习路由。我们还配置了<code>peer1</code>从其他对等节点导入路由并导出这些路由。最终，我们将<code>peer2</code>配置为仅使用export_subnets过滤器将192.168.5.5&#x2F;32导出到<code>peer1</code>。但是，目前我们还没有从<code>peer2</code>通告到<code>peer1</code>的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# ip route  </span><br><span class="line">default via 10.0.0.1 dev eth0 </span><br><span class="line">10.0.0.0/24 dev eth0 proto kernel scope link src 10.0.0.10 </span><br><span class="line">10.0.100.0/24 dev eth1 proto kernel scope link src 10.0.100.10</span><br></pre></td></tr></table></figure>

<p>此时，所有设置已经完成，因此可以从环回接口中学习路由。通过将IP添加到<code>peer2</code>的环回接口上，我们应该能够看到路由的发布。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# ip a add 192.168.5.5/32 dev lo</span><br></pre></td></tr></table></figure>

<p>现在，如果我们同时查看<code>peer1</code>上的birdc和内核路由表，我们应该可以看到<code>peer1</code>上新IP的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:~# ip route</span><br><span class="line">default viia 10.0.2.2 dev eth0</span><br><span class="line">10.0.0.0/24 dev eth1 proto kernel scope link src 10.0.0.10</span><br><span class="line">10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15</span><br><span class="line">10.0.100.0/24 dev eth2 proto kernel scope link src 10.0.100.10</span><br><span class="line">192.168.5.5 via 10.0.0.11 dev eth1 proto bird</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show route all</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">10.0.0.0/24        dev eth0 [direct1 03:10:33] * (240)</span><br><span class="line">        Type: device unicast univ</span><br><span class="line">10.0.100.0/24      dev eth1 [direct1 03:10:33] * (240)</span><br><span class="line">        Type: device unicast univ</span><br><span class="line">192.168.5.5/32     via 10.0.0.11 on eth0 [peer2 03:12:39] * (100) [AS64513i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64513</span><br><span class="line">        BGP.next_hop: 10.0.0.11</span><br><span class="line">        BGP.local_pref: 100</span><br></pre></td></tr></table></figure>

<p>ping将显示我们现在可以从<code>peer1</code>向该主机发送流量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# ping -c 1 192.168.5.5</span><br><span class="line">PING 192.168.5.5 (192.168.5.5) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.5.5: icmp_seq=1 ttl=64 time=0.135 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.5.5 ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.135/0.135/0.135/0.000 ms</span><br></pre></td></tr></table></figure>

<p>现在可以看到这些路由已通过<code>peer1</code>通告到<code>peer3</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@peer3:/# birdc show route all</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">10.0.0.0/24        via 10.0.100.10 on eth0 [peer3 03:10:37] * (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.100.10</span><br><span class="line">        BGP.local_pref: 100</span><br><span class="line">10.0.100.0/24      via 10.0.100.10 on eth0 [peer3 03:10:37] ! (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.100.10</span><br><span class="line">        BGP.local_pref: 100</span><br><span class="line">192.168.5.5/32     via 10.0.100.10 on eth0 [peer3 03:12:38] * (100) [AS64513i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512 64513</span><br><span class="line">        BGP.next_hop: 10.0.100.10</span><br><span class="line">        BGP.local_pref: 100</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@peer3:/# ping -c 1 192.168.5.5</span><br><span class="line">PING 192.168.5.5 (192.168.5.5) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.5.5: icmp_seq=1 ttl=63 time=0.082 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.5.5 ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.082/0.082/0.082/0.000 ms</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@peer3:/# traceroute 192.168.5.5</span><br><span class="line">traceroute to 192.168.5.5 (192.168.5.5), 64 hops max</span><br><span class="line">  1   10.0.100.10  0.005ms  0.003ms  0.003ms </span><br><span class="line">  2   192.168.5.5  0.003ms  0.003ms  0.003ms</span><br></pre></td></tr></table></figure>

<p>我们也可以通过查看AS PATH来了解情况。通过查看与birdc中的路由关联的AS PATH，可以看到从64513到64512的路由在到达<code>peer3</code>之前发布。</p>
<p>因为将<code>peer1</code>配置为将路由导出到<code>peer3</code>，并且由于<code>peer3</code>配置为从<code>peer1</code>导入路由，所以我们能够将此路由获取到<code>peer3</code>的BIRD路由表中。然后，由于我们已将内核协议配置为在BIRD中导出路由，因此这些路由会将其放入<code>peer3</code>的内核路由表中。</p>
<h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>在这个简单的教程中，我们探讨了许多概念，但是，我们几乎没有涉及bird的概念。随时使用此示例，以发布和过滤路由的方式进一步探索。在以后的教程中，我们将更深入地探讨BGP的工作方式以及用于确定路由的过程，包括如何通信和本地优先级以及BGP守护程序如何使用它们来选择通往服务器的最佳路径。我们还将探讨什么是任播IP，以及如何使用BGP配置高可用性，以及如何使用过滤策略代替直接接口策略来控制向每个节点声明哪些前缀。BGP可以为我们提供对网络拓扑的大量控制，并且了解如何使用BGP可以更好地调整网络以适应自己的需求。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/30/k8s/Kubernetes-External-IP-service-type/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/30/k8s/Kubernetes-External-IP-service-type/" class="post-title-link" itemprop="url">Kubernetes External IP服务类型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-30 22:50:22" itemprop="dateCreated datePublished" datetime="2020-06-30T22:50:22+00:00">2020-06-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-04-14 02:11:35" itemprop="dateModified" datetime="2024-04-14T02:11:35+00:00">2024-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在构建裸机Kubernetes集群时，您可能会遇到一个常见问题，就像我在做的那样，除了使用NodePort之外，您真的不知道如何向Internet公开Kubernetes服务。如果使用的是NodePort服务类型，它将分配一个要打开的较大端口号，并且您必须允许防火墙规则连接到这些端口。这对您的基础架构不利，尤其是在将服务器暴露于外部Internet时。好吧，还有另一种简洁的方法可以将您的Kubernetes服务公开出去，并且使用服务的原始端口号。例如，您可以将Kubernetes群集中部署的MySQL服务通过3306而不是32767端口暴露给外界。<strong>答案是使用Kubernetes External IP服务类型</strong>。</p>
<p>就个人而言，我发现在Kubernetes社区中并未广泛讨论此主题，这可能是因为许多人正在使用云提供商的负载均衡器或将Metal LB用于本地部署。</p>
<h2 id="什么是External-IP服务"><a href="#什么是External-IP服务" class="headerlink" title="什么是External IP服务"></a>什么是External IP服务</h2><p>从<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types">Kubernetes官方文档</a>中可以看到External IP的描述：</p>
<blockquote>
<p><em>如果存在路由到一个或多个集群节点的外部IP，则Kubernetes Services可以在这些<strong>External IP</strong>上公开。在服务端口上使用外部IP（作为目标IP）进入群集的流量将被路由到服务端点之一。<strong>External IP</strong>不受Kubernetes的管理，由集群管理员负责。</em></p>
</blockquote>
<p>对于大多数人来说，这种解释是可以理解的。这里最重要的是确保使用哪个IP来访问Kubernetes集群。使用External IP服务类型，我们可以将服务绑定到用于连接集群的IP。</p>
<p>如果您了解Kubernetes网络的工作方式，那将是很好的。如果您不熟悉它，请查看Mark Betz撰写的<a target="_blank" rel="noopener" href="https://medium.com/google-cloud/understanding-kubernetes-networking-pods-7117dd28727">博客文章</a>，以详细了解它们。这里最重要的是要知道Kubernetes网络与Overlay网络一起工作。这意味着一旦您到达群集中的任何节点（主节点或工作节点），您就可以虚拟访问群集中的所有节点。</p>
<p>下图就是他们的组网图：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/kubernetes-external-ip.png" alt="kubernetes-external-ip"></p>
<p>在上图中，节点1和节点2都有1个IP地址。节点1上的IP地址1.2.3.4绑定到实际Pod驻留在节点2中的httpd服务，而IP地址1.2.3.5绑定到实际Pod驻留在节点1中的nginx服务。底层的overlay网络使这成为可能。当我们curl 1.2.3.4时，应该看到来自httpd服务的响应，而curl 1.2.3.5时，则应该看到来自nginx服务的响应。</p>
<h2 id="为什么不使用Ingress"><a href="#为什么不使用Ingress" class="headerlink" title="为什么不使用Ingress"></a>为什么不使用Ingress</h2><p>即使Ingress也用于将服务公开给外部，但Ingress是为L7路由构建的。这意味着它构建为支持HTTP（端口80）和&#x2F;或HTTPS（端口443）流量，而不支持其他端口。Ingress充当基于主机的路由，或类似于Web Server中的虚拟主机。一些能够为其他端口提供服务的ingress controllers，或者可能为L4路由提供了解决方法，但我从未真正尝试使用它们。</p>
<h2 id="External-IP的优缺点"><a href="#External-IP的优缺点" class="headerlink" title="External IP的优缺点"></a>External IP的优缺点</h2><p>使用External IP的优点是：</p>
<ul>
<li>您可以完全控制所使用的IP。您可以使用属于您的ASN的IP，而不要使用云提供商的ASN。</li>
</ul>
<p>外部IP的缺点是：</p>
<ul>
<li>我们现在将要进行的简单设置并<strong>不是高可用的</strong>。这意味着，如果节点异常，则该服务将不再可用，您将需要手动修复该问题。</li>
<li>管理IP需要做一些手工工作。IP不是为您动态配置的，因此需要人工干预。</li>
</ul>
<h2 id="如何使用External-IP服务"><a href="#如何使用External-IP服务" class="headerlink" title="如何使用External IP服务"></a>如何使用External IP服务</h2><p>同样，我们将使用与我们的群集设置相同的组网图，不同的是IP地址和主机名不同。这不是一个好例子，但是当我们验证设置时，很容易区分是哪个。在实际示例中，您可能希望在一个外部IP上公开MySQL DB，在另一个外部IP上公开Kafka群集。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/kubernetes-external-ip-demo.png" alt="kubernetes-external-ip-demo"></p>
<p>我已为本教程配置了2个VM。k3s-external-ip-master将是我们的Kubernetes master节点，其IP为1.2.4.120。k3s-external-ip-worker将是Kubernetes worker节点，其IP为1.2.4.114。</p>
<p><strong>步骤1：部署Kubernetes集群</strong></p>
<p>让我们在主节点上安装k3s，然后让另一个节点加入集群。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k3sup install --ip &lt;master node ip&gt; --user &lt;username&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k3sup <span class="built_in">join</span> --server-ip &lt;master node ip&gt; --ip &lt;worker node ip&gt; --user &lt;username&gt;</span></span><br></pre></td></tr></table></figure>

<p>您现在应该会看到类似的内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get nodes</span></span><br><span class="line">NAME                                  STATUS   ROLES    AGE     VERSION</span><br><span class="line">k3s-external-ip-master               Ready    master   7m24s   v1.16.3-k3s.2</span><br><span class="line">k3s-external-ip-worker               Ready    &lt;none&gt;   2m21s   v1.16.3-k3s.2</span><br></pre></td></tr></table></figure>

<p><strong>步骤2：创建Kubernetes Deployment资源</strong></p>
<p>我们将创建nginx和httpd资源。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment nginx --image=nginx</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment httpd --image=httpd</span></span><br></pre></td></tr></table></figure>

<p>你现在应该看到这个:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-86c57db685-fzxn5   1/1     Running   0          22s</span><br><span class="line">httpd-7bddd4bd85-zk8ks   1/1     Running   0          16s</span><br></pre></td></tr></table></figure>

<p><strong>步骤3：将Deployment公开为External IP类型</strong></p>
<p>让我们创建Nginx服务的yaml：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">nginx-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">externalIPs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">1.2</span><span class="number">.4</span><span class="number">.114</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>创建httpd服务的yaml：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt; httpd-service.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: httpd-service</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: httpd</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      targetPort: 80</span><br><span class="line">  externalIPs:</span><br><span class="line">    - 1.2.4.120</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>使用kubectl命令创建2个服务的yaml：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f nginx-service.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f httpd-service.yaml</span></span><br></pre></td></tr></table></figure>

<p>现在您的Kubernetes服务应该如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes      ClusterIP   10.43.0.1       &lt;none&gt;        443/TCP   18m</span><br><span class="line">httpd-service   ClusterIP   10.43.240.149   1.2.4.120     80/TCP    32s</span><br><span class="line">nginx-service   ClusterIP   10.43.13.149    1.2.4.114     80/TCP    26s</span><br></pre></td></tr></table></figure>

<p>您可能会在此处看到服务类型为ClusterIP。我不确定为什么它不显示“外部IP”。</p>
<blockquote>
<p>k8s官网有说明，External IP与type无关</p>
</blockquote>
<p><strong>步骤4：瞧！</strong></p>
<p>让我们curl httpd服务，您应该看到Apache默认页面。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -i 1.2.4.120</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Date: Fri, 20 Dec 2019 03:36:23 GMT</span><br><span class="line">Server: Apache/2.4.41 (Unix) &lt;------</span><br><span class="line">Last-Modified: Mon, 11 Jun 2007 18:53:14 GMT</span><br><span class="line">ETag: &quot;2d-432a5e4a73a80&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 45</span><br><span class="line">Content-Type: text/html</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p>接下来，curl nginx服务，您应该看到nginx默认页面。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -i 1.2.4.114</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.17.6 &lt;------</span><br><span class="line">Date: Fri, 20 Dec 2019 03:36:01 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 612</span><br><span class="line">Last-Modified: Tue, 19 Nov 2019 12:50:08 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;5dd3e500-264&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">....</span><br></pre></td></tr></table></figure>

<h2 id="下一步是什么"><a href="#下一步是什么" class="headerlink" title="下一步是什么"></a>下一步是什么</h2><h3 id="浮动IP"><a href="#浮动IP" class="headerlink" title="浮动IP"></a>浮动IP</h3><p>如今，大多数云提供商都提供浮动IP服务。浮动IP允许您拥有1个IP，并将该IP动态分配给所需的任何IP。在这种情况下，可以将IP分配给Kubernetes集群中的任何工作节点。</p>
<p>在DigitalOcean（我相信其他提供商也允许这样做）中，您可以使用API调用将IP重新分配给其他VM。这意味着您可以在其他VM发生故障时迅速将其主动重新分配给其他VM，或者可以定期轮换IP。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/kubernetes-floating-ip.png" alt="kubernetes-floating-ip"></p>
<p>从图中可以看到，我们有1个浮动IP 1.2.3.6，该IP首先分配给节点1，当节点1不可用时将切换到节点2。IP 1.2.3.6适用于我们的MySQL服务，并将放入我们的应用程序配置中。</p>
<p>我尚未尝试此设置，因此无法确认它是否有效。我将在以后的博客文章中更新结果。</p>
<h3 id="任播IP"><a href="#任播IP" class="headerlink" title="任播IP"></a>任播IP</h3><p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/anycast.png" alt="anycast"></p>
<p>您可以将Anycast IP用作外部IP，以便它们具有高可用性。对于不熟悉Anycast IP的用户，这意味着1个IP可能会路由到2个或更多服务器。你可以在<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Anycast">这里</a>阅读更多。就个人而言，我不确定如何设置此设置。但是，我认为这在技术上是可行的。我认为这是运行外部IP服务的最佳方法。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>您可以通过很多选项为裸机Kubernetes集群获取IP。例如，您可以为此使用Inlets和MetalLB。此设置可能不是您的组织需要的最合适的设置。但是，很高兴知道如何使用此方法。</p>
<blockquote>
<p>免责声明：我仅将其用于实验和测试，而本文不适用于生产。如果您打算在生产中使用它，请咨询您的解决方案架构师或CTO。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LeaoYao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">90</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LeaoYao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
