<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lyyao09.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="云原生知识星球">
<meta property="og:url" content="https://lyyao09.github.io/page/6/index.html">
<meta property="og:site_name" content="云原生知识星球">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="LeaoYao">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://lyyao09.github.io/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>云原生知识星球</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">云原生知识星球</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/25/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/25/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/" class="post-title-link" itemprop="url">为什么Helm可以解决Kubernetes原生回滚问题？</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-25 22:15:35" itemprop="dateCreated datePublished" datetime="2020-12-25T22:15:35+00:00">2020-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题引出"><a href="#问题引出" class="headerlink" title="问题引出"></a>问题引出</h2><p>Helm是将应用程序部署到Kubernetes的绝佳工具。我们可以打包所有deployment和service等yaml文件，并使用一个简单的命令将它们部署到集群中。</p>
<p>但是Helm的另一个非常酷的功能是能够轻松升级和回滚版本（在集群中运行的Helm Chart实例的术语）的功能。</p>
<p>现在，我们可以使用kubectl进行此操作。如果我们使用<code>kubectl apply</code>升级deployment资源，则可以使用<code>kubectl rollout undo</code>来回滚该升级。这很棒！这是Kubernetes的最佳功能之一。</p>
<p>升级deployment时，将为该deployment创建一个新的replicaset，该replicaset将在一组新的Pod中运行升级后的应用程序。</p>
<p>如果使用<code>kubectl rollout undo</code>进行回滚，会删除最新replicaset中的容器，并回滚到旧replicaset的容器。</p>
<p><strong>但是这里有一个潜在的问题。如果删除旧的replicaset会怎样？</strong>如果发生这种情况，我们将无法回滚升级。好吧，我们无法使用<code>kubectl rollout undo</code>将其回滚，但是如果我们使用Helm，会发生什么？</p>
<p>让我们来看一个演示。</p>
<h2 id="Helm环境准备"><a href="#Helm环境准备" class="headerlink" title="Helm环境准备"></a>Helm环境准备</h2><p>创建一个称为testchart的Chart：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm create testchart	</span><br></pre></td></tr></table></figure>

<p>删除模板目录中所有不必要的文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ./testchart/templates/*</span><br></pre></td></tr></table></figure>

<p>创建一个deployment yaml文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment nginx \</span><br><span class="line">--image=nginx:1.17 \</span><br><span class="line">--dry-run=client \</span><br><span class="line">--output=yaml &gt; ./testchart/templates/deployment.yaml</span><br></pre></td></tr></table></figure>

<p>这将创建以下yaml并将其另存为templates目录中的deployment.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">strategy:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>创建deployment：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment nginx --image=nginx:1.17 </span><br></pre></td></tr></table></figure>

<p>为service生成yaml：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nginx \</span><br><span class="line">--type=LoadBalancer \</span><br><span class="line">--port=80 \</span><br><span class="line">--dry-run=client \</span><br><span class="line">--output=yaml &gt; ./testchart/templates/service.yaml</span><br></pre></td></tr></table></figure>

<p>这将为我们提供以下yaml并将其另存为模板目录中的service.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>删除deployment，模板化values.yaml 和deployment.yaml文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete deployment nginx</span><br><span class="line">rm ./testchart/values.yaml</span><br><span class="line">echo &quot;containerImage: nginx:1.17&quot; &gt; ./testchart/values.yaml</span><br><span class="line">sed -i &#x27;s/nginx:1.17/&#123;&#123; .Values.containerImage &#125;&#125;/g&#x27; ./testchart/templates/deployment.yaml</span><br></pre></td></tr></table></figure>

<p>最终，deployment.yaml文件如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">strategy:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> &#123;&#123; <span class="string">.Values.containerImage</span> &#125;&#125;</span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>改造后的yaml中容器镜像不再是硬编码的。它将从values.yaml文件中获取nginx:1.17的值，或者我们可以使用set标志来覆盖它（我们将在一分钟内完成）。</p>
<h2 id="Helm部署示例"><a href="#Helm部署示例" class="headerlink" title="Helm部署示例"></a>Helm部署示例</h2><p>首先，将Chart部署到Kubernetes集群中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install testchart ./testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-install-1.png" alt="helm-install-1"></p>
<p>该应用程序版本是Chart.yaml文件中设置的默认版本（尚未更新）</p>
<p>检查部署中运行的镜像版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment -o jsonpath=&#x27;&#123; .items[*].spec.template.spec.containers[*].image &#125;&#123;&quot;\n&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-history-updated.png" alt="get-container-image-1"></p>
<p>查看到的容器镜像就是Chart中values.yaml文件中定义的镜像版本。</p>
<p>现在升级Release，将默认的容器镜像值替换为set标志指定的值：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade testchart ./testchart --set containerImage=nginx:1.18</span><br></pre></td></tr></table></figure>

<p>确认版本已升级（检查版本号）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm list</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-container-image-1.png" alt="helm-upgrade-1"></p>
<p>另外，请确认Release历史：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm history testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-upgrade-1.png" alt="helm-history-updated"></p>
<p>这样我们就可以看到该Release的初始部署，然后是升级。应用版本保持不变，因为我没有更改Chart.yaml文件中的值。但是，镜像版本已更改，我们可以通过以下方式看到：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment -o jsonpath=&#x27;&#123; .items[*].spec.template.spec.containers[*].image &#125;&#123;&quot;\n&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-rollout-undo.png" alt="get-container-image-2"></p>
<p>因此，我们已经升级了在deployment中容器运行的镜像版本。</p>
<p>让我们看一下deployment的replicasets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get replicasets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-replicasets-2.png" alt="get-replicasets-1"></p>
<p>因此，我们为Helm版本创建的deployment有两个replicasets。最初的一个运行nginx v1.17，最新的一个运行nginx v1.18。</p>
<p>如果我们想使用kubectl回退升级，则可以使用（不要运行此代码！）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-replicasets-1.png" alt="kubectl-rollout-undo"></p>
<p>这里将发生的是，删除最新replicasets下的Pod，并创建旧replicasets下的Pod，将nginx回滚到v1.17。</p>
<p>但是我们不会那样做，因为我们正在使用Helm。</p>
<h2 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h2><p>继续在当前环境中获取最旧的replicasets名称，并删除它：：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">REPLICA_SET=$(kubectl get replicasets -o jsonpath=&#x27;&#123;.items[0].metadata.name &#125;&#x27; --sort-by=.metadata.creationTimestamp)</span><br><span class="line">kubectl delete replicasets $REPLICA_SET</span><br></pre></td></tr></table></figure>

<p>因此，我们现在只有一个replicasets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get replicasets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-container-image-2.png" alt="get-replicasets-2"></p>
<p>现在尝试使用<code>kubectl rollout undo</code>命令进行回滚：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-rollout-undo-2.png" alt="kubectl-rollout-undo-2"></p>
<p>失败的原因是我们删除了旧的replicasets，因此该deployment没有历史记录，可以通过以下方式查看：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout history deployment nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-rollout-history.png" alt="kubectl-rollout-history"></p>
<h2 id="使用Helm回滚"><a href="#使用Helm回滚" class="headerlink" title="使用Helm回滚"></a>使用Helm回滚</h2><p>虽然旧的replicasets被删除了，但是Helm的实现机制决定了使用Helm部署的Release会保留历史：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm history testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-history-2.png" alt="helm-history-2"></p>
<p>所以，我们可以使用Helm回滚：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm rollback testchart 1</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-rollback.png" alt="helm-rollback"></p>
<p>查看Release状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm list</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-list-rollback.png" alt="helm-list-rollback"></p>
<p>查看Release历史：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm history testchart</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/get-replicasets-3.png" alt="helm-rollback-history"></p>
<p>查看replicasets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get replicasets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/helm-rollback-history.png" alt="get-replicasets-3"></p>
<p>旧的replicasets又回来了！怎么样？</p>
<h2 id="原理探究"><a href="#原理探究" class="headerlink" title="原理探究"></a>原理探究</h2><p>让我们看一下集群中的secrets：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secrets</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-get-secrets.png" alt="kubectl-get-secrets"></p>
<p>可以看出，这些secrets中会存储Helm发布所有历史记录！初始版本（v1），升级（v2）和回滚（v3）。</p>
<p>让我们仔细看看v1版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.testchart.v1 -o json</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/kubectl-get-secrets-2.png" alt="kubectl-get-secrets-2"></p>
<p>嗯，这个Release内容看起来很有趣。我们可以做的是对base64进行解码，然后通过<a target="_blank" rel="noopener" href="http://www.txtwizard.net/compression%E8%BF%9B%E8%A1%8C%E8%A7%A3%E5%8E%8B%E7%BC%A9%EF%BC%8C%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9C%E5%A6%82%E4%B8%8B%EF%BC%9A">http://www.txtwizard.net/compression进行解压缩，得到结果如下：</a></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">&quot;name&quot;</span><span class="string">:&quot;testchart&quot;</span>,</span><br><span class="line"><span class="attr">&quot;info&quot;:</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;first_deployed&quot;</span><span class="string">:&quot;2020-08-09T11:21:20.4665817+01:00&quot;</span>,</span><br><span class="line">        <span class="string">&quot;last_deployed&quot;</span><span class="string">:&quot;2020-08-09T11:21:20.4665817+01:00&quot;</span>,</span><br><span class="line">        <span class="string">&quot;deleted&quot;</span><span class="string">:&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span><span class="string">:&quot;Install</span> <span class="string">complete&quot;</span>,</span><br><span class="line">        <span class="string">&quot;status&quot;</span><span class="string">:&quot;superseded&quot;</span>&#125;,</span><br><span class="line">        <span class="string">&quot;chart&quot;</span><span class="string">:</span>&#123;<span class="attr">&quot;metadata&quot;:</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span><span class="string">:&quot;testchart&quot;</span>,</span><br><span class="line">        <span class="string">&quot;version&quot;</span><span class="string">:&quot;0.1.0&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span><span class="string">:&quot;A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Kubernetes&quot;</span>,</span><br><span class="line">        <span class="string">&quot;apiVersion&quot;</span><span class="string">:&quot;v2&quot;</span>,</span><br><span class="line">        <span class="string">&quot;appVersion&quot;</span><span class="string">:&quot;1.16.0&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span><span class="string">:&quot;application&quot;</span>&#125;,</span><br><span class="line">        <span class="string">&quot;lock&quot;</span><span class="string">:null</span>,</span><br><span class="line">        <span class="string">&quot;templates&quot;</span><span class="string">:</span>[</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">&quot;name&quot;:</span></span><br><span class="line">                <span class="string">&quot;templates/deployment.yaml&quot;</span>,</span><br><span class="line">                <span class="string">&quot;data&quot;</span><span class="string">:&quot;YXBpVmVyc2lvbjogYXBwcy92MQpraW5kOiBEZXBsb3ltZW50Cm1ldGFkYXRhOgogIGNyZWF0aW9uVGltZXN0YW1wOiBudWxsCiAgbGFiZWxzOgogICAgYXBwOiBuZ2lueAogIG5hbWU6IG5naW54CnNwZWM6CiAgcmVwbGljYXM6IDEKICBzZWxlY3RvcjoKICAgIG1hdGNoTGFiZWxzOgogICAgICBhcHA6IG5naW54CiAgc3RyYXRlZ3k6IHt9CiAgdGVtcGxhdGU6CiAgICBtZXRhZGF0YToKICAgICAgY3JlYXRpb25UaW1lc3RhbXA6IG51bGwKICAgICAgbGFiZWxzOgogICAgICAgIGFwcDogbmdpbngKICAgIHNwZWM6CiAgICAgIGNvbnRhaW5lcnM6CiAgICAgIC0gaW1hZ2U6IHt7IC5WYWx1ZXMuY29udGFpbmVySW1hZ2UgfX0KICAgICAgICBuYW1lOiBuZ2lueAogICAgICAgIHJlc291cmNlczoge30Kc3RhdHVzOiB7fQo=&quot;</span>&#125;,&#123;<span class="string">&quot;name&quot;</span><span class="string">:&quot;templates/service.yaml&quot;</span>,<span class="string">&quot;data&quot;</span><span class="string">:&quot;YXBpVmVyc2lvbjogdjEKa2luZDogU2VydmljZQptZXRhZGF0YToKICBjcmVhdGlvblRpbWVzdGFtcDogbnVsbAogIGxhYmVsczoKICAgIGFwcDogbmdpbngKICBuYW1lOiBuZ2lueApzcGVjOgogIHBvcnRzOgogIC0gcG9ydDogODAKICAgIHByb3RvY29sOiBUQ1AKICAgIHRhcmdldFBvcnQ6IDgwCiAgc2VsZWN0b3I6CiAgICBhcHA6IG5naW54CiAgdHlwZTogTG9hZEJhbGFuY2VyCnN0YXR1czoKICBsb2FkQmFsYW5jZXI6IHt9Cg==&quot;</span>&#125;],<span class="string">&quot;values&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;containerImage&quot;</span><span class="string">:&quot;nginx:1.17&quot;</span>&#125;,<span class="string">&quot;schema&quot;</span><span class="string">:null</span>,<span class="string">&quot;files&quot;</span><span class="string">:</span>[&#123;<span class="string">&quot;name&quot;</span><span class="string">:&quot;.helmignore&quot;</span>,<span class="string">&quot;data&quot;</span><span class="string">:&quot;IyBQYXR0ZXJucyB0byBpZ25vcmUgd2hlbiBidWlsZGluZyBwYWNrYWdlcy4KIyBUaGlzIHN1cHBvcnRzIHNoZWxsIGdsb2IgbWF0Y2hpbmcsIHJlbGF0aXZlIHBhdGggbWF0Y2hpbmcsIGFuZAojIG5lZ2F0aW9uIChwcmVmaXhlZCB3aXRoICEpLiBPbmx5IG9uZSBwYXR0ZXJuIHBlciBsaW5lLgouRFNfU3RvcmUKIyBDb21tb24gVkNTIGRpcnMKLmdpdC8KLmdpdGlnbm9yZQouYnpyLwouYnpyaWdub3JlCi5oZy8KLmhnaWdub3JlCi5zdm4vCiMgQ29tbW9uIGJhY2t1cCBmaWxlcwoqLnN3cAoqLmJhawoqLnRtcAoqLm9yaWcKKn4KIyBWYXJpb3VzIElERXMKLnByb2plY3QKLmlkZWEvCioudG1wcm9qCi52c2NvZGUvCg==&quot;</span>&#125;]&#125;,</span><br><span class="line">                <span class="string">&quot;manifest&quot;</span><span class="string">:&quot;---\n#</span> </span><br><span class="line">                    <span class="attr">Source:</span> <span class="string">testchart/templates/service.yaml\n</span></span><br><span class="line">                    <span class="attr">apiVersion:</span> <span class="string">v1\n</span></span><br><span class="line">                    <span class="attr">kind:</span> <span class="string">Service\nmetadata:\n</span>  </span><br><span class="line">                    <span class="attr">creationTimestamp:</span> <span class="literal">null</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">labels:\n</span>    </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">name:</span> <span class="string">nginx\n</span></span><br><span class="line">                    <span class="string">spec:\n</span>  </span><br><span class="line">                    <span class="string">ports:\n</span>  </span><br><span class="line">                    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span><span class="string">\n</span>    </span><br><span class="line">                    <span class="attr">protocol:</span> <span class="string">TCP\n</span>    </span><br><span class="line">                    <span class="attr">targetPort:</span> <span class="number">80</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">selector:\n</span>    </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">type:</span> <span class="string">LoadBalancer\n</span></span><br><span class="line">                    <span class="string">status:\n</span>  <span class="attr">loadBalancer:</span> &#123;&#125;<span class="string">\n---\n#</span> </span><br><span class="line">                     </span><br><span class="line">                    <span class="attr">Source:</span> <span class="string">testchart/templates/deployment.yaml\n</span></span><br><span class="line">                    <span class="attr">apiVersion:</span> <span class="string">apps/v1\n</span></span><br><span class="line">                    <span class="attr">kind:</span> <span class="string">Deployment\n</span></span><br><span class="line">                    <span class="string">metadata:\n</span>  </span><br><span class="line">                    <span class="attr">creationTimestamp:</span> <span class="literal">null</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">labels:\n</span>    </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">name:</span> <span class="string">nginx\nspec:\n</span>  </span><br><span class="line">                    <span class="attr">replicas:</span> <span class="number">1</span><span class="string">\n</span>  </span><br><span class="line">                    <span class="string">selector:\n</span>    </span><br><span class="line">                    <span class="string">matchLabels:\n</span>      </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>  </span><br><span class="line">                    <span class="attr">strategy:</span> &#123;&#125;<span class="string">\n</span>  </span><br><span class="line">                    <span class="string">template:\n</span>    </span><br><span class="line">                    <span class="string">metadata:\n</span>      </span><br><span class="line">                    <span class="attr">creationTimestamp:</span> <span class="literal">null</span><span class="string">\n</span>      </span><br><span class="line">                    <span class="string">labels:\n</span>        </span><br><span class="line">                    <span class="attr">app:</span> <span class="string">nginx\n</span>    </span><br><span class="line">                    <span class="string">spec:\n</span>      </span><br><span class="line">                    <span class="string">containers:\n</span>      </span><br><span class="line">                    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17\n</span>        </span><br><span class="line">                    <span class="attr">name:</span> <span class="string">nginx\n</span>        </span><br><span class="line">                    <span class="attr">resources:</span> &#123;&#125;<span class="string">\n</span></span><br><span class="line">                    <span class="attr">status:</span> &#123;&#125;<span class="string">\n&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;version&quot;</span><span class="string">:1</span>,</span><br><span class="line">                    <span class="string">&quot;namespace&quot;</span><span class="string">:&quot;default&quot;</span></span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>

<p>BOOM！看起来就像我们的deployment和service清单！我们可以看到最初的Helm版本中包含的所有信息（确认容器镜像为nginx:1.17）！</p>
<p>因此，通过将这些信息作为secrets存储在目标Kubernetes集群中，即使已删除了旧的replicasets，Helm也可以回滚升级！太酷了！</p>
<p>不过结果还不是很清晰，查看data字段……看起来像是加密信息。</p>
<p>让我们解密吧！这次在命令行上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.testchart.v1 -o jsonpath=&quot;&#123; .data.release &#125;&quot; | base64 -d | gunzip -c | jq &#x27;.chart.templates[].data&#x27; | tr -d &#x27;&quot;&#x27; | base64 -d</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Why-Helm-Can-Solve-Kubernetes-Native-Rollback-Problem/decode-helm-secret.png" alt="decode-helm-secret"></p>
<p>哈！这里有deployment和service的yaml文件！</p>
<p>通过使用Helm，即使已删除deployment的旧replicasets，我们也可以回滚，因为Helm将Release历史记录在secrets并存储在目标Kubernetes集群中。通过使用上面的代码，我们可以解密这些secrets并查看其中包含的信息。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/12/25/k8s/Decoding-A-Helm-Chart-Releases/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/25/k8s/Decoding-A-Helm-Chart-Releases/" class="post-title-link" itemprop="url">解析Helm Char Release内容</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-25 21:05:35" itemprop="dateCreated datePublished" datetime="2020-12-25T21:05:35+00:00">2020-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>如果我们在集群中安装了Helm Chart，可能会想知道Release的存储位置。</p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>让我们从一些背景开始。安装一个简单的Nginx Helm Chart：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm install --name my-release stable/nginx-ingress</span></span><br></pre></td></tr></table></figure>

<p>现在，要获取已安装Helm的详细信息，可以使用四个命令。</p>
<p><strong>helm ls</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm <span class="built_in">ls</span></span> </span><br><span class="line">NAME        REVISION	UPDATED                 	STATUS  	</span><br><span class="line">my-release  1      	    Wed Sep 12 07:41:48 2018	DEPLOYED</span><br></pre></td></tr></table></figure>

<p>通常，我们要运行的第一个命令是helm ls。执行此操作是为了了解我们的集群中当前安装了哪些Helm Chart。无论它们是否失败，<code>STATUS</code>会展示出部署结果是成功还是失败。</p>
<p><strong>helm get</strong></p>
<p>一旦获得安装Chart的名称。下一步通常是尝试更详细地了解安装了什么。<code>helm get</code>命令可以为我们提供帮助。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm get my-release</span></span><br><span class="line">REVISION: 1</span><br><span class="line">RELEASED: Thu Mar 23 15:59:14 2017</span><br><span class="line">CHART: nginx-1.0</span><br><span class="line">USER-SUPPLIED VALUES:</span><br><span class="line">foo: bar</span><br><span class="line"></span><br><span class="line">COMPUTED VALUES:</span><br><span class="line">foo: bar</span><br><span class="line">image: nginx</span><br><span class="line">imagePullPolicy: IfNotPresent</span><br><span class="line">ingress:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">**....**</span>  </span><br></pre></td></tr></table></figure>



<p><strong>helm status</strong></p>
<p>如果我们遇到任何问题，并且希望获得Chart开发人员写下的一些说明。<code>helm status</code>可以通过呈现NOTES.txt文件来帮助我们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ helm status my-release</span><br><span class="line">The nginx-ingress controller has been installed. </span><br><span class="line">Get the application URL by running these commands:</span><br><span class="line">export NODE_IP=$(kubectl --namespace &#123;&#123; .Release.Namespace &#125;&#125; get nodes -o jsonpath=&quot;&#123;.items[0].status.addresses[1].address&#125;&quot;)   </span><br><span class="line">echo &quot;Visit http://10.10.10.10:80 to access your application via HTTP.&quot;  </span><br><span class="line">echo &quot;Visit https://10.10.10.10:443 to access your application via HTTPS.&quot;</span><br></pre></td></tr></table></figure>

<p>上面的Helm状态可以通过values.yaml或–set修改。这是从NOTES.txt呈现的帮助者文本。</p>
<p><strong>helm history</strong></p>
<p>最后，我们还可以获得Chart部署的修订历史记录。当运行<code>helm upgrade</code>命令时会更新版本。假设我们要使用override.yaml覆盖某些值。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm upgrade --install my-release --values override.yaml --<span class="built_in">set</span> foo=notbar nginx</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm <span class="built_in">history</span> my-release</span></span><br><span class="line">REVISION    UPDATED                     STATUS      CHART           DESCRIPTION</span><br><span class="line">1           Thu Mar 23 15:57:40 2020    SUPERSEDED  nginx-0.4.3 Install complete</span><br><span class="line">2           Thu Mar 23 15:59:14 2020    DEPLOYED    nginx-0.4.3 Upgrade complete</span><br></pre></td></tr></table></figure>

<p>所有这些信息都存储在哪里？</p>
<ul>
<li><p>Helm v2版本，默认位置在<code>configmap</code>中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get configmap -n kube-system -l <span class="string">&quot;OWNER=TILLER&quot;</span></span></span><br><span class="line">NAME                     DATA      AGE</span><br><span class="line">my-release.v1          1         7m</span><br><span class="line">my-release.v2          1         6m</span><br></pre></td></tr></table></figure>


</li>
<li><p>Helm v3版本，默认位置在<code>secrets</code>中。<strong>强烈建议这样做</strong>，因为这些数据包含许多有关我们部署的信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get secrets -n kube-system</span></span><br><span class="line">NAME                     DATA      AGE</span><br><span class="line">my-release.v1          1         7m</span><br><span class="line">my-release.v2          1         6m</span><br><span class="line">default-token-43hfuds  1         1d</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="解析Configmap内容"><a href="#解析Configmap内容" class="headerlink" title="解析Configmap内容"></a>解析Configmap内容</h2><p>步骤1. 获取Configmap数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get configmap -n kube-system my-release.v1 -o=jsonpath=<span class="string">&#x27;&#123;.data.release&#125;&#x27;</span> &gt; release-encoded</span></span><br></pre></td></tr></table></figure>

<p>步骤2. 确保编码后的Release包含如下字符串：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">H4sIAAAAAAAC/+w6TY8cS.....</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">you should see a long block of string like above</span></span><br></pre></td></tr></table></figure>

<p>步骤3. 解析数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat release-encoded | base64 -d | gzip -cd &gt; release-decoded</span><br></pre></td></tr></table></figure>

<p>步骤4. 查看数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat release-decoded</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">you should see a whole bunch of data <span class="keyword">for</span> the chart similar to above when you did helm get.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">but also this data contains a lot more like. the actual template. Value rendered.. etc...</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">try it :) i already gave you the commands 🤠⽕😁🏃🏼‍</span></span><br></pre></td></tr></table></figure>

<p>将Chart存储在<code>configmaps</code>中的问题在于，一旦黑客进入我们的集群，它就会成为黑客的金钥匙。将其存储为<code>secrets</code>可以提供某种保护（假设我们对机密信息进行了加密）。☸️</p>
<h2 id="解析Secrets内容"><a href="#解析Secrets内容" class="headerlink" title="解析Secrets内容"></a>解析Secrets内容</h2><p>步骤1. 解析指定版本的Release所有内容（Template内容依然是编码格式）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.my-release.v1 -o jsonpath=&quot;&#123; .data.release &#125;&quot; | base64 -d | gunzip -c | jq .</span><br></pre></td></tr></table></figure>

<p>步骤2. 解析指定版本的Release中的Template内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret sh.helm.release.v1.my-release.v1 -o jsonpath=&quot;&#123; .data.release &#125;&quot; | base64 -d | gunzip -c | jq &#x27;.chart.templates[].data&#x27; | tr -d &#x27;&quot;&#x27; | base64 -d</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：该方法同样适用于解析Configmap内容。</p>
</blockquote>
<h2 id="一些建议"><a href="#一些建议" class="headerlink" title="一些建议"></a>一些建议</h2><p>还有一些保护<code>tiller</code>的方法，例如使用https连接。但是，按照设计，<code>tiller</code>仍然需要大量特权才能在我们的集群中运行。并且仍然违反<strong>最小特权原则</strong>。<strong>我的建议是尽快移至helm3</strong>。</p>
<p>Helm3完全删除了tiller，而是依靠本地计算机的身份验证在群集中工作。默认情况下，它还将Chart数据作为<code>secrets</code>存储在群集中。<strong>Helm2将在2020年12月停止提供安全修复程序</strong>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/11/12/k8s/Kubernetes-Production-Best-Practices/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/12/k8s/Kubernetes-Production-Best-Practices/" class="post-title-link" itemprop="url">Kubernetes生产环境最佳实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-12 22:10:44" itemprop="dateCreated datePublished" datetime="2020-11-12T22:10:44+00:00">2020-11-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本文提供了在Kubernetes上部署安全，可伸缩和弹性服务的最佳实践。内容开源在<a target="_blank" rel="noopener" href="https://github.com/learnk8s/kubernetes-production-best-practices">github仓库</a>。如果有缺少或不足之处，欢迎提issue。</p>
<h2 id="Part1-应用开发"><a href="#Part1-应用开发" class="headerlink" title="Part1 应用开发"></a>Part1 应用开发</h2><h3 id="健康检测"><a href="#健康检测" class="headerlink" title="健康检测"></a><strong>健康检测</strong></h3><ul>
<li><strong>为容器配置Readiness探针</strong><ul>
<li>如果未设置readiness探针，则kubelet会假定该应用程序已准备就绪，可以在容器启动后立即接收流量。</li>
<li>如果容器需要2分钟才能启动，则这2分钟内对容器的所有请求将失败。</li>
</ul>
</li>
<li><strong>发生致命错误时允许容器崩溃</strong><ul>
<li><p>如果应用程序遇到不可恢复的错误，则应使其崩溃。</p>
</li>
<li><p>此类不可恢复的错误的示例是：</p>
<ol>
<li>未捕获的异常</li>
<li>代码中的错字（动态语言）</li>
<li>无法加载标头或依赖项</li>
</ol>
</li>
<li><p>上述错误不应发信号通知Liveness探针失败。相反，应该立即退出该进程，并让kubelet重新启动容器。</p>
</li>
</ul>
</li>
<li><strong>配置被动的Liveness探针</strong><ul>
<li>Liveness探针旨在容器卡住时重新启动容器。</li>
<li>考虑以下情形：如果应用程序正在处理无限循环，则无法退出。当该进程消耗100％的CPU时，将没有时间回复（其他）Readiness探针检查，并且最终将其从服务中删除。但是，该Pod仍被注册为当前Deployment的活动副本。如果没有Liveness探针，它将保持运行状态，但与服务分离。换句话说，该进程不仅不处理任何请求，而且也在消耗资源。</li>
<li>请注意，不应该使用Liveness探针来处理应用程序中的致命错误，并要求Kubernetes重新启动应用程序。相反，应该让应用程序崩溃。仅在过程无响应的情况下，才应将“liveness”探针用作恢复机制。</li>
</ul>
</li>
<li><strong>两个探针的值不同</strong><ul>
<li>当“liveness”和“readiness”探针指向相同的端点时，探针的作用会合并在一起。当应用程序发出信号表明尚未准备就绪或尚待运行时，kubelet会将容器与服务分离并同时将其删除。这时可能会注意到连接断开，因为容器没有足够的时间耗尽当前连接或处理传入的连接。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://freecontent.manning.com/handling-client-requests-properly-with-kubernetes/">handling-client-requests-properly-with-kubernetes&#x2F;</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>请注意，readiness和liveness没有默认值。</p>
</blockquote>
<h3 id="应用独立"><a href="#应用独立" class="headerlink" title="应用独立"></a><strong>应用独立</strong></h3><ul>
<li><p><strong>Readiness探针是独立的</strong></p>
<ul>
<li>Readiness不包括对服务的依赖性，例如：数据库、数据库的迁移、API、第三方服务（<a target="_blank" rel="noopener" href="https://blog.colinbreck.com/kubernetes-liveness-and-readiness-probes-how-to-avoid-shooting-yourself-in-the-foot/#shootingyourselfinthefootwithreadinessprobes">反例</a>）</li>
</ul>
</li>
<li><p><strong>应用重试连接到依赖服务</strong></p>
<ul>
<li>应用启动时，它不应该因为数据库等依赖项尚未就绪而崩溃。相反，应用程序应继续尝试重新连接数据库，直到成功为止。</li>
<li>Kubernetes希望可以以任何顺序启动应用程序。当确保应用程序可以重新连接到诸如数据库之类的依赖项时，便知道可以提供更强大，更灵活的服务。</li>
</ul>
</li>
</ul>
<h3 id="友好关闭"><a href="#友好关闭" class="headerlink" title="友好关闭"></a><strong>友好关闭</strong></h3><ul>
<li><strong>应用程序未通过SIGTERM关闭，但可以正常终止连接</strong><ul>
<li>可能需要一些时间才能感知到诸如kube-proxy或Ingress控制器之类的组件endpoint更改。因此，尽管标记为已终止，流量仍可能流向Pod。</li>
<li>应用程序应停止在所有剩余连接上接受新请求，并在耗尽传出队列后将其关闭。</li>
<li>如果想回顾endpoint在群集中的传播方式，请参考：<a target="_blank" rel="noopener" href="https://freecontent.manning.com/handling-client-requests-properly-with-kubernetes/">handling-client-requests-properly-with-kubernetes&#x2F;</a></li>
</ul>
</li>
<li><strong>应用程序仍在宽限期内处理传入的请求</strong><ul>
<li>可能要考虑使用容器生命周期事件（例如preStop处理程序）来自定义Pod删除之前发生的情况。</li>
</ul>
</li>
<li><strong>Dockerfile中的CMD将SIGTERM转发到进程</strong><ul>
<li>通过在应用中捕获SIGTERM信号，可以在Pod即将终止时收到通知。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://pracucci.com/graceful-shutdown-of-kubernetes-pods.html">graceful-shutdown-of-kubernetes-pods</a></li>
</ul>
</li>
<li><strong>关闭所有空闲的keep-alive套接字</strong><ul>
<li>如果应用程序调用未关闭TCP连接（例如使用TCP保持活动状态或连接池），它将连接到一个Pod，而不使用该服务中的其他Pod。</li>
<li>不应该突然终止长期存在的连接。相反，应该在关闭应用程序之前终止它们。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="http://dillonbuchanan.com/programming/gracefully-shutting-down-a-nodejs-http-server/">gracefully-shutting-down-a-nodejs-http-server</a></li>
</ul>
</li>
</ul>
<h3 id="失败容忍"><a href="#失败容忍" class="headerlink" title="失败容忍"></a><strong>失败容忍</strong></h3><ul>
<li><strong>为Deployment部署运行多个副本</strong><ul>
<li>切勿单独运行一个Pod类型的资源，而是考虑将Pod作为Deployment，DaemonSet，ReplicaSet或StatefulSet的一部分进行部署。</li>
<li>示例参考：<a target="_blank" rel="noopener" href="https://cloudmark.github.io/Node-Management-In-GKE/#replicas">Node-Management-In-GKE</a></li>
</ul>
</li>
<li><strong>避免将Pod放置在单个节点中</strong><ul>
<li>即使运行Pod的多个副本，也无法保证丢失节点不会影响服务。</li>
<li>应该将反关联性规则应用于部署，以便Pod分布在群集的所有节点中。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinit">inter-pod-affinity-and-anti-affinit</a></li>
</ul>
</li>
<li><strong>设定Pod中断预算</strong><ul>
<li>drain节点后，该节点上的所有Pod都将被删除并重新安排。</li>
<li>为了保护Deployment免受可能同时摧毁多个Pod的意外事件的影响，可以定义Pod中断预算。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">pod-disruptions</a></li>
</ul>
</li>
</ul>
<h3 id="资源使用"><a href="#资源使用" class="headerlink" title="资源使用"></a><strong>资源使用</strong></h3><ul>
<li><strong>为所有容器设置内存限制和请求</strong><ul>
<li>资源限制用于限制容器可以使用多少CPU和内存，并使用containerSpec的resources属性设置。</li>
<li>调度程序将这些用作度量标准之一，以确定哪个节点最适合当前Pod。</li>
<li>根据调度程序，没有内存限制的容器的内存利用率为零。</li>
<li>如果可调度在任何节点上的Pod数量不受限制，则会导致资源超负荷使用并可能导致节点（和kubelet）崩溃。</li>
<li>如果容器进程超出内存限制，则该进程将终止。由于CPU是可压缩的资源，因此如果容器超出限制，则将限制该过程。即使它可以使用当时可用的某些CPU。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-memory-6b41e9a955f9">understanding-resource-limits-in-kubernetes-memory</a>，<a target="_blank" rel="noopener" href="https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-cpu-time-9eff74d3161b">understanding-resource-limits-in-kubernetes-cpu</a></li>
</ul>
</li>
<li><strong>将CPU请求设置为1个CPU或以下</strong><ul>
<li>除非有计算密集型作业，否则建议将请求设置为1个CPU或更低.</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xjpHggHKm78">YouTube视频</a></li>
</ul>
</li>
<li><strong>禁用CPU限制—除非有很好的用例</strong><ul>
<li>CPU 资源以 <em>CPU</em> 单位度量。</li>
<li>cpu：1表示每秒1个CPU单位。如果有1个线程，则每秒消耗的CPU时间不能超过1秒。如果有2个线程，则可以在0.5秒内消耗1个CPU单位。8个线程可以在0.125秒内消耗1个CPU单位。此后，请求将受到限制。</li>
<li>如果不确定最佳应用设置，最好不要设置CPU限制。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-cpu-time-9eff74d3161b">understanding-resource-limits-in-kubernetes-cpu</a></li>
</ul>
</li>
<li><strong>命名空间具有LimitRange</strong><ul>
<li>如果我们认为可能忘记设置内存和CPU限制，则应考虑使用LimitRange对象为当前名称空间中部署的容器定义标准大小。</li>
<li>设置方法参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/policy/limit-range/">limit-range</a></li>
</ul>
</li>
<li><strong>为Pod设置适当的服务质量（QoS）</strong><ul>
<li>当节点进入过量使用状态（即使用过多资源）时，Kubernetes会尝试驱逐该节点中的某些Pod。</li>
<li>Kubernetes根据定义明确的逻辑对Pod进行排名和逐出。</li>
<li>设置方法参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/">quality-service-pod</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>请注意，如果不确定如何配置正确的CPU或内存限制，则可以使用Kubernetes中的Vertical Pod Autoscaler。自动缩放器会分析应用并给出建议的值。</p>
</blockquote>
<h3 id="标签资源"><a href="#标签资源" class="headerlink" title="标签资源"></a><strong>标签资源</strong></h3><ul>
<li><strong>定义技术标签</strong></li>
<li><strong>定义业务标签</strong></li>
<li><strong>定义安全标签</strong></li>
</ul>
<h3 id="日志配置"><a href="#日志配置" class="headerlink" title="日志配置"></a><strong>日志配置</strong></h3><ul>
<li><strong>将应用程序日志记录到stdout和stderr</strong><ul>
<li>有两种日志记录策略：被动和主动。使用被动日志记录的应用程序不了解日志记录基础结构，而是将消息记录到标准输出中。</li>
<li>在主动日志记录中，该应用程序与中间聚合器建立网络连接，将数据发送到第三方日志记录服务，或直接写入数据库或索引。主动日志记录被视为反模式，应避免使用它。</li>
<li>最佳实践参考：<a target="_blank" rel="noopener" href="https://12factor.net/logs">logs</a></li>
</ul>
</li>
<li><strong>避免使用sidecar记录日志（如果可以的话）</strong><ul>
<li>如果希望将日志转换应用于具有非标准日志事件模型的应用程序，则可能需要使用sidecar容器。</li>
<li>使用Sidecar容器，可以在将日志条目运送到其他地方之前对其进行规范化。例如，先将Apache日志转换为Logstash JSON格式，然后再将其发送到日志基础结构。但是，如果可以控制应用程序，则可以从一开始就输出正确的格式。这样可以节省为集群中的每个Pod运行额外的容器的时间。</li>
</ul>
</li>
</ul>
<h3 id="Pod扩缩容"><a href="#Pod扩缩容" class="headerlink" title="Pod扩缩容"></a><strong>Pod扩缩容</strong></h3><ul>
<li><strong>容器在其本地文件系统中不存储任何状态</strong><ul>
<li>容器可以访问本地文件系统，用户可能会想使用它来持久化数据。</li>
<li>但是，将持久性数据存储在容器的本地文件系统中会阻止Pod进行水平缩放（即通过添加或删除Pod的副本）。</li>
<li>这是因为，通过使用本地文件系统，每个容器都维护自己的“状态”，这意味着Pod副本的状态可能会随时间而变化。从用户的角度来看，这会导致行为不一致（例如，当请求命中一个Pod时，一条特定的用户信息可用，但当请求命中另一个Pod时，则不可用）。</li>
<li>相反，任何持久性信息都应保存在Pod外部的集中位置。例如，在集群中的PersistentVolume中，或者在集群外部的某些存储服务中甚至更好。</li>
</ul>
</li>
<li><strong>对具有可变使用模式的应用程序使用HPA</strong><ul>
<li>HPA是内置的Kubernetes功能，可监视应用程序并根据当前使用情况自动添加或删除Pod副本。</li>
<li>配置HPA可使应用在任何流量情况下（包括意外的高峰）保持可用并响应。</li>
<li>配置HPA时必须创建一个HorizontalPodAutoscaler资源，该资源定义要监视的应用程序的度量。</li>
<li>HPA可以监视内置资源指标（Pod的CPU和内存使用情况）或自定义指标。对于自定义指标，还负责收集和公开这些指标，例如，可以使用Prometheus和Prometheus Adapter进行此操作。</li>
</ul>
</li>
<li><strong>Vertical Pod Autoscaler仍处于Beta版，请勿使用</strong><ul>
<li>类似于HPA，还有VPA。</li>
<li>VPA可以自动调整Pod的资源请求和限制，以便当Pod需要更多资源时可以获取它们（增加&#x2F;减少单个Pod的资源称为垂直缩放，与水平缩放相对）。</li>
<li>这对于缩放无法水平缩放的应用程序很有用。</li>
<li>但是，HPA当前处于beta版本，它具有一些已知的局限性（例如，通过更改其资源要求来扩展Pod，要求终止Pod并重新启动它）。</li>
<li>考虑到这些限制以及Kubernetes上大多数应用程序都可以水平扩展的事实，建议不要在生产环境中使用VPA（至少要等到稳定的版本才能使用）。</li>
</ul>
</li>
<li><strong>如果工作负载差异很大，请使用群集自动伸缩放器</strong><ul>
<li>群集自动缩放器是“自动缩放器”的另一种类型（HAP和VPA除外）。</li>
<li>群集自动缩放器可以通过添加或删除工作节点来自动缩放群集的大小。</li>
<li>当由于现有工作节点上的资源不足而无法调度Pod时，会进行放大操作。在这种情况下，Cluster Autoscaler将创建一个新的工作节点，以便可以调度Pod。同样，当现有工作节点的利用率较低时，群集自动伸缩程序可以通过从一个工作节点中逐出所有工作负载并将其删除来进行缩减。</li>
<li>对于高度可变的工作负载，例如当Pods的数量可能在短时间内成倍增长然后返回到先前的值时，使用Cluster Autoscaler是有意义的。在这种情况下，群集自动伸缩器可以满足需求高峰，而不会通过过度配置工作节点来浪费资源。</li>
<li>但是，如果工作负载变化不大，则可能不值得设置Cluster Autoscaler，因为它可能永远不会触发。如果工作负载缓慢且单调地增长，则足以监视现有工作节点的利用率并在达到临界值时手动添加其他工作节点。</li>
</ul>
</li>
</ul>
<h3 id="配置原则"><a href="#配置原则" class="headerlink" title="配置原则"></a><strong>配置原则</strong></h3><ul>
<li><strong>外部化所有配置</strong><ul>
<li>配置应在应用程序代码之外进行维护。</li>
<li>这有几个好处。首先，更改配置不需要重新编译应用程序。其次，可以在应用程序运行时更新配置。第三，相同的代码可以在不同的环境中使用。</li>
<li>在Kubernetes中，可以将配置保存在ConfigMaps中，然后可以在将卷作为环境变量传入时将其安装到容器中。</li>
<li>在ConfigMap中仅保存非敏感配置。对于敏感信息（例如凭据），请使用Secret资源。</li>
</ul>
</li>
<li><strong>将Secrets作为卷而不是环境变量安装</strong><ul>
<li>Secret资源的内容应作为卷装入容器中，而不应作为环境变量传递。</li>
<li>这是为了防止秘密值出现在用于启动容器的命令中，该命令可能由不应该访问秘密值的人员看到。</li>
</ul>
</li>
</ul>
<h2 id="Part2-集群管理"><a href="#Part2-集群管理" class="headerlink" title="Part2 集群管理"></a>Part2 集群管理</h2><h3 id="命名空间限制"><a href="#命名空间限制" class="headerlink" title="命名空间限制"></a><strong>命名空间限制</strong></h3><ul>
<li><strong>命名空间具有LimitRange</strong><ul>
<li>没有限制的容器可能导致与其他容器的资源争用以及计算资源的消耗。</li>
<li>Kubernetes具有两个限制资源利用的功能：ResourceQuota和LimitRange。</li>
<li>使用LimitRange对象，可以定义资源请求的默认值以及名称空间内单个容器的限制。</li>
<li>在该命名空间内创建的，未明确指定请求和限制值的任何容器都将分配为默认值。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">resource-quotas</a></li>
</ul>
</li>
<li><strong>命名空间具有ResourceQuotas</strong><ul>
<li>使用ResourceQuotas，可以限制命名空间内所有容器的总资源消耗。</li>
<li>定义命名空间的资源配额会限制属于该名称空间的所有容器可以消耗的CPU，内存或存储资源的总量。</li>
<li>还可以为其他Kubernetes对象设置配额，例如当前名称空间中的Pod数量。</li>
<li>如果存在他人使用群集并创建20000 ConfigMap，则可以使用LimitRange来防止这种情况。</li>
</ul>
</li>
</ul>
<h3 id="Pod安全策略"><a href="#Pod安全策略" class="headerlink" title="Pod安全策略"></a><strong>Pod安全策略</strong></h3><ul>
<li><p><strong>启用Pod安全策略</strong></p>
<ul>
<li>例如，可以使用Kubernetes Pod安全策略来限制：<ol>
<li>访问主机进程或网络名称空间；</li>
<li>运行特权容器容器；</li>
<li>运行的用户；</li>
<li>访问主机文件系统；</li>
<li>Linux功能，Seccomp或SELinux配置文件</li>
</ol>
</li>
<li>选择正确的策略取决于集群的性质。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://resources.whitesourcesoftware.com/blog-whitesource/kubernetes-pod-security-policy">kubernetes-pod-security-policy</a></li>
</ul>
</li>
<li><p><strong>禁用特权容器</strong></p>
<ul>
<li>在Pod中，容器可以以“特权”模式运行，并且对主机系统上的资源的访问几乎不受限制。</li>
<li>尽管在某些特定的用例中，必须具有这种级别的访问权限，但总的来说，让容器执行此操作存在安全风险。</li>
<li>特权Pod的有效使用案例包括在节点上使用硬件，例如GPU。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">security-context</a></li>
</ul>
</li>
<li><p><strong>在容器中使用只读文件系统</strong></p>
<ul>
<li>在容器中运行只读文件系统会强制容器不可变。</li>
<li>这不仅减轻了一些旧的（且有风险的）做法（例如热修补），而且还帮助防止了恶意进程在容器内存储或操作数据的风险。</li>
<li>使用只读文件系统运行容器听起来可能很简单，但是可能会带来一些复杂性。</li>
<li>如果需要写日志或将文件存储在临时文件夹中怎么办？</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@axbaretto/running-docker-containers-securely-in-production-98b8104ef68">running-docker-containers-securely-in-production</a></li>
</ul>
</li>
<li><p><strong>防止容器以root身份运行</strong></p>
<ul>
<li>在容器中运行的进程与主机上的任何其他进程没有什么不同，只不过它有一小部分元数据声明它在容器中。</li>
<li>因此，容器中的根与主机上的根（uid 0）相同。</li>
<li>如果用户设法脱离了以root用户身份在容器中运行的应用程序，则他们可能能够使用同一root用户获得对主机的访问权限。</li>
<li>配置容器以使用非特权用户是防止特权升级攻击的最佳方法。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b">processes-in-containers-should-not-run-as-root</a></li>
</ul>
</li>
<li><p><strong>限制capabilities</strong></p>
<ul>
<li><p>Linux capabilities使进程能够执行许多特权操作，其中只有root用户默认可以执行。</p>
</li>
<li><p>例如，CAP_CHOWN允许进程“对文件UID和GID进行任意更改”。</p>
</li>
<li><p>即使进程不是以root身份运行，进程也有可能通过提升特权来使用那些类似root的功能。</p>
</li>
<li><p>换句话说，如果不想受到损害，则应仅启用所需的功能。</p>
</li>
<li><p>但是应该启用什么功能？为什么？以下两篇文章探讨了有关Linux内核功能的理论和最佳实践：</p>
<p><a target="_blank" rel="noopener" href="https://blog.container-solutions.com/linux-capabilities-why-they-exist-and-how-they-work">Linux Capabilities: Why They Exist and How They Work</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.container-solutions.com/linux-capabilities-in-practice">Linux Capabilities In Practice</a></p>
</li>
</ul>
</li>
<li><p><strong>防止特权升级</strong></p>
<ul>
<li>应该在关闭特权升级的情况下运行容器，以防止使用setuid或setgid二进制文件提升特权。</li>
</ul>
</li>
</ul>
<h3 id="网络策略"><a href="#网络策略" class="headerlink" title="网络策略"></a><strong>网络策略</strong></h3><ul>
<li><strong>启用网络策略</strong><ul>
<li>Kubernetes网络策略指定Pod组的访问权限，就像云中的安全组用于控制对VM实例的访问一样。</li>
<li>换句话说，它在Kubernetes集群上运行的Pod之间创建了防火墙。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://ahmet.im/blog/kubernetes-network-policy/">Securing Kubernetes Cluster Networking</a></li>
</ul>
</li>
<li><strong>每个命名空间中都有一个保守的NetworkPolicy</strong><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ahmetb/kubernetes-network-policy-recipes">存储库</a>包含Kubernetes网络策略的各种用例和示例YAML文件。</li>
<li>如果想知道如何丢弃&#x2F;限制在Kubernetes上运行的应用程序的流量，请阅读<a target="_blank" rel="noopener" href="https://github.com/ahmetb/kubernetes-network-policy-recipes">how to drop&#x2F;restrict traffic to applications running on Kubernetes</a>。</li>
</ul>
</li>
</ul>
<h3 id="RBAC策略"><a href="#RBAC策略" class="headerlink" title="RBAC策略"></a><strong>RBAC策略</strong></h3><ul>
<li><strong>禁用默认服务帐户的自动挂载RBAC策略</strong><ul>
<li>请注意，默认的ServiceAccount将自动安装到所有Pod的文件系统中，详见<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server">use-the-default-service-account-to-access-the-api-server</a></li>
<li>可能要禁用它并提供更详细的策略。</li>
</ul>
</li>
<li><strong>设置为所需的最少特权</strong><ul>
<li>寻找有关如何设置RBAC规则的好的建议是一项挑战。</li>
<li>在<a target="_blank" rel="noopener" href="https://thenewstack.io/three-realistic-approaches-to-kubernetes-rbac/">Kubernetes RBAC的3种现实方法</a>中，可以找到三种实用场景和有关如何入门的实用建议。</li>
</ul>
</li>
<li><strong>RBAC策略是精细的，不能共享</strong><ul>
<li>Zalando有一个简洁的策略来定义角色和ServiceAccounts。</li>
<li>首先，他们描述他们的要求：<ol>
<li>用户应该能够部署，但不应允许他们查看如“secret”这类资源</li>
<li>管理员应拥有对所有资源的完全访问权限</li>
<li>默认情况下，应用程序不应获得对Kubernetes API的写访问权限</li>
<li>对于某些用途，可以有Kubernetes API写权限。</li>
</ol>
</li>
<li>四个要求转化为五个单独的角色：<ol>
<li>ReadOnly</li>
<li>PowerUser</li>
<li>Operator</li>
<li>Controller</li>
<li>Admin</li>
</ol>
</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://kubernetes-on-aws.readthedocs.io/en/latest/dev-guide/arch/access-control/adr-004-roles-and-service-accounts.html">access-control-roles-and-service-accounts</a></li>
</ul>
</li>
</ul>
<h3 id="自定义策略"><a href="#自定义策略" class="headerlink" title="自定义策略"></a><strong>自定义策略</strong></h3><ul>
<li><strong>只允许从已知registry部署容器</strong><ul>
<li>可能要考虑的最常见的自定义策略之一是限制可以在群集中部署的镜像。</li>
<li><a target="_blank" rel="noopener" href="https://blog.openpolicyagent.org/securing-the-kubernetes-api-with-open-policy-agent-ce93af0552c3#3c6e">参考文档</a>说明了如何使用开放策略代理来限制未批准的镜像。</li>
</ul>
</li>
<li><strong>强制Ingress主机名唯一</strong><ul>
<li>用户创建Ingress清单时，可以使用其中的任何主机名。</li>
<li>但是，可能希望阻止用户多次使用相同的主机名并互相覆盖。</li>
<li>Open Policy Agent的<a target="_blank" rel="noopener" href="https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/#4-define-a-policy-and-load-it-into-opa-via-kubernetes">官方文档</a>包含有关如何在validation Webhook中检查Ingress资源的教程。</li>
</ul>
</li>
<li><strong>仅在Ingress主机名中使用批准的域名</strong><ul>
<li>用户创建Ingress清单时，可以使用其中的任何主机名。</li>
<li>但是，可能希望阻止用户使用无效的主机名。</li>
<li>Open Policy Agent的<a target="_blank" rel="noopener" href="https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/#4-define-a-policy-and-load-it-into-opa-via-kubernetes">官方文档</a>包含有关如何在validation Webhook中检查Ingress资源的教程。</li>
</ul>
</li>
</ul>
<h2 id="Part3-集群配置"><a href="#Part3-集群配置" class="headerlink" title="Part3 集群配置"></a>Part3 集群配置</h2><blockquote>
<p>该部分还在进行中。如果对这部分内容有意见，欢迎提issue。</p>
</blockquote>
<h3 id="集群要求"><a href="#集群要求" class="headerlink" title="集群要求"></a><strong>集群要求</strong></h3><ul>
<li><p><strong>集群通过CIS基准测试</strong></p>
<ul>
<li>互联网安全中心提供了一些准则和基准测试，以确保代码安全的最佳做法</li>
<li>他们还维护了Kubernetes的基准，可以从<a target="_blank" rel="noopener" href="https://www.cisecurity.org/benchmark/kubernetes/">官方网站</a>上下载该基准。</li>
<li>虽然可以阅读冗长的指南并手动检查集群是否符合要求，但更简单的方法是下载并执行<a target="_blank" rel="noopener" href="https://github.com/aquasecurity/kube-bench">kube-bench</a>。</li>
<li>kube-bench是一个工具，用于自动执行CIS Kubernetes基准测试并报告集群中的错误配置。</li>
</ul>
<blockquote>
<p>请注意，无法使用kube-bench检查托管集群（例如GKE，EKS和AKS）的主节点。主节点由云提供商控制。</p>
</blockquote>
</li>
<li><p><strong>禁用云提供商的元数据API</strong></p>
<ul>
<li>云平台（AWS，Azure，GCE等）通常将本地元数据服务公开给实例。</li>
<li>默认情况下，实例上运行的Pod可以访问这些API，并且可以包含该节点的云凭据或诸如kubelet凭据之类的置备数据。</li>
<li>这些凭据可用于在群集内升级或升级到同一帐户下的其他云服务。</li>
</ul>
</li>
<li><p><strong>限制对Alpha或Beta功能的访问</strong></p>
<ul>
<li>Alpha和Beta Kubernetes功能正在积极开发中，可能会存在限制或错误，从而导致安全漏洞。</li>
<li>始终评估Alpha或Beta功能可能提供的价值，以防对安全状况造成潜在风险。</li>
<li>如有疑问，请禁用不使用的功能。</li>
</ul>
</li>
</ul>
<h3 id="身份认证"><a href="#身份认证" class="headerlink" title="身份认证"></a><strong>身份认证</strong></h3><ul>
<li><p><strong>使用OpenID（OIDC）令牌作为用户身份验证策略</strong></p>
<ul>
<li>Kubernetes支持各种身份验证方法，包括OpenID Connect（OIDC）。</li>
<li>OpenID Connect允许单点登录（SSO）（例如Google身份）连接到Kubernetes集群和其他开发工具。</li>
<li>无需单独记住或管理凭据。</li>
<li>可能有多个群集连接到同一OpenID提供程序。</li>
<li>更多信息参考：<a target="_blank" rel="noopener" href="https://thenewstack.io/kubernetes-single-sign-one-less-identity/">kubernetes-single-sign-one-less-identity</a></li>
</ul>
</li>
<li><p><strong>ServiceAccount令牌仅适用于应用程序和控制器</strong></p>
<ul>
<li>ServiceAccount不应用于尝试与Kubernetes群集进行交互的最终用户，但对于在Kubernetes上运行的应用程序和工作负载，它们是首选的身份验证策略。</li>
</ul>
</li>
</ul>
<h3 id="日志设置"><a href="#日志设置" class="headerlink" title="日志设置"></a><strong>日志设置</strong></h3><ul>
<li><strong>有一个日志保留和归档策略</strong><ul>
<li>应该保留30-45天的历史日志。</li>
</ul>
</li>
<li><strong>从节点，控制平面，审计中收集日志</strong><ul>
<li>从哪些地方收集日志：<ol>
<li>节点 (kubelet, container runtime)</li>
<li>控制平面 (API server, scheduler, controller manager)</li>
<li>Kubernetes审计 (all requests to the API server)</li>
</ol>
</li>
<li>应该收集什么：<ol>
<li>应用名称。从元数据标签中检索。</li>
<li>应用程序实例。从元数据标签中检索。</li>
<li>应用程序版本。从元数据标签中检索。</li>
<li>集群ID。从Kubernetes集群检索。</li>
<li>容器名称。从Kubernetes API检索。</li>
<li>运行此容器的群集节点。从Kubernetes集群检索。</li>
<li>运行容器的Pod名称。从Kubernetes集群检索。</li>
<li>命名空间。从Kubernetes集群检索。</li>
</ol>
</li>
</ul>
</li>
<li><strong>在每个节点上最好有一个守护程序来收集日志，而不是sidecar</strong><ul>
<li>应用程序日志应输出到标准输出，而不是文件。</li>
<li>每个节点上的守护程序可以从容器运行时收集日志（如果记录到文件，则可能需要每个pod的sidecar容<strong>器）。</strong></li>
</ul>
</li>
<li><strong>提供日志聚合工具</strong><ul>
<li>使用日志聚合工具，例如EFK技术栈（Elasticsearch，Fluentd，Kibana），DataDog，Sumo Logic，Sysdig，GCP Stackdriver，Azure Monitor，AWS CloudWatch。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/10/21/docker/Create-Tag-Retention-Rules/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/21/docker/Create-Tag-Retention-Rules/" class="post-title-link" itemprop="url">Harbor中如何创建tag保留规则</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-21 20:26:07" itemprop="dateCreated datePublished" datetime="2020-10-21T20:26:07+00:00">2020-10-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="创建Tag保留规则"><a href="#创建Tag保留规则" class="headerlink" title="创建Tag保留规则"></a>创建Tag保留规则</h2><p>一个repository可以快速积累大量镜像tag，在给定时间之后或一旦它们被后续镜像构建取代后，可能不需要许多镜像tag。这些多余的tag显然会消耗大量的存储容量。作为Harbor系统管理员，可以定义规则来管理给定repository中要保留多少个tag，或将某些tag保留多长时间。</p>
<h2 id="Tag保留规则如何工作"><a href="#Tag保留规则如何工作" class="headerlink" title="Tag保留规则如何工作"></a>Tag保留规则如何工作</h2><p>在repositories上而不是projects上定义tag保留规则（<em>repository属于project内的概念</em>）。在定义保留规则时，这可以提供更大的粒度。顾名思义，当我们为repositories定义保留规则时，也即在定义要保留的tag。我们没有定义规则来显式删除tag，而是当设置规则时，repositories中任何未标识为可保留的标记都将被丢弃。</p>
<p>tag保留规则具有3个按顺序应用的过滤器，如下表所述。</p>
<table>
<thead>
<tr>
<th align="left">Order</th>
<th align="left">Filter</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">First</td>
<td align="left">一个或多个repository</td>
<td align="left">标识要在其上应用规则的一个或多个repository。可以标识具有特定名称或名称片段的repository，或者不具有该名称或名称片段的repository。允许使用通配符（例如* repo，repo *和**）。首先使用repository filter以标记要对其应用保留规则的repository。根据标签标准，将识别出的repository指定用于进一步匹配。在此阶段，对没有指定的repository不采取任何措施。</td>
</tr>
<tr>
<td align="left">Second</td>
<td align="left">保留数量</td>
<td align="left">通过指定最大数量的标签或指定最大保留标签的时间来设置要保留的标签。</td>
</tr>
<tr>
<td align="left">Third</td>
<td align="left">要保留的标签</td>
<td align="left">标识要应用规则的一个或多个标签。可以标识具有特定名称或名称片段的标签，或者不具有该名称或名称片段的标签。允许使用通配符（例如* tag，tag *和**）。</td>
</tr>
</tbody></table>
<p>有关如何应用**通配符的信息，请参见<a target="_blank" rel="noopener" href="https://github.com/bmatcuk/doublestar#patterns%E3%80%82">https://github.com/bmatcuk/doublestar#patterns。</a></p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h3><ul>
<li>在一个project中有5个repositories，repositories A到E。<ul>
<li>repository A具有100个镜像tag，所有这些镜像tag均已在上周有pull操作。</li>
<li>repository B到E每个都有6个镜像，上个月都没有pull操作。</li>
</ul>
</li>
<li>将repositories过滤器设置为**，这意味着包括了project中的所有repositories。</li>
<li>设置保留策略，以在每个repositories中保留最近提取的10个映像。</li>
<li>将标签过滤器设置为**，这意味着包括repositories中的所有标签。</li>
</ul>
<p>在此示例中，规则在repository A中保留了10个最近有pull操作的镜像，并且在repository B至E中的每一个中都保留了所有6个镜像。因此，project中总共保留了34个镜像tag。换句话说，该规则不会将repository A到E中的所有镜像都视为单个池，然后从中选择10个最新镜像。因此，即使repository A中的第11至第100个标签比repository B至E中的任何标签相比都有pull操作，也将保留repository B至E中的所有标签，因为每个repository中的标签少于10个。</p>
<h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h3><p>本示例使用与示例1相同的project和repositories，但设置了保留策略以保留每个repository中最近7天内有pull操作的镜像。</p>
<p>在这种情况下，保留了repository A中的所有镜像，因为它们是最近7天内有pull操作的。repository B到E中的任何镜像都不会保留，因为它们在上周都没有发生pull操作。在此示例中，保留了100个镜像，而示例1中则保留了34个镜像。</p>
<h2 id="Tag保留规则和原生Docker-Tag删除问题"><a href="#Tag保留规则和原生Docker-Tag删除问题" class="headerlink" title="Tag保留规则和原生Docker Tag删除问题"></a>Tag保留规则和原生Docker Tag删除问题</h2><p><strong>警告</strong>：由于本机Docker tag删除行为，当前的保留策略实施存在问题。如果有多个tag引用相同的SHA摘要，并且如果这些tag的子集被配置的保留策略标记为要删除，则所有其余tag也将被删除。这违反了保留策略，因此在这种情况下，所有tag都将保留。在以后的更新版本中将解决此问题，以便tag保留策略可以删除tag而不删除摘要和其他共享tag。</p>
<p>例如，我们有以下tag，这些tag根据其推送时间列出，并且它们都引用相同的SHA摘要：</p>
<ul>
<li><code>harbor-1.8</code>, pushed 8&#x2F;14&#x2F;2019 12:00am</li>
<li><code>harbor-release</code>, pushed 8&#x2F;14&#x2F;2019 03:00am</li>
<li><code>harbor-nightly</code>, pushed 8&#x2F;14&#x2F;2019 06:00am</li>
<li><code>harbor-latest</code>, pushed 8&#x2F;14&#x2F;2019 09:00am</li>
</ul>
<p>如果配置了保留策略，以保留与Harbor- *匹配的两个最新标记，以便删除Harbor-rc和Harbor-latest。但是，由于所有tag都引用相同的SHA摘要，因此此策略还将删除标签Harbor-1.8和Harbor-release，因此将保留所有标签。（时间和删除的tag有点对不上）</p>
<h2 id="在一个Repository上合并规则"><a href="#在一个Repository上合并规则" class="headerlink" title="在一个Repository上合并规则"></a>在一个Repository上合并规则</h2><p>每个project最多可以定义15条规则。我们可以将多个规则应用于一个repository或一组repositories。在将多个规则应用于repository 时，它们将使用OR逻辑而不是AND逻辑来应用。这样，就不会在给定的repository 上优先应用规则。规则在后台同时运行，每个规则的结果集在运行结束时合并。</p>
<h3 id="Example-3"><a href="#Example-3" class="headerlink" title="Example 3"></a>Example 3</h3><p>本示例使用与示例1和2相同的project和repositories，但是设置了两个规则：</p>
<ul>
<li>规则1：保留每个repository中最近7天内pull操作的所有镜像。</li>
<li>规则2：每个repository中最多保留10个镜像。</li>
</ul>
<p>对于repository A，规则1保留所有镜像，因为它们都是在上周发生pull操作的。规则2保留最近发生pull操作的10个镜像。因此，由于这两个规则是通过OR关系应用的，所有100个镜像都保留在repository A中。</p>
<p>对于repositories B-E，规则1将保留0个镜像，因为上周未发生pull操作。规则2将保留所有6个镜像，因为6 &lt;10。因此，由于这两个规则以OR关系应用，对于repositories B-E，每个repository将保留所有6个图像。</p>
<p>在此示例中，所有镜像均被保留。</p>
<h3 id="Example-4"><a href="#Example-4" class="headerlink" title="Example 4"></a>Example 4</h3><p>本示例使用与先前示例不同的repository。</p>
<ul>
<li><p>包含12个tag的repository：</p>
<table>
<thead>
<tr>
<th align="left">Production</th>
<th align="left">Release Candidate</th>
<th align="left">Release</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>2.1-your_repo-prod</code></td>
<td align="left"><code>2.1-your_repo-rc</code></td>
<td align="left"><code>2.1-your_repo-release</code></td>
</tr>
<tr>
<td align="left"><code>2.2-your_repo-prod</code></td>
<td align="left"><code>2.2-your_repo-rc</code></td>
<td align="left"><code>2.2-your_repo-release</code></td>
</tr>
<tr>
<td align="left"><code>3.1-your_repo-prod</code></td>
<td align="left"><code>3.1-your_repo-rc</code></td>
<td align="left"><code>3.1-your_repo-release</code></td>
</tr>
<tr>
<td align="left"><code>4.4-your_repo-prod</code></td>
<td align="left"><code>4.4-your_repo-rc</code></td>
<td align="left"><code>4.4-your_repo-release</code></td>
</tr>
</tbody></table>
</li>
<li><p>在此repository上定义了3个tag保留规则：</p>
<ul>
<li><p>保留以2开头的10个最近发生pull操作的镜像tag。</p>
</li>
<li><p>保留以-prod结尾的10个最近发生pull操作的镜像tag。</p>
</li>
<li><p>保留所有不包含2.1-your_repo-prod的tag。</p>
</li>
</ul>
</li>
</ul>
<p>在此示例中，规则将应用于以下7个tag（与预期不符，官方收到反馈后已修改）：</p>
<ul>
<li><code>2.1-your_repo-rc</code></li>
<li><code>2.1-your_repo-release</code></li>
<li><code>2.2-your_repo-prod</code></li>
<li><code>2.2-your_repo-rc</code></li>
<li><code>2.2-your_repo-release</code></li>
<li><code>3.1-your_repo-prod</code></li>
<li><code>4.4-your_repo-prod</code></li>
</ul>
<h2 id="Tag保留规则如何与项目配额搭配使用"><a href="#Tag保留规则如何与项目配额搭配使用" class="headerlink" title="Tag保留规则如何与项目配额搭配使用"></a>Tag保留规则如何与项目配额搭配使用</h2><p>Harbor系统管理员可以设置一个project可以包含的tag数量及其可以使用的存储量的最大值。有关project配额的信息，请参阅<a target="_blank" rel="noopener" href="https://goharbor.io/docs/1.10/administration/configure-project-quotas/">配置project配额</a>。</p>
<p>如果在project上设置配额，则不能超过该配额。即使设置的保留规则超过配额，配额也将应用于project。换句话说，不能使用保留规则来绕过配额。</p>
<h2 id="配置Tag保留规则实例"><a href="#配置Tag保留规则实例" class="headerlink" title="配置Tag保留规则实例"></a>配置Tag保留规则实例</h2><ol>
<li><p>使用至少具有项目管理员特权的帐户登录到Harbor界面。</p>
</li>
<li><p>转到”project”，选择一个project，然后选择tag保留。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention1.png" alt="tag-retention"></p>
</li>
<li><p>单击”添加规则”以添加规则。</p>
</li>
<li><p>在“repositories”下拉菜单中，选择匹配或排除。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention3.png" alt="tag-retention"></p>
</li>
<li><p>在“repositories”文本框中，标识要在其上应用规则的repository。</p>
<p>可以通过输入以下信息来定义要在哪些repositories上应用规则：</p>
</li>
</ol>
<ul>
<li><p>repository名称，例如my_repo_1。</p>
</li>
<li><p>以逗号分隔的repository名称列表，例如my_repo_1，my_repo_2，your_repo_3。</p>
</li>
<li><p>带通配符的部分repository名称，例如my _ <em>，</em> _ 3或*<em>repo</em>*。</p>
</li>
<li><p>**将规则应用于project中的所有repositories。</p>
<p> 如果选择<strong>匹配</strong>，则规则将应用于标识的repository。如果选择<strong>排除</strong>，则该规则将应用于project中除已标识的repositories之外的所有repositories。</p>
</li>
</ul>
<ol start="6">
<li><p>在“按镜像或天数计数”下拉菜单中，定义要保留的tag数量或保留的时间。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention4.png" alt="tag-retention"></p>
</li>
</ol>
<table>
<thead>
<tr>
<th align="left">Option</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>retain the most recently pushed # images</strong></td>
<td align="left">输入要保留的最大镜像个数，保留最近发生push操作的镜像。不考虑镜像的时间。</td>
</tr>
<tr>
<td align="left"><strong>retain the most recently pulled # images</strong></td>
<td align="left">输入要保留的最大镜像个数，保留最近发生pull操作的镜像。不考虑镜像的时间。</td>
</tr>
<tr>
<td align="left"><strong>retain the images pushed within the last # days</strong></td>
<td align="left">输入保留镜像的天数，仅保留在此期间发生push操作的镜像。不考虑镜像数量。</td>
</tr>
<tr>
<td align="left"><strong>retain the images pulled within the last # days</strong></td>
<td align="left">输入保留镜像的天数，仅保留在此期间发生pull操作的镜像。不考虑镜像数量。</td>
</tr>
<tr>
<td align="left"><strong>retain always</strong></td>
<td align="left">始终保留此规则标识的镜像。</td>
</tr>
</tbody></table>
<ol start="7">
<li><p>在”tag”下拉菜单中，选择匹配或排除。  </p>
</li>
<li><p>在“标签”文本框中，标识要在其上应用规则的tag。</p>
<p>可以通过输入以下信息来定义要在其上应用规则的tag：</p>
</li>
</ol>
<ul>
<li>tag名称，例如my_tag_1。</li>
<li>tag名称的逗号分隔列表，例如my_tag_1，my_tag_2，your_tag_3。</li>
<li>带通配符的部分tag名称，例如my _ <em>，</em> _ 3或* <em>tag</em> *。</li>
<li>**将规则应用于project中的所有tag。</li>
</ul>
<ol start="9">
<li><p>单击”添加”以保存规则。</p>
</li>
<li><p>（可选）单击“添加规则”以添加更多规则，每个project最多15条。</p>
</li>
<li><p>（可选）在“计划”下，单击“编辑”，然后选择运行规则的频率。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention2.png" alt="tag-retention"></p>
<p>如果选择“自定义”，请输入cron job命令以配置规则。</p>
<p>注意：如果定义多个规则，则计划将应用于所有规则。不能配置不同的规则在不同的时间运行。</p>
</li>
<li><p>单击“模拟运行”以测试定义的一个或多个规则。</p>
</li>
<li><p>单击“立即运行”以立即运行规则。</p>
</li>
</ol>
<p><strong>警告</strong>：运行规则后，将无法还原它。强烈建议先执行模拟运行，然后再运行规则。</p>
<p>要修改现有规则，请使用规则旁边的操作下拉菜单来禁用，编辑或删除该规则。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/docker/Create-Tag-Retention-Rules/tag-retention5.png" alt="tag-retention"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/08/24/k8s/Determine-best-networking-option/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/24/k8s/Determine-best-networking-option/" class="post-title-link" itemprop="url">Calico中的网络模式选择最佳实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-24 22:09:22" itemprop="dateCreated datePublished" datetime="2020-08-24T22:09:22+00:00">2020-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Big-picture"><a href="#Big-picture" class="headerlink" title="Big picture"></a>Big picture</h3><p>了解Calico支持的各种网络选项，以便可以根据需要选择最佳选项。</p>
<h3 id="Value"><a href="#Value" class="headerlink" title="Value"></a>Value</h3><p>Calico灵活的模块化体系结构支持广泛的部署选项，因此可以根据自己的特定环境和需求选择最佳的网络方案。这包括在BGP和非BGP的情况下，以underlying或overlay模式与各种CNI和IPAM插件以及基础网络类型一起运行的能力。</p>
<h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><p>如果想完全了解可用的网络选项，我们建议确保自己熟悉并理解以下概念。如果希望跳过学习并直接获得选择和建议，则可以跳至“网络选项”。</p>
<h4 id="Kubernetes网络基础知识"><a href="#Kubernetes网络基础知识" class="headerlink" title="Kubernetes网络基础知识"></a>Kubernetes网络基础知识</h4><p>Kubernetes网络模型定义了一个“扁平”网络，其中：</p>
<ul>
<li>每个Pod都有自己的IP地址。	</li>
<li>无需NAT，任何节点上的Pod均可与所有其他节点上的所有Pod通信。</li>
</ul>
<p>这将创建一个干净的，向后兼容的模型，从端口分配，命名，服务发现，负载平衡，应用程序配置和迁移的角度来看，可以将Pod像VM或物理主机一样对待。可以使用网络策略来定义网络分段，以将流量限制在这些基本网络功能内。</p>
<p>在此模型中，可以灵活地支持不同的网络方案和环境。确切地如何实现网络的详细信息取决于所使用的CNI，网络和云提供商插件的组合。</p>
<h4 id="CNI插件"><a href="#CNI插件" class="headerlink" title="CNI插件"></a>CNI插件</h4><p>CNI（容器网络接口）是一个标准API，允许将不同的网络实现插入Kubernetes。每当创建或销毁Pod时，Kubernetes都会调用API。CNI插件有两种类型：</p>
<ul>
<li>CNI网络插件：负责向Kubernetes Pod网络中添加Pod或从Kubernetes Pod网络中删除Pod。这包括创建&#x2F;删除每个Pod的网络接口，以及将其连接&#x2F;断开与其他网络实现的连接。</li>
<li>CNI IPAM插件：负责在Pod创建或删除时分配和释放Pod的IP地址。根据插件的不同，这可能包括为每个节点分配一个或多个IP地址（CIDR）范围，或从底层公共云网络获取IP地址以分配给Pod。</li>
</ul>
<h4 id="云提供商集成"><a href="#云提供商集成" class="headerlink" title="云提供商集成"></a>云提供商集成</h4><p>Kubernetes云提供商集成是特定于云的控制器，可以配置基础云网络以帮助提供Kuberenetes网络。根据云提供商的不同，这可能包括自动将路由编程到基础云网络中，以便它本机知道如何路由Pod流量。</p>
<h4 id="Kubenet"><a href="#Kubenet" class="headerlink" title="Kubenet"></a>Kubenet</h4><p>Kubenet是Kubernetes中内置的一个非常基本的网络插件。它没有实现跨节点通信或网络策略。它通常与云提供商集成一起使用，后者在云提供商网络中设置路由以在节点之间或在单节点环境中进行通信。Kubenet与Calico不兼容。</p>
<h4 id="Overlay网络"><a href="#Overlay网络" class="headerlink" title="Overlay网络"></a>Overlay网络</h4><p>overlay网络是位于另一个网络之上的网络。在Kubernetes的上下文中，overlay网络可用于处理基础网络顶部节点之间的Pod到Pod流量，这些节点不知道Pod IP地址或哪些Pod在哪些节点上运行。overlay网络通过将基础网络不知道如何处理（例如使用Pod IP地址）的网络数据包封装在基础网络确实知道如何处理的外部数据包（例如节点IP地址）中。用于封装的两种常见网络协议是VXLAN和IP-in-IP。</p>
<p>使用overlay网络的主要优点是它减少了对基础网络的依赖性。例如，可以在几乎任何基础网络之上运行VXLAN，而无需与基础网络集成或对其进行任何更改。</p>
<p>使用overlay网络的主要缺点是：</p>
<ul>
<li>对性能有轻微影响。封装数据包的过程占用少量CPU，并且数据包中用于编码封装（VXLAN或IP-in-IP标头）所需的额外字节减少了可以发送的内部数据包的最大大小，这意味着需要为相同数量的总数据发送更多数据包。</li>
<li>Pod IP地址无法在集群外部路由。</li>
</ul>
<h4 id="跨子网Overlay网络"><a href="#跨子网Overlay网络" class="headerlink" title="跨子网Overlay网络"></a>跨子网Overlay网络</h4><p>除了标准的VXLAN或IP-in-IP overlay外，Calico还支持VXLAN和IP-in-IP的“cross-subnet”模式。在这种模式下，在每个子网中，基础网络充当L2网络。在单个子网内发送的数据包不进行封装，因此可以获得非overlay网络的性能。跨子网发送的数据包像普通的overlay网络一样被封装，从而减少了对基础网络的依赖（无需与基础网络集成或对其进行任何更改）。</p>
<p>就像使用标准overlay网络一样，基础网络也不知道Pod IP地址，并且Pod IP地址无法在集群外部路由。</p>
<h4 id="Pod-IP路由到集群外部的能力"><a href="#Pod-IP路由到集群外部的能力" class="headerlink" title="Pod IP路由到集群外部的能力"></a>Pod IP路由到集群外部的能力</h4><p>不同的Kubernetes网络实现的一个重要区别特征是Pod IP地址是否可在整个较宽网络的集群外部路由。</p>
<p><strong>不可路由</strong>	</p>
<p>如果Pod IP地址无法在集群外部路由，则当Pod尝试建立与集群外部IP地址的网络连接时，Kubernetes将使用一种称为SNAT（源网络地址转换）的技术来更改源IP从Pod的IP地址到托管Pod的节点的IP地址。连接上的所有返回数据包都会自动映射回Pod IP地址。因此，Pod不知道发生了SNAT，连接的目的地将节点视为连接的源，而底层的更广泛的网络不会看到Pod IP地址。</p>
<p>对于相反方向的连接，其中集群外部的某些设备需要连接到Pod，这只能通过Kubernetes service或Kubernetes ingress来完成。集群之外的任何人都无法直接连接到Pod IP地址，因为更广泛的网络不知道如何将数据包路由到Pod IP地址。</p>
<p><strong>可路由</strong></p>
<p>如果Pod IP地址可以在集群外部路由，则Pod可以不使用SNAT即可连接到外部世界，并且集群外部可以直接连接到Pod，而无需通过Kubernetes service或Kubernetes ingress。</p>
<p>Pod IP可路由到集群外部的优点是：</p>
<ul>
<li>避免将SNAT用于出站连接对于与现有更广泛的安全要求进行集成可能至关重要。它还可以简化操作日志的调试和易懂性。</li>
<li>如果有专门的工作负载，这意味着某些Pod需要直接访问而不需要通过Kubernetes service或Kubernetes ingress，那么可路由的Pod IP在操作上可能更简单。</li>
</ul>
<p>Pod IP地址可路由到集群外的主要缺点是，Pod IP在整个网络中必须是唯一的。因此，例如，如果运行多个群集，则需要为每个群集中的Pod使用不同的IP地址范围（CIDR）。当大规模运行时，或者如果现有其他企业对IP地址空间有大量重要需求，这又可能导致IP地址范围耗尽的挑战。</p>
<p><strong>决定可路由性的因素是什么？</strong></p>
<p>如果集群使用overlay网络，则Pod IP通常无法路由到集群外。</p>
<p>如果集群不使用overlay网络，那么Pod IP是否路由到集群外取决于所用的CNI插件，云提供商集成或与物理网络（对于本地）BGP对等连接。</p>
<h4 id="BGP"><a href="#BGP" class="headerlink" title="BGP"></a>BGP</h4><p>BGP（边界网关协议）是用于跨网络共享路由的基于标准的网络协议。它是互联网的基本组成部分之一，具有出色的扩展特性。</p>
<p>Calico内置了对BGP的支持。在本地部署中，这使Calico可以与物理网络（通常连接到Top或Rack路由器）建立对等关系以交换路由，从而形成一个none-overlay网络，其中Pod IP地址可以在更广泛的网络中路由，就像附加的任何其他工作负载一样到网络。</p>
<h3 id="关于Calico网络"><a href="#关于Calico网络" class="headerlink" title="关于Calico网络"></a>关于Calico网络</h3><p>Calico网络灵活的模块化架构包括以下内容。</p>
<p><strong>Calico CNI网络插件</strong></p>
<p>Calico CNI网络插件使用一对虚拟以太网设备（一对）将Pod连接到主机网络名称空间的L3路由。这种L3架构避免了许多其他Kubernetes网络解决方案中附加的L2桥不必要的复杂性和性能开销。</p>
<p><strong>Calico CNI IPAM插件</strong></p>
<p>Calico CNI IPAM插件为一个或多个可配置IP地址范围之外的Pod分配IP地址，并根据需要为每个节点动态分配IP块。与许多其他CNI IPAM插件（包括在许多网络解决方案中使用的主机本地IPAM插件）相比，具有更有效的IP地址空间使用。</p>
<p><strong>Overlay网络模式</strong></p>
<p>Calico可以提供VXLAN或IP-in-IP网络，包括cross-subnet模式。</p>
<p><strong>Non-overlay网络模式</strong></p>
<p>Calico可以提供在任何基础L2网络之上运行的non-overlay网络，或者是具有适当的云提供商集成的公共云网络或支持BGP的L3网络（通常是具有标准Top-of-Rack路由器）。</p>
<p><strong>网络策略</strong></p>
<p>Calico的网络策略执行引擎实现了Kubernetes网络策略的全部功能，以及Calico Network Policy的扩展功能。这可以与Calico的内置网络模式或任何其他Calico兼容的网络插件和云提供商集成结合使用。</p>
<h3 id="与Calico兼容的CNI插件和云提供商集成"><a href="#与Calico兼容的CNI插件和云提供商集成" class="headerlink" title="与Calico兼容的CNI插件和云提供商集成"></a>与Calico兼容的CNI插件和云提供商集成</h3><p>除Calico CNI插件和内置网络模式外，Calico还与许多第三方CNI插件和云提供商集成兼容。</p>
<p><strong>Amazon VPC CNI</strong></p>
<p>Amazon VPC CNI插件从基础AWS VPC分配Pod IP，并使用AWS弹性网络接口提供VPC本机Pod网络（可在集群外部路由的Pod IP）。它是Amazon EKS中使用的默认网络，并与Calico一起用于网络策略实施。</p>
<p><strong>Azure CNI</strong></p>
<p>Azure CNI插件从基础Azure VNET分配Pod IP，将Azure虚拟网络配置为提供VNET本机Pod网络（可在群集外部路由的Pod IP）。它是Microsoft AKS中使用的默认网络，可与Calico一起执行网络策略。</p>
<p><strong>Azure cloud provider</strong></p>
<p>Azure云提供商集成可以用作Azure CNI插件的替代方法。它使用host-local IPAM插件分配Pod IP，并使用相应的路由对基础Azure VNET子网进行编程。Pod IP仅可在VNET子网内路由（这通常意味着它们无法路由到群集外部）。</p>
<p><strong>Google cloud provider</strong></p>
<p>Google云提供商集成使用host-local IPAM插件分配Pod IP，并对Google Cloud网络Alias IP范围进行编程，以在Google Cloud上提供VPC本机Pod网络（可在集群外部路由的Pod IP）。它是Google Kubernetes Engine（GKE）的默认设置，并带有Calico来执行网络策略。</p>
<p><strong>Host local IPAM</strong></p>
<p>host-local IPAM插件是常用的IP地址管理CNI插件，它为每个节点分配固定大小的IP地址范围（CIDR），然后从该范围内分配Pod IP地址。默认地址范围大小是256个IP地址（a&#x2F;24），其中两个IP地址是为特殊目的保留的，未分配给Pod。host-local IPAM插件的简单性使其易于理解，但与Calico CNI IPAM插件相比，其IP地址空间使用效率较低。</p>
<p><strong>Flannel</strong></p>
<p>Flannel使用从host-local IPAM插件获得的静态CIDR路由pod间的通信。Flannel提供了许多网络后端，但主要与VXLAN后端一起使用。Calico CNI和Calico网络策略可以与flannel和host-local IPAM插件结合使用，以提供具有策略实施功能的VXLAN网络。这种组合有时称为“Canal”。</p>
<blockquote>
<p>注意：Calico现在内置了对VXLAN的支持，为了简化起见，我们通常建议优先使用Calico + Flannel组合。</p>
</blockquote>
<h3 id="网络选择"><a href="#网络选择" class="headerlink" title="网络选择"></a>网络选择</h3><h4 id="本地"><a href="#本地" class="headerlink" title="本地"></a><strong>本地</strong></h4><p>Calico本地部署最常见的网络设置是non-overlay模式，该模式使用BGP与物理网络（通常是机架路由器的顶部）对等，以使Pod IP可在集群外部路由。（当然，可以根据需要配置其余的本地部署网络，以限制群集外的Pod IP路由的范围。）此设置提供了丰富的Calico高级功能，包括公告Kubernetes serviceIP的能力（cluster IPs or external IPs），以及在Pod，名称空间或节点级别控制IP地址管理的能力，以支持与现有企业网络和安全要求集成的各种可能性。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>No</td>
<td>BGP</td>
</tr>
</tbody></table>
<p>如果不能将BGP对等连接到物理网络，并且群集在单个L2网络中，则还可以运行non-overlay模式，而Calico只能在群集中的节点之间对等BGP。即使这不是严格的overlay网络，也无法在集群外部路由Pod IP，因为基础网络没有Pod IP的路由。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>No</td>
<td>BGP</td>
</tr>
</tbody></table>
<p>或者，可以在VXLAN或IP-in-IP模式下运行Calico，并使用cross-subnet模式来优化每个L2子网内的性能。</p>
<p>推荐方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>替代方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>IPIP</td>
<td>BGP</td>
</tr>
</tbody></table>
<h4 id="AWS"><a href="#AWS" class="headerlink" title="AWS"></a>AWS</h4><p>如果希望在集群外部可路由Pod IP地址，则必须使用Amazon VPC CNI插件。这是EKS的默认网络模式，并使用Calico的网络策略。Pod IP地址是从基础VPC分配的，每个节点的Pod的最大数量取决于实例类型。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>AWS</td>
<td>AWS</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果希望避免依赖特定的云提供商，或者由于IP地址范围耗尽的挑战，或者如果Amazon VPC CNI插件每个节点支持的最大Pod数量不足以从基础VPC分配Pod IP，则存在问题。根据需求，我们建议使用Calico的overlay + cross-subnet模式。Pod IP将无法在集群外部路由，但是可以在不依赖基础云网络的情况下将集群扩展到Kubernetes的极限。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>在这个简短的视频中，可以了解有关AWS上的Kubernetes Networking的更多信息，包括上述每个选项的工作原理。<a target="_blank" rel="noopener" href="https://www.projectcalico.org/everything-you-need-to-know-about-kubernetes-pod-networking-on-aws/">Everything you need to know about Kubernetes networking on AWS</a>。</p>
<h4 id="Azure"><a href="#Azure" class="headerlink" title="Azure"></a>Azure</h4><p>如果希望在群集外部可以路由Pod IP地址，则必须使用Azure CNI插件。这由AKS和Calico进行网络策略支持。Pod IP地址是从基础VNET分配的。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Azure</td>
<td>Azure</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果要使用AKS，但由于IP地址范围耗尽的问题而无法从基础VNET分配Pod IP，则可以将Calico与Azure云提供商集成一起使用。它使用host-local IPAM为每个节点分配&#x2F;24地址段，并为这些&#x2F;24地址段在群集的基础VNET子网中编程路由。在群集&#x2F;VNET子网外部无法路由Pod IP，因此如果需要，可以在多个群集中使用相同的Pod IP地址范围（CIDR）。</p>
<blockquote>
<p>注意：在某些AKS文档中将其称为kubenet + Calico，但实际上是带有Azure云提供程序的Calico CNI，并且不使用kubenet插件。</p>
</blockquote>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Host Local</td>
<td>Calico</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果不使用AKS，而是希望避免依赖于特定的云提供商，或者由于IP地址范围耗尽的问题而无法从基础VNET分配Pod IP，那么我们建议使用Calico的overlay + cross-subnet模式。Pod IP将无法在集群外部路由，但是可以在不依赖基础云网络的情况下将集群扩展到Kubernetes的极限。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>可以在此短视频中了解有关Azure上Kubernetes Networking的更多信息，包括上述每个选项的工作原理：<a target="_blank" rel="noopener" href="https://www.projectcalico.org/everything-you-need-to-know-about-kubernetes-pod-networking-on-azure/">Everything you need to know about Kubernetes networking on Azure</a></p>
<h4 id="Google-Cloud"><a href="#Google-Cloud" class="headerlink" title="Google Cloud"></a>Google Cloud</h4><p>如果想在集群外部路由Pod IP地址，则必须将Google云提供商集成与host-local IPAM CNI插件结合使用。GKE和Calico都为网络策略提供了支持。从基础VPC分配Pod IP地址，并自动将相应的Alias IP地址分配给节点。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Host Local</td>
<td>Calico</td>
<td>No</td>
<td>VPC&#x2F;Native</td>
</tr>
</tbody></table>
<p>如果希望避免依赖特定的云提供商，或者由于IP地址范围耗尽的挑战而无法从基础VPC分配Pod IP，那么我们建议使用Calico的overlay模式。由于Google云网络是纯L3网络，因此不支持cross-subnet模式。Pod IP将无法在集群外部路由，但是可以在不依赖基础云网络的情况下将集群扩展到Kubernetes的极限。</p>
<p>推荐方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>
<p>替代方案：</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>IPIP</td>
<td>BGP</td>
</tr>
</tbody></table>
<p>可以在此短片中了解有关Google云上的Kubernetes Networking的更多信息，包括上述每个选项的工作原理：<a target="_blank" rel="noopener" href="https://www.projectcalico.org/everything-you-need-to-know-about-kubernetes-pod-networking-on-google-cloud/">Everything you need to know about Kubernetes networking on Google cloud</a></p>
<h4 id="IBM-Cloud"><a href="#IBM-Cloud" class="headerlink" title="IBM Cloud"></a>IBM Cloud</h4><p>如果使用的是IBM Cloud，则建议使用IKS，该产品具有内置Calico的功能，可提供cross-subnet +IPIP模式的网络模式。除了为Pod提供网络策略外，IKS还使用Calico网络策略来保护群集中的主机节点。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>IPIP</td>
<td>BGP</td>
</tr>
</tbody></table>
<h4 id="Anywhere"><a href="#Anywhere" class="headerlink" title="Anywhere"></a>Anywhere</h4><p>上面的环境列表显然并不详尽。理解本指南中的概念和解释有助于确定适合的环境。如果仍然不确定，则可以通过Calico用户的Slack或Discourse论坛寻求建议。记住，如果要使用，而不想担心各种选项，则可以在几乎任何环境中以VXLAN + overlay模式运行Calico。</p>
<table>
<thead>
<tr>
<th>Policy</th>
<th>IPAM</th>
<th>CNI</th>
<th>Overlay</th>
<th>Routing</th>
</tr>
</thead>
<tbody><tr>
<td>Calico</td>
<td>Calico</td>
<td>Calico</td>
<td>VXLAN</td>
<td>Calico</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/30/linux/Intro-to-BGP-with-BIRD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/30/linux/Intro-to-BGP-with-BIRD/" class="post-title-link" itemprop="url">BGP路由Bird介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-30 22:58:22" itemprop="dateCreated datePublished" datetime="2020-06-30T22:58:22+00:00">2020-06-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>边界网关协议（BGP）是互联网涉及的核心技术之一，它使网络能够相互通信。了解如何使用此工具来定义网络拓扑，不仅可以让我们更好地了解互联网络，还可以将这种鲁棒性应用到自己的网络。</p>
<p>在本教程结束时，我们将熟悉BGP的核心概念，并能够把相关的术语传达给其他人。此外，我们还将学会使用BIRD的用户界面建立对等会话并开始发布路由。</p>
<p>本文使用docker容器实现这一目标。为了完成本教程，需要确保已安装<code>docker</code>和<code>docker-compose</code>。</p>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>首先，需要克隆bird_examples_docker项目。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/ncatelli/bird_examples_docker.git</span></span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash"><span class="built_in">cd</span> bird_examples_docker</span></span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose up -d</span>	</span><br></pre></td></tr></table></figure>

<p>上述命令将创建三个容器（<code>peer1</code>，<code>peer2</code>和<code>peer3</code>），所有这些容器均已安装BIRD并已建立对等会话。如果还不知道这意味着什么，请不要担心，我们将在设置好BGP并准备就绪后对其进行介绍。</p>
<p>首先连接到peer1并检查所有设置是否正确。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose <span class="built_in">exec</span> peer1 bash</span></span><br><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:03    </span><br><span class="line">device1  Device   master   up     02:36:03    </span><br><span class="line">direct1  Direct   master   up     02:36:03    </span><br><span class="line">peer2    BGP      master   up     02:36:08    Established   </span><br><span class="line">peer3    BGP      master   up     02:36:07    Established    	</span><br></pre></td></tr></table></figure>

<p>如果发现<code>peer2</code>和<code>peer3</code>已经显示<code>Established</code>，则说明一切正常，我们已准备就绪。在开始使用之前，将简要介绍BGP的工作原理。</p>
<h2 id="原理概述"><a href="#原理概述" class="headerlink" title="原理概述"></a>原理概述</h2><p>边界网关协议（BGP）是一种外部网关协议，用于在自治系统之间交换路由信息。自治系统（AS）是路由前缀和策略的组织单位。这些AS由唯一的16位（后来扩展到32位）自治系统编号（ASN）标识。例如，Facebook的ASN为32934或通常显示为AS32934。BGP的强大之处在于其在成千上万个分散式AS之间传递路由协议和策略的能力。</p>
<p>互联网以及许多其他网络由相互之间进行通信的许多自治系统组成。对等会话促进了这种通信，该会话允许两个AS交换策略，路由和链接状态。所有这些信息都在两个BGP守护程序之间交换，这两个守护程序在TCP的179端口上进行侦听。</p>
<p>虽然BGP被认为是用于在Internet上的大型组织之间进行路由的外部网关协议，但它也可以在AS中使用，以使网络工程师能够控制其内部网络的拓扑。这是eBGP和iBGP术语的来源。iBGP将是本教程其余部分的重点。现在，我们将开始使用BIRD及其交互式命令行工具<code>birdc</code>尝试这些对等会话。</p>
<h3 id="BIRD简介"><a href="#BIRD简介" class="headerlink" title="BIRD简介"></a>BIRD简介</h3><p>BIRD是功能齐全的路由守护程序，它支持许多不同的路由协议，包括BGP。BIRD提供了一种简单的配置格式和命令行，用于与会话进行交互。BIRD还内置了对IPv4和IPv6的支持，以及与这两种协议一起使用的相应工具。</p>
<h3 id="检查BGP会话"><a href="#检查BGP会话" class="headerlink" title="检查BGP会话"></a><strong>检查BGP会话</strong></h3><p>与我们验证是否正确配置了docker环境的方式类似，我们可以通过运行以下命令查看正在运行的会话：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:02    </span><br><span class="line">device1  Device   master   up     02:36:02    </span><br><span class="line">direct1  Direct   master   up     02:36:02    </span><br><span class="line">peer2    BGP      master   up     02:36:07    Established   </span><br><span class="line">peer3    BGP      master   up     02:36:06    Established         	</span><br></pre></td></tr></table></figure>

<p>这给了我们很多信息。但是，让我们关注最后两个条目，<code>peer2</code>和<code>peer3</code>。我们可以看到它们都是BGP协议，并且info字段显示已经<code>Established</code>。这些条目中的每一个都对应于<code>peer1</code>与<code>peer2</code>和<code>peer3</code>打开的BGP会话。为了演示这些值与正在运行的会话之间的关系，让我们在peer2上停止Bird服务。在新的终端窗口中，运行以下命令来停止<code>peer2</code>，模拟网络故障。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose stop peer2</span></span><br><span class="line">Stopping bird_examples_peer2_1 ... done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:02    </span><br><span class="line">device1  Device   master   up     02:36:02    </span><br><span class="line">direct1  Direct   master   up     02:36:02    </span><br><span class="line">peer2    BGP      master   start  02:43:38    Connect       Socket: Connection closed</span><br><span class="line">peer3    BGP      master   up     02:36:06    Established  </span><br></pre></td></tr></table></figure>

<p>通过重新启动<code>peer2</code>，BIRD应该重新启动，并且随后应重新建立对等会话。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose start peer2</span></span><br><span class="line">Starting peer2 ... done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show protocols</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">name     proto    table    state  since       info</span><br><span class="line">kernel1  Kernel   master   up     02:36:02    </span><br><span class="line">device1  Device   master   up     02:36:02    </span><br><span class="line">direct1  Direct   master   up     02:36:02    </span><br><span class="line">peer2    BGP      master   up     02:46:29    Established   </span><br><span class="line">peer3    BGP      master   up     02:36:06    Established    </span><br></pre></td></tr></table></figure>

<p>通过停止<code>peer2</code>上的<code>bird</code>守护程序，我们使端口179上的TCP连接在<code>peer1</code>和<code>peer2</code>之间关闭。这样做会将我们的对等会话从<code>Established</code>更改为<code>Connect</code>。这两个状态对应于许多BGP状态中的两个，但是出于本教程的考虑，我们将仅关注<code>Established</code>，并将所有其他值视为未建立。对于那些更好奇的人，可以在Wikipedia上有关<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol#Finite-state_machines">BGP</a>的文章中找到有关会话状态的更多信息。</p>
<h3 id="配置BGP会话"><a href="#配置BGP会话" class="headerlink" title="配置BGP会话"></a><strong>配置BGP会话</strong></h3><p>尽管现在知道了如何检查会话是否已经建立，但了解这些会话的配置也很重要。为此，我们需要深入研究bird配置文件。让我们看一下<code>peer1</code>上的&#x2F;etc&#x2F;bird下的配置文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:~# cat /etc/bird/bird.conf</span><br><span class="line">router id 10.0.0.10;</span><br><span class="line"></span><br><span class="line">protocol kernel &#123;</span><br><span class="line">  metric 0;</span><br><span class="line">  import none;</span><br><span class="line">  learn;</span><br><span class="line">  export all;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol device &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol direct &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol bgp peer2 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.0.11 as 64513;</span><br><span class="line">  import all;</span><br><span class="line">  export all;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protocol bgp peer3 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.100.11 as 64514;</span><br><span class="line">  import all;</span><br><span class="line">  export all;</span><br></pre></td></tr></table></figure>

<p>我们可以看到建立这些初始会话所需的配置非常少。为了更深入地了解这项工作的真正作用，我们将专注于一个特定块：<code>bgp peer2</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">protocol bgp peer2 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.0.11 as 64513;</span><br><span class="line">  import all;</span><br><span class="line">  export none;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在本教程的前面，我们讨论了eBGP和iBGP之间的区别以及大型AS如何使用唯一的ASN标识自己。但是，一小部分可用的ASN已保留给专用iBGP使用。这个范围是<code>64512-65534</code>。知道了这一点，我们可以看到我们已经将私有范围中的ASN分配给了<code>peer2</code>，<code>peer1</code>被分配了ASN 64512。</p>
<p>查看下一条语句，我们可以看到具有IP和附加AS的邻居语句。该IP对应于我们尝试与之建立会话的主机或BGP术语中的邻居，而64513对应于我们分配给<code>peer2</code>主机的AS。可以通过查看<code>peer2</code>上的配置文件来确认这一点。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# grep -A4 peer1 /etc/bird/bird.conf</span><br><span class="line">protocol bgp peer1 &#123;</span><br><span class="line">  local as 64513;</span><br><span class="line">  neighbor 10.0.0.10 as 64512;</span><br><span class="line">  export none;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>协议BGP块中的这两个指令处理会话的初始建立。</p>
<p>虽然建立和维护会话对于BGP的运行至关重要，但仅建立会话无法路由任何流量。在下一节中，我们将探讨配置文件中的其他一些元素，以及如何使用它们来发现和宣布节点之间的路由。在继续进行此操作之前，先回顾一下我们当前的拓扑。</p>
<p>当前，我们的网络中有三个节点，<code>peer1</code>（AS64512），<code>peer2</code>（AS64513）和<code>peer3</code>（AS64514）。这些配置在同一广播域中，但是对等的结构类似于<code>peer3</code> &lt;-&gt; <code>peer1</code> &lt;-&gt; <code>peer2</code>。这种结构允许通过我们的路由服务器<code>peer1</code>从<code>peer2</code>或<code>peer3</code>进行路由通信。在继续进行本教程的下一步，即发布路由时，请牢记此拓扑。</p>
<table>
<thead>
<tr>
<th align="left">IP地址</th>
<th>节点名</th>
<th>AS号</th>
</tr>
</thead>
<tbody><tr>
<td align="left">10.0.0.10</td>
<td>peer1</td>
<td>64512</td>
</tr>
<tr>
<td align="left">10.0.0.11</td>
<td>peer2</td>
<td>64513</td>
</tr>
<tr>
<td align="left">10.0.100.11</td>
<td>peer3</td>
<td>64514</td>
</tr>
</tbody></table>
<h3 id="BGP发布路由"><a href="#BGP发布路由" class="headerlink" title="BGP发布路由"></a><strong>BGP发布路由</strong></h3><p><strong>内核协议</strong></p>
<p>在开始发布Bird守护程序之间的路由之前，我们应该首先了解BIRD如何在Linux内核和BIRD守护程序之间传递路由。这就是我们前面看到的内核协议块起作用的地方。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">protocol kernel &#123;</span><br><span class="line">  metric 0;</span><br><span class="line">  learn;</span><br><span class="line">  import none;</span><br><span class="line">  export all; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>kernel块中可以指定许多选项，并且可以在<a target="_blank" rel="noopener" href="http://bird.network.cz/?get_doc&f=bird-6.html#ss6.6">此处</a>找到关于这些选项的更多信息，但是我们要执行的大部分操作由导入&#x2F;导出定义。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import none;</span><br></pre></td></tr></table></figure>

<p>告诉BIRD不要将路由从内核路由表中读取到BIRD中。我们将通过直接协议（即配置）获取路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export all;</span><br></pre></td></tr></table></figure>

<p>告诉BIRD将其他公告了解的所有路由导出到内核的路由表中。这使我们可以实际利用此主机上的任何已获取的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">metric 0;</span><br></pre></td></tr></table></figure>

<p>度量标准值由内核用来确定路由的优先级，并选择优先级最低的路由。在这种情况下，我们将其设置为0或未定义，以便我们首选本地路由。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn;</span><br></pre></td></tr></table></figure>

<p>最后，我们将设置学习指令，该指令将允许其他守护程序从内核路由表中学习路由。</p>
<p><strong>发现直接路由</strong></p>
<p>现在，我们已经配置了BIRD守护程序以将路由直接推送到内核路由表，我们将需要配置对等端以发现本地直接路由。由于我们会将这些路由直接添加到我们的环回接口，因此在选择的编辑器中，将直接协议配置为仅使用<code>lo</code>接口。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">grep -A2 direct conf/peer2/etc/bird/bird.conf</span></span><br><span class="line">protocol direct &#123;</span><br><span class="line">  interface &quot;lo&quot;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose restart peer2</span></span><br><span class="line">Restarting bird_examples_peer2_1 ... done</span><br></pre></td></tr></table></figure>

<p>由于我们的网络上也有<code>peer3</code>，因此在此主机上进行相同操作，以防止宣布其他任何路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">grep -A2 direct conf/peer3/etc/bird/bird.conf</span></span><br><span class="line">protocol direct &#123;</span><br><span class="line">  interface &quot;lo&quot;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose restart peer3</span></span><br><span class="line">Restarting bird_examples_peer3_1 ... done</span><br></pre></td></tr></table></figure>

<p>此时，除了默认的10.0.0.0子网（可以使用<code>birdc</code>进行验证）以外，我们将没有其他路由学习和发布。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# birdc show route all</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">10.0.0.0/24        via 10.0.0.10 on eth0 [peer1 03:05:02] ! (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.0.10</span><br><span class="line">        BGP.local_pref: 100</span><br><span class="line">10.0.100.0/24      via 10.0.0.10 on eth0 [peer1 03:05:02] * (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.0.10</span><br><span class="line">        BGP.local_pref: 100</span><br></pre></td></tr></table></figure>

<p><strong>过滤引用和导出</strong></p>
<p>与内核模块类似，导出和导入可用于控制BGP对等方导入和导出的内容。首先，我们探讨过滤的概念以及如何将其用于控制将宣布或导出哪些路由。</p>
<p>BIRD中的过滤器基本上是在路由上执行的函数，返回接受或拒绝。这使我们能够应用一种简单的编程语言来为我们的路由策略添加逻辑。过滤器可以包含任何内容，从单个语句到非常复杂的逻辑。首先，让我们将none和all指令重新实现为过滤器，然后将它们添加到include指令上方的bird.conf文件中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filter accept_all &#123;</span><br><span class="line">  accept;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filter reject_all &#123;</span><br><span class="line">  reject;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>现在我们已经有了过滤器，让我们在我们的协议块之一的导入&#x2F;导出指令中实现它们。在主机<code>peer1</code>上，让我们看一下<code>peer2</code>块。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">protocol bgp peer2 &#123;</span><br><span class="line">  local as 64512;</span><br><span class="line">  neighbor 10.0.0.11 as 64513;</span><br><span class="line">  import filter accept_all;</span><br><span class="line">  export filter accept_all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从功能上讲，这与我们的原始配置相同，但是现在我们可以使用进一步的逻辑扩展这些设置。通过进一步研究过滤器脚本语言，可以了解这些过滤器的功能。为了扩展我们所学的知识，让我们在<code>peer2</code>上的bird.conf中创建一个过滤器，以控制要向<code>peer1</code>发布的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter export_subnets &#123;</span><br><span class="line">  if net ~ [ 192.168.5.5/32 ] then &#123;</span><br><span class="line">    accept;</span><br><span class="line">  &#125;</span><br><span class="line">  reject;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后，我们需要在<code>peer2</code>上更新<code>peer1</code>以使用此导出过滤器。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# grep -A4 peer1 /etc/bird/bird.conf</span><br><span class="line">protocol bgp peer1 &#123;</span><br><span class="line">  local as 64513;</span><br><span class="line">  neighbor 10.0.0.10 as 64512;</span><br><span class="line">  export filter export_subnets; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">ncatelli@ofet&gt; </span><span class="language-bash">docker-compose restart peer1 peer2</span></span><br><span class="line">Restarting bird_examples_peer2_1 ... done</span><br><span class="line">Restarting bird_examples_peer1_1 ... done</span><br></pre></td></tr></table></figure>

<p><strong>发布路由</strong></p>
<p>现在，我们有了开始发布<code>peer1</code>和<code>peer2</code>之间的路由所需的所有构造块。在此之前，让我们回顾一下我们所做的事情。首先，我们已将BIRD守护程序配置为使用我们的内核协议在其内部路由表和内核路由表之间进行通信。我们已将BIRD守护程序配置为从具有直接协议的环回接口中学习路由。我们还配置了<code>peer1</code>从其他对等节点导入路由并导出这些路由。最终，我们将<code>peer2</code>配置为仅使用export_subnets过滤器将192.168.5.5&#x2F;32导出到<code>peer1</code>。但是，目前我们还没有从<code>peer2</code>通告到<code>peer1</code>的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# ip route  </span><br><span class="line">default via 10.0.0.1 dev eth0 </span><br><span class="line">10.0.0.0/24 dev eth0 proto kernel scope link src 10.0.0.10 </span><br><span class="line">10.0.100.0/24 dev eth1 proto kernel scope link src 10.0.100.10</span><br></pre></td></tr></table></figure>

<p>此时，所有设置已经完成，因此可以从环回接口中学习路由。通过将IP添加到<code>peer2</code>的环回接口上，我们应该能够看到路由的发布。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@peer2:/# ip a add 192.168.5.5/32 dev lo</span><br></pre></td></tr></table></figure>

<p>现在，如果我们同时查看<code>peer1</code>上的birdc和内核路由表，我们应该可以看到<code>peer1</code>上新IP的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:~# ip route</span><br><span class="line">default viia 10.0.2.2 dev eth0</span><br><span class="line">10.0.0.0/24 dev eth1 proto kernel scope link src 10.0.0.10</span><br><span class="line">10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15</span><br><span class="line">10.0.100.0/24 dev eth2 proto kernel scope link src 10.0.100.10</span><br><span class="line">192.168.5.5 via 10.0.0.11 dev eth1 proto bird</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# birdc show route all</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">10.0.0.0/24        dev eth0 [direct1 03:10:33] * (240)</span><br><span class="line">        Type: device unicast univ</span><br><span class="line">10.0.100.0/24      dev eth1 [direct1 03:10:33] * (240)</span><br><span class="line">        Type: device unicast univ</span><br><span class="line">192.168.5.5/32     via 10.0.0.11 on eth0 [peer2 03:12:39] * (100) [AS64513i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64513</span><br><span class="line">        BGP.next_hop: 10.0.0.11</span><br><span class="line">        BGP.local_pref: 100</span><br></pre></td></tr></table></figure>

<p>ping将显示我们现在可以从<code>peer1</code>向该主机发送流量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@peer1:/# ping -c 1 192.168.5.5</span><br><span class="line">PING 192.168.5.5 (192.168.5.5) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.5.5: icmp_seq=1 ttl=64 time=0.135 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.5.5 ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.135/0.135/0.135/0.000 ms</span><br></pre></td></tr></table></figure>

<p>现在可以看到这些路由已通过<code>peer1</code>通告到<code>peer3</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@peer3:/# birdc show route all</span><br><span class="line">BIRD 1.6.6 ready.</span><br><span class="line">10.0.0.0/24        via 10.0.100.10 on eth0 [peer3 03:10:37] * (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.100.10</span><br><span class="line">        BGP.local_pref: 100</span><br><span class="line">10.0.100.0/24      via 10.0.100.10 on eth0 [peer3 03:10:37] ! (100) [AS64512i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512</span><br><span class="line">        BGP.next_hop: 10.0.100.10</span><br><span class="line">        BGP.local_pref: 100</span><br><span class="line">192.168.5.5/32     via 10.0.100.10 on eth0 [peer3 03:12:38] * (100) [AS64513i]</span><br><span class="line">        Type: BGP unicast univ</span><br><span class="line">        BGP.origin: IGP</span><br><span class="line">        BGP.as_path: 64512 64513</span><br><span class="line">        BGP.next_hop: 10.0.100.10</span><br><span class="line">        BGP.local_pref: 100</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@peer3:/# ping -c 1 192.168.5.5</span><br><span class="line">PING 192.168.5.5 (192.168.5.5) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.5.5: icmp_seq=1 ttl=63 time=0.082 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.5.5 ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.082/0.082/0.082/0.000 ms</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@peer3:/# traceroute 192.168.5.5</span><br><span class="line">traceroute to 192.168.5.5 (192.168.5.5), 64 hops max</span><br><span class="line">  1   10.0.100.10  0.005ms  0.003ms  0.003ms </span><br><span class="line">  2   192.168.5.5  0.003ms  0.003ms  0.003ms</span><br></pre></td></tr></table></figure>

<p>我们也可以通过查看AS PATH来了解情况。通过查看与birdc中的路由关联的AS PATH，可以看到从64513到64512的路由在到达<code>peer3</code>之前发布。</p>
<p>因为将<code>peer1</code>配置为将路由导出到<code>peer3</code>，并且由于<code>peer3</code>配置为从<code>peer1</code>导入路由，所以我们能够将此路由获取到<code>peer3</code>的BIRD路由表中。然后，由于我们已将内核协议配置为在BIRD中导出路由，因此这些路由会将其放入<code>peer3</code>的内核路由表中。</p>
<h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>在这个简单的教程中，我们探讨了许多概念，但是，我们几乎没有涉及bird的概念。随时使用此示例，以发布和过滤路由的方式进一步探索。在以后的教程中，我们将更深入地探讨BGP的工作方式以及用于确定路由的过程，包括如何通信和本地优先级以及BGP守护程序如何使用它们来选择通往服务器的最佳路径。我们还将探讨什么是任播IP，以及如何使用BGP配置高可用性，以及如何使用过滤策略代替直接接口策略来控制向每个节点声明哪些前缀。BGP可以为我们提供对网络拓扑的大量控制，并且了解如何使用BGP可以更好地调整网络以适应自己的需求。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/30/k8s/Kubernetes-External-IP-service-type/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/30/k8s/Kubernetes-External-IP-service-type/" class="post-title-link" itemprop="url">Kubernetes External IP服务类型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-30 22:50:22" itemprop="dateCreated datePublished" datetime="2020-06-30T22:50:22+00:00">2020-06-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在构建裸机Kubernetes集群时，您可能会遇到一个常见问题，就像我在做的那样，除了使用NodePort之外，您真的不知道如何向Internet公开Kubernetes服务。如果使用的是NodePort服务类型，它将分配一个要打开的较大端口号，并且您必须允许防火墙规则连接到这些端口。这对您的基础架构不利，尤其是在将服务器暴露于外部Internet时。好吧，还有另一种简洁的方法可以将您的Kubernetes服务公开出去，并且使用服务的原始端口号。例如，您可以将Kubernetes群集中部署的MySQL服务通过3306而不是32767端口暴露给外界。<strong>答案是使用Kubernetes External IP服务类型</strong>。</p>
<p>就个人而言，我发现在Kubernetes社区中并未广泛讨论此主题，这可能是因为许多人正在使用云提供商的负载均衡器或将Metal LB用于本地部署。</p>
<h2 id="什么是External-IP服务"><a href="#什么是External-IP服务" class="headerlink" title="什么是External IP服务"></a>什么是External IP服务</h2><p>从<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types">Kubernetes官方文档</a>中可以看到External IP的描述：</p>
<blockquote>
<p><em>如果存在路由到一个或多个集群节点的外部IP，则Kubernetes Services可以在这些<strong>External IP</strong>上公开。在服务端口上使用外部IP（作为目标IP）进入群集的流量将被路由到服务端点之一。<strong>External IP</strong>不受Kubernetes的管理，由集群管理员负责。</em></p>
</blockquote>
<p>对于大多数人来说，这种解释是可以理解的。这里最重要的是确保使用哪个IP来访问Kubernetes集群。使用External IP服务类型，我们可以将服务绑定到用于连接集群的IP。</p>
<p>如果您了解Kubernetes网络的工作方式，那将是很好的。如果您不熟悉它，请查看Mark Betz撰写的<a target="_blank" rel="noopener" href="https://medium.com/google-cloud/understanding-kubernetes-networking-pods-7117dd28727">博客文章</a>，以详细了解它们。这里最重要的是要知道Kubernetes网络与Overlay网络一起工作。这意味着一旦您到达群集中的任何节点（主节点或工作节点），您就可以虚拟访问群集中的所有节点。</p>
<p>下图就是他们的组网图：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/kubernetes-external-ip.png" alt="kubernetes-external-ip"></p>
<p>在上图中，节点1和节点2都有1个IP地址。节点1上的IP地址1.2.3.4绑定到实际Pod驻留在节点2中的httpd服务，而IP地址1.2.3.5绑定到实际Pod驻留在节点1中的nginx服务。底层的overlay网络使这成为可能。当我们curl 1.2.3.4时，应该看到来自httpd服务的响应，而curl 1.2.3.5时，则应该看到来自nginx服务的响应。</p>
<h2 id="为什么不使用Ingress"><a href="#为什么不使用Ingress" class="headerlink" title="为什么不使用Ingress"></a>为什么不使用Ingress</h2><p>即使Ingress也用于将服务公开给外部，但Ingress是为L7路由构建的。这意味着它构建为支持HTTP（端口80）和&#x2F;或HTTPS（端口443）流量，而不支持其他端口。Ingress充当基于主机的路由，或类似于Web Server中的虚拟主机。一些能够为其他端口提供服务的ingress controllers，或者可能为L4路由提供了解决方法，但我从未真正尝试使用它们。</p>
<h2 id="External-IP的优缺点"><a href="#External-IP的优缺点" class="headerlink" title="External IP的优缺点"></a>External IP的优缺点</h2><p>使用External IP的优点是：</p>
<ul>
<li>您可以完全控制所使用的IP。您可以使用属于您的ASN的IP，而不要使用云提供商的ASN。</li>
</ul>
<p>外部IP的缺点是：</p>
<ul>
<li>我们现在将要进行的简单设置并<strong>不是高可用的</strong>。这意味着，如果节点异常，则该服务将不再可用，您将需要手动修复该问题。</li>
<li>管理IP需要做一些手工工作。IP不是为您动态配置的，因此需要人工干预。</li>
</ul>
<h2 id="如何使用External-IP服务"><a href="#如何使用External-IP服务" class="headerlink" title="如何使用External IP服务"></a>如何使用External IP服务</h2><p>同样，我们将使用与我们的群集设置相同的组网图，不同的是IP地址和主机名不同。这不是一个好例子，但是当我们验证设置时，很容易区分是哪个。在实际示例中，您可能希望在一个外部IP上公开MySQL DB，在另一个外部IP上公开Kafka群集。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/kubernetes-external-ip-demo.png" alt="kubernetes-external-ip-demo"></p>
<p>我已为本教程配置了2个VM。k3s-external-ip-master将是我们的Kubernetes master节点，其IP为1.2.4.120。k3s-external-ip-worker将是Kubernetes worker节点，其IP为1.2.4.114。</p>
<p><strong>步骤1：部署Kubernetes集群</strong></p>
<p>让我们在主节点上安装k3s，然后让另一个节点加入集群。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k3sup install --ip &lt;master node ip&gt; --user &lt;username&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k3sup <span class="built_in">join</span> --server-ip &lt;master node ip&gt; --ip &lt;worker node ip&gt; --user &lt;username&gt;</span></span><br></pre></td></tr></table></figure>

<p>您现在应该会看到类似的内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get nodes</span></span><br><span class="line">NAME                                  STATUS   ROLES    AGE     VERSION</span><br><span class="line">k3s-external-ip-master               Ready    master   7m24s   v1.16.3-k3s.2</span><br><span class="line">k3s-external-ip-worker               Ready    &lt;none&gt;   2m21s   v1.16.3-k3s.2</span><br></pre></td></tr></table></figure>

<p><strong>步骤2：创建Kubernetes Deployment资源</strong></p>
<p>我们将创建nginx和httpd资源。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment nginx --image=nginx</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment httpd --image=httpd</span></span><br></pre></td></tr></table></figure>

<p>你现在应该看到这个:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-86c57db685-fzxn5   1/1     Running   0          22s</span><br><span class="line">httpd-7bddd4bd85-zk8ks   1/1     Running   0          16s</span><br></pre></td></tr></table></figure>

<p><strong>步骤3：将Deployment公开为External IP类型</strong></p>
<p>让我们创建Nginx服务的yaml：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">nginx-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">externalIPs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">1.2</span><span class="number">.4</span><span class="number">.114</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>创建httpd服务的yaml：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt; httpd-service.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: httpd-service</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: httpd</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      targetPort: 80</span><br><span class="line">  externalIPs:</span><br><span class="line">    - 1.2.4.120</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>使用kubectl命令创建2个服务的yaml：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f nginx-service.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f httpd-service.yaml</span></span><br></pre></td></tr></table></figure>

<p>现在您的Kubernetes服务应该如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes      ClusterIP   10.43.0.1       &lt;none&gt;        443/TCP   18m</span><br><span class="line">httpd-service   ClusterIP   10.43.240.149   1.2.4.120     80/TCP    32s</span><br><span class="line">nginx-service   ClusterIP   10.43.13.149    1.2.4.114     80/TCP    26s</span><br></pre></td></tr></table></figure>

<p>您可能会在此处看到服务类型为ClusterIP。我不确定为什么它不显示“外部IP”。</p>
<blockquote>
<p>k8s官网有说明，External IP与type无关</p>
</blockquote>
<p><strong>步骤4：瞧！</strong></p>
<p>让我们curl httpd服务，您应该看到Apache默认页面。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -i 1.2.4.120</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Date: Fri, 20 Dec 2019 03:36:23 GMT</span><br><span class="line">Server: Apache/2.4.41 (Unix) &lt;------</span><br><span class="line">Last-Modified: Mon, 11 Jun 2007 18:53:14 GMT</span><br><span class="line">ETag: &quot;2d-432a5e4a73a80&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 45</span><br><span class="line">Content-Type: text/html</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p>接下来，curl nginx服务，您应该看到nginx默认页面。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -i 1.2.4.114</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.17.6 &lt;------</span><br><span class="line">Date: Fri, 20 Dec 2019 03:36:01 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 612</span><br><span class="line">Last-Modified: Tue, 19 Nov 2019 12:50:08 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;5dd3e500-264&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">....</span><br></pre></td></tr></table></figure>

<h2 id="下一步是什么"><a href="#下一步是什么" class="headerlink" title="下一步是什么"></a>下一步是什么</h2><h3 id="浮动IP"><a href="#浮动IP" class="headerlink" title="浮动IP"></a>浮动IP</h3><p>如今，大多数云提供商都提供浮动IP服务。浮动IP允许您拥有1个IP，并将该IP动态分配给所需的任何IP。在这种情况下，可以将IP分配给Kubernetes集群中的任何工作节点。</p>
<p>在DigitalOcean（我相信其他提供商也允许这样做）中，您可以使用API调用将IP重新分配给其他VM。这意味着您可以在其他VM发生故障时迅速将其主动重新分配给其他VM，或者可以定期轮换IP。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/kubernetes-floating-ip.png" alt="kubernetes-floating-ip"></p>
<p>从图中可以看到，我们有1个浮动IP 1.2.3.6，该IP首先分配给节点1，当节点1不可用时将切换到节点2。IP 1.2.3.6适用于我们的MySQL服务，并将放入我们的应用程序配置中。</p>
<p>我尚未尝试此设置，因此无法确认它是否有效。我将在以后的博客文章中更新结果。</p>
<h3 id="任播IP"><a href="#任播IP" class="headerlink" title="任播IP"></a>任播IP</h3><p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Kubernetes-External-IP-service-type/anycast.png" alt="anycast"></p>
<p>您可以将Anycast IP用作外部IP，以便它们具有高可用性。对于不熟悉Anycast IP的用户，这意味着1个IP可能会路由到2个或更多服务器。你可以在<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Anycast">这里</a>阅读更多。就个人而言，我不确定如何设置此设置。但是，我认为这在技术上是可行的。我认为这是运行外部IP服务的最佳方法。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>您可以通过很多选项为裸机Kubernetes集群获取IP。例如，您可以为此使用Inlets和MetalLB。此设置可能不是您的组织需要的最合适的设置。但是，很高兴知道如何使用此方法。</p>
<blockquote>
<p>免责声明：我仅将其用于实验和测试，而本文不适用于生产。如果您打算在生产中使用它，请咨询您的解决方案架构师或CTO。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/22/k8s/Advertising-Kubernetes-Service-IPs-with-Calico-and-BGP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/22/k8s/Advertising-Kubernetes-Service-IPs-with-Calico-and-BGP/" class="post-title-link" itemprop="url">使用Calico的BGP发布Kubernetes Service IP路由</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-22 21:58:22" itemprop="dateCreated datePublished" datetime="2020-06-22T21:58:22+00:00">2020-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>访问Kubernetes集群中托管的服务的两种最常见方法是通过<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a>或<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer">Load Balancer</a>。对于公有云用户来说，这些是访问服务的简单有效方法。云托管的控制器可以完成分配公共IP，设置负载平衡和管理SSL的繁重工作。</p>
<p>在本地运行私有托管的Kubernetes集群的运营商将很快意识到，将服务公开提供比在公有云上更为复杂。服务将在公共互联网上还是仅对本地用户公开？应该如何设置Ingress，负载平衡，IP分配和SSL管理？在维护安全性的同时将服务公开发布的最有效方法是什么？</p>
<p>Calico项目通过其服务IP发布功能为某些问题提供了答案，该功能与现有的机架（ToR）基础架构集成在一起，可以提供Kubernetes服务IP或Kubernetes外部服务IP的路由。在以下情况下，服务IP发布是一个很好的解决方案：</p>
<ul>
<li>您的ToR解决方案能够运行边界网关协议（BGP）</li>
<li>您希望将服务从群集共享到网络基础结构的其余部分</li>
<li>您想利用网络负载均衡</li>
</ul>
<p>为了启用服务IP发布功能，Calico需要与BGP路由器建立对等关系，该路由器在Calico的内部路由器之外，但在网络本地。BGP是网络中使用的最基本的路由协议之一。在较高级别，BGP通过在信任对等方之间共享路由来工作。与ToR对等时，Calico共享Kubernetes服务的路由，这使它们可用于整个网络。</p>
<p>为了帮助讨论此功能，假定我们安装以下方式配置了网络和群集：</p>
<ul>
<li>托管Kubernetes节点的服务器机架通过顶部机架式路由器连接到物理网络</li>
<li>Calico作为CNI和网络策略插件运行</li>
<li>Calico和Rack顶部路由器配置为使用BGP对等</li>
</ul>
<p>在此设置中，我们具有以下网络配置：</p>
<ul>
<li>机架顶部路由器的IP地址是192.168.1.1，服务器的IP地址是从192.168.1.0&#x2F;24分配的</li>
<li>Kubernetes Pod网络配置了CIDR 10.48.0.0&#x2F;16</li>
<li>Kubernetes服务集群IP范围配置为10.49.0.0&#x2F;16</li>
<li>外部服务IP范围配置为192.168.3.0&#x2F;24</li>
</ul>
<p>您的ToR BGP路由器的确切配置超出了本文的范围，并且会因您使用的供应商或软件包而异。如果您没有可用的服务器机架，但仍然想尝试该功能，那么在单独的服务器上运行的<a target="_blank" rel="noopener" href="https://bird.network.cz/">Bird Internet Routing Daemon（BIRD）</a>是尝试进行操作的不错选择。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/k8s/Advertising-Kubernetes-Service-IPs-with-Calico-and-BGP/Screen-Shot-2020-04-01-at-12.01.48-PM-1024x794.png"></p>
<p>第一步是启用ToR和Calico网络之间的对等连接。其工作方式将根据您的ToR实现而有所不同，但是要牢记一些关键事项：</p>
<ul>
<li>必须将ToR路由器配置为与在每个节点上运行的Calico对等</li>
<li>ToR需要接受来自外部网络，外部服务网络和Pod服务网络的路由和流量</li>
<li>如果可以选择，ToR应该启用正常重启，以防止网络服务中断</li>
</ul>
<p>将ToR配置为接受路由后，下一步是在Calico端启用对等。首先通过以下清单告诉Calico有关外部BGP路由器的信息：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">calicoctl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="bullet">-</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">projectcalico.org/v3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BGPPeer</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bgppeer-global-64512</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">peerIP:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line">  <span class="attr">asNumber:</span> <span class="number">64512</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>启用对等功能后，Calico可以使Pod成为网络中的头等公民，而无需覆盖网络，并使他们可以直接在群集外部访问。</p>
<p>尽管启用了对等连接，但是Calico仍需要进一步配置以公开Kubernetes服务IP范围。这可以通过创建新的Calico BGPConfiguration资源来完成：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">calicoctl</span> <span class="string">create</span> <span class="string">-f</span> <span class="bullet">-</span> <span class="string">&lt;&lt;EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">projectcalico.org/v3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BGPConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceClusterIPs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">cidr:</span> <span class="number">10.49</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>启用服务群集IP范围的发布后，ToR上的路由表将如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip r</span></span><br><span class="line">...</span><br><span class="line">10.49.0.0/16</span><br><span class="line">nexthop via 192.168.1.10 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.1.11 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.1.12 dev eth2 weight 1 </span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>注意到10.49.0.0&#x2F;16网络的路由如何在节点之间实现ECMP负载平衡。您公开的所有服务将由ToR在所有节点上进行负载平衡。为了说明这一点，我们可以创建一个基本的Nginx服务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">control:~$ kubectl apply -f - &lt;&lt;EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">EOF</span><br><span class="line">control:~$ kubectl expose nginx</span><br><span class="line">control:~$ kubectl get services</span><br><span class="line">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.49.0.1      &lt;none&gt;        443/TCP   19m</span><br><span class="line">nginx        ClusterIP   10.49.62.131   &lt;none&gt;        80/TCP    4m43s</span><br></pre></td></tr></table></figure>

<p>现在，您可以从外部网络通过其内部群集IP地址访问Kubernetes托管服务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">external:~$ curl 10.49.62.131</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这里有两个阶段的负载平衡。首先，ToR通过将其路由到节点来对与群集IP的连接进行负载平衡。然后，使用NAT（网络地址转换）在该节点上运行的kube-proxy负载均衡到特定的Pod，以将目标IP从群集IP更改为后备Pod之一的IP地址。后备Pod可能在本地节点上，也可能在其他节点之一上，从而导致了另一个网络跃点。</p>
<p>如果我们想避免额外的潜在网络跳数，可以通过将服务上的外部流量策略设置为本地来实现。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">control:~$ kubectl patch service nginx \</span><br><span class="line">  -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;type&quot;: &quot;NodePort&quot;, &quot;externalTrafficPolicy&quot;:&quot;Local&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p>现在，在ToR上，您将看到路由表的新增内容，包括Nginx服务到正在运行Nginx的特定节点的ECMP负载平衡：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip r</span></span><br><span class="line">...</span><br><span class="line">10.49.0.0/16 </span><br><span class="line">nexthop via 192.168.2.10 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.2.11 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.2.12 dev eth2 weight 1 </span><br><span class="line">...</span><br><span class="line">10.49.62.131</span><br><span class="line">nexthop via 192.168.2.11 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.2.12 dev eth2 weight 1 </span><br></pre></td></tr></table></figure>

<p>这是公开Kubernetes网络服务的简便方法，但是在操作上，它具有将Kubernetes群集中该IP范围内的每个服务都暴露给网络其余部分的缺点。如果您想更精细地控制提供哪些服务，或者想要分配真正面向公众的IP地址，Calico可以通过发布外部服务IP来解决这个问题。该方法类似，主要区别在于外部IP不由Kubernetes集群管理，必须手动分配给服务。</p>
<p>下一个示例将说明这一点。首先重新配置BGPConfiguration，以发布外部IP而不是内部IP（值得注意的是，您可以一次公开这两个集合，但是在此示例中，我们要关闭对内部网络的公共访问，同时仍提供对应用程序的访问）。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">control</span> <span class="string">:~$calicoctl</span> <span class="string">create</span> <span class="string">-f</span> <span class="bullet">-</span> <span class="string">&lt;&lt;EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">projectcalico.org/v3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BGPConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceClusterIPs:</span></span><br><span class="line">  <span class="attr">serviceExternalIPs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">cidr:</span> <span class="number">192.168</span><span class="number">.3</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>检查路由时，请注意已删除到群集IP范围的路由，并已添加到外部服务网络的路由。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip r</span></span><br><span class="line">...</span><br><span class="line">192.168.3.0/24</span><br><span class="line">nexthop via 192.168.1.10 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.1.11 dev eth2 weight 1 </span><br><span class="line">nexthop via 192.168.1.12 dev eth2 weight 1 </span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>该服务的群集IP不再公开可见。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">external :~$ curl -m 10 10.49.62.131</span><br><span class="line">curl: (28) Connection timed out after 10001 milliseconds</span><br></pre></td></tr></table></figure>

<p>我们现在在发布外部IP范围，但我们还需要为服务分配一个外部IP：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">control:~$ kubectl patch svc nginx \</span><br><span class="line">-p  &#x27;&#123;&quot;spec&quot;: &#123;&quot;externalIPs&quot;: [&quot;192.168.3.180&quot;]&#125;&#125;&#x27;</span><br><span class="line">control:~$ kubectl get services</span><br><span class="line">NAME       TYPE       CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE</span><br><span class="line">kubernetes ClusterIP  10.49.0.1      &lt;none&gt;          443/TCP        152m</span><br><span class="line">nginx      NodePort   10.49.62.131   192.168.3.180   80:31890/TCP   109m</span><br></pre></td></tr></table></figure>

<p>检查连接性：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">external:~$ curl 192.168.3.180</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>到此为止，我们快速完成了Calico如何在Kuberentes群集之外发布服务和外部服务IP的快速浏览。对于具有启用BGP路由的本地云，这是一种简单的解决方案，无需提供安装和维护自定义Kubernetes负载均衡器或Ingress控制器的额外工作即可访问Kubernetes服务。如果您想了解更多有关此功能的信息，请查阅官方的Calico项目”<a target="_blank" rel="noopener" href="https://docs.projectcalico.org/networking/advertise-service-ips">Advertise Kubernetes Service IPs</a>“。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/13/linux/An-introduction-to-linux-interfaces-for-virtual-networking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/13/linux/An-introduction-to-linux-interfaces-for-virtual-networking/" class="post-title-link" itemprop="url">Linux接口之虚拟网络接口介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-13 20:01:15" itemprop="dateCreated datePublished" datetime="2020-06-13T20:01:15+00:00">2020-06-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://developers.redhat.com/topics/linux/">Linux</a>具有丰富的虚拟网络功能，可用作托管VM和<a target="_blank" rel="noopener" href="https://developers.redhat.com/blog/category/containers/">容器</a>以及云环境的基础。本文将简要介绍所有常用的虚拟网络接口类型。内容没有代码分析，仅简要介绍了接口及其在Linux上的用法。可以使用<code>ip link help</code>命令获取接口列表的帮助。</p>
<p>内容涵盖了以下常用的接口以及一些易于相互混淆的接口：</p>
<ul>
<li>Bridge</li>
<li>Bonded interface</li>
<li>Team device</li>
<li>VLAN (Virtual LAN) </li>
<li>VXLAN (Virtual eXtensible Local Area Network)</li>
<li>MACVLAN</li>
<li>IPVLAN</li>
<li>MACVTAP&#x2F;IPVTAP</li>
<li>MACsec (Media Access Control Security)</li>
<li>VETH (Virtual Ethernet)</li>
<li>VCAN (Virtual CAN)</li>
<li>VXCAN (Virtual CAN tunnel)</li>
<li>IPOIB (IP-over-InfiniBand)</li>
<li>NLMON (NetLink MONitor)</li>
<li>Dummy interface</li>
<li>IFB (Intermediate Functional Block)</li>
<li>netdevsim</li>
</ul>
<p>阅读本文之后，我们将了解这些接口是什么，它们之间的区别，何时使用它们以及如何创建它们。</p>
<h2 id="Bridge"><a href="#Bridge" class="headerlink" title="Bridge"></a>Bridge</h2><p>Linux网桥的行为类似于网络交换机。它在与其连接的接口之间转发数据包。它通常用于在路由器，网关或虚拟机与主机上的网络命名空间之间转发数据包。它还支持STP，VLAN过滤和多播侦听。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/bridge.png" alt="bridge"></p>
<p>如果想要在VM，容器和主机之间建立通信通道，请使用网桥。</p>
<p>以下是创建网桥的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add br0 <span class="built_in">type</span> bridge</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 master br0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> tap1 master br0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> tap2 master br0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> veth1 master br0</span></span><br></pre></td></tr></table></figure>

<p>上述命令创建了一个名为<code>br0</code>网桥，并且设置了两个TAP设备（<code>tap1</code>，<code>tap2</code>），一个VETH设备（<code>veth1</code>），和物理设备（<code>eth0</code>）作为它的从设备，如上图所示。</p>
<h2 id="Bond"><a href="#Bond" class="headerlink" title="Bond"></a>Bond</h2><p>Linux bond驱动提供了一种用于将多个网络接口聚合为单个逻辑“绑定”接口的方法。绑定接口的行为取决于模式。一般来说，提供热备用或负载平衡两种模式。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/net_failover.png" alt="bond"></p>
<p>如果想提高链接速度或在服务器上进行故障转移时，请使用bond接口。</p>
<p>以下是创建bond接口的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ip link add bond1 type bond miimon 100 mode active-backup</span><br><span class="line">ip link set eth0 master bond1</span><br><span class="line">ip link set eth1 master bond1</span><br></pre></td></tr></table></figure>

<p>上述命令创建了一个名称为<code>bond1</code>的<code>active-backup</code>模式的bond接口。对于其他模式，请参阅 <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/bonding.txt">内核文档</a>。</p>
<h2 id="Team-device"><a href="#Team-device" class="headerlink" title="Team device"></a>Team device</h2><p>与bond接口类似，team device的目的是提供一种在L2层将多个NIC（端口）分组为一个逻辑端口（teamdev）的机制。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/bond.png" alt="team"></p>
<p>需要注意的是，team device不会尝试复制或模仿bond接口。它的作用是使用不同的方法来解决相同的问题。</p>
<p>但是bond和team device之间也存在一些功能差异。例如，team device支持LACP负载平衡，NS&#x2F;NA（IPV6）链接监视，D-Bus接口等，而这些功能在bond中是不存在的。有关bond和team device之间差异的更多详细信息，请参见 <a target="_blank" rel="noopener" href="https://github.com/jpirko/libteam/wiki/Bonding-vs.-Team-features">bond vs team device</a>。</p>
<p>综上，如果想使用bond无法提供的某些功能，请使用team device。</p>
<p>创建team device的方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">teamd -o -n -U -d -t team0 -c <span class="string">&#x27;&#123;&quot;runner&quot;: &#123;&quot;name&quot;: &quot;activebackup&quot;&#125;,&quot;link_watch&quot;: &#123;&quot;name&quot;: &quot;ethtool&quot;&#125;&#125;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 down</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> eth1 down</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">teamdctl team0 port add eth0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">teamdctl team0 port add eth1</span></span><br></pre></td></tr></table></figure>

<p>上述命令将创建一个<code>team0</code>的team device，且模式为<code>active-backup</code>，并添加<code>eth0</code> 和 <code>eth1</code>作为<code>team0</code>的子接口。</p>
<p>最近，一个名为<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/networking/net_failover.html">net_failover</a>的新驱动已添加到Linux内核。它是用于虚拟化的另一种故障转移网络设备，并管理主（[passthru&#x2F;VF<a target="_blank" rel="noopener" href="https://wiki.libvirt.org/page/Networking#PCI_Passthrough_of_host_network_devices">虚拟功能]</a> 设备）从网络设备和备用（原始超虚拟接口）从网络设备。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/vlan_01.png" alt="net_failover"></p>
<h2 id="VLAN"><a href="#VLAN" class="headerlink" title="VLAN"></a>VLAN</h2><p>VLAN（也称为虚拟LAN）通过向网络数据包添加标签来分隔广播域。VLAN使网络管理员可以将同一台交换机下或不同交换机之间的主机分组。</p>
<p>VLAN标头如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/vlan.png" alt="vlan_01"></p>
<p>如果想在VM，命名空间或主机中分隔子网，请使用VLAN。</p>
<p>以下是创建VLAN的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add <span class="built_in">link</span> eth0 name eth0.2 <span class="built_in">type</span> vlan <span class="built_in">id</span> 2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add <span class="built_in">link</span> eth0 name eth0.3 <span class="built_in">type</span> vlan <span class="built_in">id</span> 3</span></span><br></pre></td></tr></table></figure>

<p>上述命令将添加名为<code>eth0.2</code>的<code>VLAN2</code>和名为<code>eth0.3</code>的<code>VLAN 3</code> 。拓扑如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/team.png" alt="vlan"></p>
<p><strong>注意</strong>：在配置VLAN时，需要确保连接到主机的交换机能够处理VLAN标签，例如，通过将交换机端口设置为中继模式。</p>
<h2 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h2><p>VXLAN（虚拟可扩展局域网）是一种隧道协议，旨在解决IEEE 802.1q中有限的VLAN ID（4,096）的问题。由<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7348">IETF RFC 7348</a>描述。</p>
<p>通过24位网段ID（又称为VXLAN网络标识符（VNI）），VXLAN最多允许2 ^ 24（16,777,216）个虚拟LAN，这是VLAN容量的4,096倍。</p>
<p>VXLAN将带有VXLAN标头的第2层帧封装到UDP-IP数据包中，如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/vxlan_01.png" alt="vxlan_01"></p>
<p>VXLAN通常部署在虚拟主机上的数据中心中，该主机可以分布在多个机架上。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/vxlan.png" alt="vxlan"></p>
<p>下面是使用VXLAN的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add vx0 <span class="built_in">type</span> vxlan <span class="built_in">id</span> 100 <span class="built_in">local</span> 1.1.1.1 remote 2.2.2.2 dev eth0 dstport 4789</span></span><br></pre></td></tr></table></figure>

<p>作为参考，可以阅读<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/vxlan.txt">VXLAN内核文档</a>或<a target="_blank" rel="noopener" href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux">VXLAN简介</a>。</p>
<h2 id="MACVLAN"><a href="#MACVLAN" class="headerlink" title="MACVLAN"></a>MACVLAN</h2><p>使用VLAN，我们可以在一个接口上创建多个接口，并根据VLAN标记过滤数据包。使用MACVLAN，我们可以在一个接口上创建具有不同第2层（即以太网MAC）地址的多个接口。</p>
<p>在使用MACVLAN之前，如果要从VM或命名空间连接到物理网络，则需要创建TAP&#x2F;VETH设备，并将一侧连接到网桥，并同时将物理接口连接到主机上的网桥，如下所示。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macvlan_01.png" alt="br_ns"></p>
<p>现在，借助MACVLAN，我们可以将与MACVLAN关联的物理接口直接绑定到命名空间，而无需桥接。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/br_ns.png" alt="macvlan"></p>
<p>MACVLAN有五种类型：</p>
<p>1.Private：即使外部交换机支持hairpin模式，也不允许同一物理接口上的MACVLAN实例之间进行通信。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macvlan_02.png" alt="macvlan_01"></p>
<ol start="2">
<li>VEPA：同一物理接口上从一个MACVLAN实例到另一个MACVLAN实例的数据通过该物理接口传输。连接的交换机需要支持hairpin模式，或者必须有TCP&#x2F;IP路由器转发数据包才能进行通信。</li>
</ol>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macvlan.png" alt="macvlan_02"></p>
<ol start="3">
<li>Bridge：所有端点都通过物理接口通过简单的桥接器直接相互连接。</li>
</ol>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macvlan_04.png" alt="macvlan_03"></p>
<ol start="4">
<li>Passthru：允许将单个VM直接连接到物理接口。</li>
</ol>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/ipvlan.png" alt="macvlan_04"></p>
<ol start="5">
<li>Source：该模式用于基于允许的源MAC地址列表过滤流量，以创建基于MAC的VLAN关联。请参阅<a target="_blank" rel="noopener" href="https://git.kernel.org/pub/scm/linux/kernel/git/davem/net.git/commit/?id=79cf79abce71">提交消息</a>。</li>
</ol>
<p>模式是根据不同的需求选择的。桥接模式是最常用的。如果要从容器直接连接到物理网络时，请使用MACVLAN。</p>
<p>设置MACVLAN的方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add macvlan1 <span class="built_in">link</span> eth0 <span class="built_in">type</span> macvlan mode bridge</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add macvlan2 <span class="built_in">link</span> eth0 <span class="built_in">type</span> macvlan mode bridge</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add net1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add net2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> macvlan1 netns net1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> macvlan2 netns net2</span></span><br></pre></td></tr></table></figure>

<p>上述命令将以桥接模式创建两个新的MACVLAN设备，并将这两个设备分配给两个不同的命名空间。</p>
<h2 id="IPVLAN"><a href="#IPVLAN" class="headerlink" title="IPVLAN"></a>IPVLAN</h2><p>IPVLAN与MACVLAN相似，区别在于端点具有相同的MAC地址。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macvlan_03.png" alt="ipvlan"></p>
<p>IPVLAN支持L2和L3模式。IPVLAN L2模式在桥接模式下的行为类似于MACVLAN。父接口看起来像一个网桥或交换机。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/ipvlan_02.png" alt="ipvlan_01"></p>
<p>在IPVLAN L3模式下，父接口的行为就像路由器，并且数据包在端点之间路由，从而提供了更好的可伸缩性。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/ipvlan_01.png" alt="ipvlan_02"></p>
<p>关于何时使用IPVLAN，  <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/ipvlan.txt">IPVLAN内核文档</a> 说MACVLAN和IPVLAN在许多方面都非常相似，并且可以依据特定的场景很好地定义选择哪个。如果以下情况之一定义我们需要的场景，则可以选择使用ipvlan：<br>（a）连接到外部交换机&#x2F;路由器的Linux主机已配置了策略，每个端口仅允许一个mac。<br>（b）在主服务器上创建的虚拟设备均未超过mac容量，并且无法将NIC置于混杂模式，因此性能下降是一个问题。<br>（c）如果要将从设备放入敌对&#x2F;不受信任的网络命名空间中，则从设备上的L2可能会被更改&#x2F;滥用。</p>
<p>设置IPVLAN实例的方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add ns0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name ipvl0 <span class="built_in">link</span> eth0 <span class="built_in">type</span> ipvlan mode l2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> dev ipvl0 netns ns0</span></span><br></pre></td></tr></table></figure>

<p>上述命令将创建一个名为<code>ipvl0</code>L2的IPVLAN设备，并分配给<code>ns0</code>命名空间。</p>
<h2 id="MACVTAP-IPVTAP"><a href="#MACVTAP-IPVTAP" class="headerlink" title="MACVTAP&#x2F;IPVTAP"></a>MACVTAP&#x2F;IPVTAP</h2><p>MACVTAP&#x2F;IPVTAP是一种新的设备驱动，旨在简化虚拟化桥接网络。当在物理接口顶部创建MACVTAP&#x2F;IPVTAP实例时，内核还将创建一个字符设备&#x2F;dev&#x2F;tapX，以与<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/TUN/TAP">TUN&#x2F;TAP</a>设备一样使用，并可以由KVM &#x2F; QEMU直接使用。</p>
<p>使用MACVTAP&#x2F;IPVTAP，我们可以用单个模块替换TUN&#x2F;TAP和网桥驱动的组合：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macvtap.png" alt="macvtap"></p>
<p>通常，MACVLAN&#x2F;IPVLAN用于使访客和主机都直接显示在主机所连接的交换机上。MACVTAP和IPVTAP之间的差异与MACVLAN&#x2F;IPVLAN相同。</p>
<p>以下是创建MACVTAP实例的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add <span class="built_in">link</span> eth0 name macvtap0 <span class="built_in">type</span> macvtap</span></span><br></pre></td></tr></table></figure>

<h2 id="MACsec"><a href="#MACsec" class="headerlink" title="MACsec"></a>MACsec</h2><p>MACsec（媒体访问控制安全）是用于有线以太网LAN中安全性的IEEE标准。与IPsec相似，作为第2层规范，MACsec不仅可以保护IP流量，还可以保护ARP，NS（邻居发现）和DHCP。MACsec标头如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macsec_01.png" alt="macsec_01"></p>
<p>MACsec的主要用例是保护标准LAN上的所有消息（包括ARP，NS和DHCP消息）的安全。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/veth.png" alt="macsec"></p>
<p>MACsec配置的方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add macsec0 <span class="built_in">link</span> eth1 <span class="built_in">type</span> macsec</span></span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：上述命令仅在e<code>th1</code>设备上添加了名为<code>macsec0</code>的MACsec。有关更详细的配置，请参阅<a target="_blank" rel="noopener" href="https://developers.redhat.com/blog/2016/10/14/macsec-a-different-solution-to-encrypt-network-traffic/">Sabrina Dubroca</a><a target="_blank" rel="noopener" href="https://developers.redhat.com/blog/2016/10/14/macsec-a-different-solution-to-encrypt-network-traffic/">MACsec简介</a>“配置示例”部分 。</p>
<h2 id="VETH"><a href="#VETH" class="headerlink" title="VETH"></a>VETH</h2><p>VETH（虚拟以太网）设备是本地以太网隧道。设备是成对创建的，如下图所示。在VETH对中的一个设备上传输的数据包将立即在另一设备上接收。当任何一台设备关闭时，该VETH对的链接状态为关闭。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-linux-interfaces-for-virtual-networking/macsec.png" alt="veth"></p>
<p>当任意命名空间需要与主机命名空间或彼此之间进行通信时，请使用VETH配置。</p>
<p>以下是设置VETH配置的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add net1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add net2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add veth1 netns net1 <span class="built_in">type</span> veth peer name veth2 netns net2</span></span><br></pre></td></tr></table></figure>

<p>上述命令将创建两个名称空间<code>net1</code>和<code>net2</code>，以及一对VETH设备，并将<code>veth1</code>分配给<code>net1</code>，<code>veth2</code>分配给<code>net2</code>。这两个命名空间与此VETH对相连。分配一对IP地址，这样就可以在两个命名空间之间通信。</p>
<h2 id="VCAN"><a href="#VCAN" class="headerlink" title="VCAN"></a>VCAN</h2><p>与网络环回设备类似，VCAN（虚拟CAN）驱动提供了虚拟本地CAN（控制器局域网）接口，因此用户可以通过VCAN接口发送&#x2F;接收CAN消息。如今，CAN主要用于汽车领域。</p>
<p>有关更多CAN协议信息，请参考 <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/can.txt">内核CAN文档</a>。</p>
<p>如果需要在本地主机上测试CAN协议实现时，请使用VCAN。</p>
<p>创建VCAN的方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add dev vcan1 <span class="built_in">type</span> vcan</span></span><br></pre></td></tr></table></figure>

<h2 id="VXCAN"><a href="#VXCAN" class="headerlink" title="VXCAN"></a>VXCAN</h2><p>与VETH驱动类似，VXCAN（虚拟CAN隧道）在两个VCAN网络设备之间实现本地CAN流量隧道。创建VXCAN实例时，两个VXCAN设备将成对创建。当一端接收到数据包时，该数据包出现在设备对上，反之亦然。VXCAN可用于跨命名空间通信。</p>
<p>如果想跨命名空间发送CAN消息时，请使用VXCAN配置。</p>
<p>设置VXCAN实例的方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add net1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip netns add net2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add vxcan1 netns net1 <span class="built_in">type</span> vxcan peer name vxcan2 netns net2</span></span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：Red Hat Enterprise Linux尚不支持VXCAN。</p>
<h2 id="IPOIB"><a href="#IPOIB" class="headerlink" title="IPOIB"></a>IPOIB</h2><p>IPOIB设备支持IP-over-InfiniBand协议。这将通过InfiniBand（IB）传输IP数据包，因此我们可以将IB设备用作快速NIC。</p>
<p>IPoIB驱动支持两种操作模式：datagram和connected。在datagram模式下，使用IB UD（不可靠数据包）传输。在connected模式下，使用IB RC（可靠连接）传输。connected模式利用了IB传输的连接特性，并允许MTU最多达到64K的最大IP数据包大小。</p>
<p>有关更多详细信息，请参见 <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/infiniband/ipoib.txt">IPOIB内核文档</a>。</p>
<p>如果想拥有IB设备并想通过IP与远程主机通信时，请使用IPOIB设备。</p>
<p>以下是创建IPOIB设备的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add ib0 name ipoib0 <span class="built_in">type</span> ipoib pkey IB_PKEY mode connected</span></span><br></pre></td></tr></table></figure>

<h2 id="NLMON"><a href="#NLMON" class="headerlink" title="NLMON"></a>NLMON</h2><p>NLMON是Netlink监视设备。</p>
<p>如果想要监视系统Netlink消息时，请使用NLMON设备。</p>
<p>以下是创建NLMON设备的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add nlmon0 <span class="built_in">type</span> nlmon</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> nlmon0 up</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tcpdump -i nlmon0 -w nlmsg.pcap</span></span><br></pre></td></tr></table></figure>

<p>上述命令将创建一个名称为NLMON的<code>nlmon0</code>设备并进行设置。使用数据包嗅探器（例如，  <code>tcpdump</code>）捕获Netlink消息。Wireshark的最新版本具有对Netlink消息进行解码的功能。</p>
<h2 id="Dummy-interface"><a href="#Dummy-interface" class="headerlink" title="Dummy interface"></a>Dummy interface</h2><p>虚拟接口完全是虚拟的，例如loopback接口。虚拟接口的目的是提供一种设备，可以在不实际传输数据包的情况下路由数据包。</p>
<p>使用虚拟接口使无效的SLIP（串行Internet协议）地址看起来像本地程序的真实地址。如今，虚拟接口主要用于测试和调试。</p>
<p>以下是创建虚拟接口的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add dummy1 <span class="built_in">type</span> dummy</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip addr add 1.1.1.1/24 dev dummy1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> dummy1 up</span></span><br></pre></td></tr></table></figure>

<h2 id="IFB"><a href="#IFB" class="headerlink" title="IFB"></a>IFB</h2><p>IFB（中间功能块）驱动提供了一种设备，该设备允许集中来自多个源的流量并调整传入流量，而不是将其丢弃。</p>
<p>如果想要排队和调整传入流量时，请使用IFB接口。</p>
<p>以下是创建IFB接口的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add ifb0 <span class="built_in">type</span> ifb</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> ifb0 up</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tc qdisc add dev ifb0 root sfq</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tc qdisc add dev eth0 handle ffff: ingress</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tc filter add dev eth0 parent ffff: u32 match u32 0 0 action mirred egress redirect dev ifb0</span></span><br></pre></td></tr></table></figure>

<p>上述命令将创建一个名为<code>ifb0</code>的IFB设备，并将根据qdisc调度程序替换为SFQ（随机公平队列），SFQ是无类排队调度程序。然后，在<code>eth0</code>上添加一个qdisc调度程序，并将所有入口流量重定向到<code>ifb0</code>。</p>
<p>有关更多IFB qdisc用例，请参考 <a target="_blank" rel="noopener" href="https://wiki.linuxfoundation.org/networking/ifb">IFB上的Linux Foundation Wiki</a>。</p>
<h2 id="netdevsim接口"><a href="#netdevsim接口" class="headerlink" title="netdevsim接口"></a>netdevsim接口</h2><p>netdevsim是一种模拟的联网设备，用于测试各种联网API。目前，它特别专注于测试硬件卸载，tc&#x2F;XDP BPF和SR-IOV。</p>
<p>如下命令可以创建一个netdevsim设备</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add dev sim0 <span class="built_in">type</span> netdevsim</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> dev sim0 up</span></span><br></pre></td></tr></table></figure>

<p>要启用tc卸载：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ethtool -K sim0 hw-tc-offload on</span></span><br></pre></td></tr></table></figure>

<p>加载XDP BPF或tc BPF程序：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> dev sim0 xdpoffload obj prog.o</span></span><br></pre></td></tr></table></figure>

<p>要添加用于SR-IOV测试的VF，请执行以下操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> 3 &gt; /sys/class/net/sim0/device/sriov_numvfs</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> sim0 vf 0 mac</span> </span><br></pre></td></tr></table></figure>

<p>要更改vf编号，需要先完全禁用它们：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> 0 &gt; /sys/class/net/sim0/device/sriov_numvfs</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> 5 &gt; /sys/class/net/sim0/device/sriov_numvfs</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>默认情况下，RHEL中没有编译netdevsim。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lyyao09.github.io/2020/06/11/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LeaoYao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="云原生知识星球">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/11/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/" class="post-title-link" itemprop="url">Linux虚拟接口之隧道介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-11 22:08:12" itemprop="dateCreated datePublished" datetime="2020-06-11T22:08:12+00:00">2020-06-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-02 14:09:30" itemprop="dateModified" datetime="2024-11-02T14:09:30+00:00">2024-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Linux支持多种隧道，但是新用户可能会因为它们之间的差异而感到困惑，无法确定哪种隧道适合给定的场景。本文将简要介绍Linux内核中常用的隧道接口。内容没有代码分析，仅简要介绍了接口及其在Linux上的用法。感兴趣的话，可以通过iproute2的命令ip link help获得隧道接口列表以及特定隧道配置的帮助。</p>
<p>这篇文章介绍了以下常用接口：</p>
<ul>
<li>IPIP</li>
<li>SIT</li>
<li>ip6tnl</li>
<li>VTI和VTI6</li>
<li>GRE和GRETAP</li>
<li>IP6GRE和IP6GRETAP</li>
<li>FOU</li>
<li>GUE</li>
<li>GENEVE</li>
<li>ERSPAN和IP6ERSPAN</li>
</ul>
<p>阅读本文之后，我们将了解这些接口是什么，它们之间的区别，何时使用它们以及如何创建它们。</p>
<h2 id="IPIP"><a href="#IPIP" class="headerlink" title="IPIP"></a>IPIP</h2><p>顾名思义，IPIP隧道是RFC 2003中定义的IP over IP隧道。IPIP隧道标头如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/ipip.png" alt="ipip"></p>
<p>通常用于通过公共IPv4互联网连接两个内部IPv4子网。它具有最低的开销，但只能传输IPv4单播流量。这意味着您<strong>无法</strong>通过IPIP隧道发送多播。</p>
<p>IPIP隧道同时支持IP over IP和MPLS over IP。</p>
<p><strong>注意：</strong>加载ipip模块或首次创建IPIP设备时，Linux内核将在每个名称空间中创建tunl0默认设备，其属性为local &#x3D; any和remote &#x3D; any。接收IPIP协议数据包时，如果内核找不到其他本地&#x2F;远程属性与其来源或目标地址更匹配的设备，则内核会将其转发给tunl0作为备用设备。</p>
<p>如下是创建IPIP隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">On Server A:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name ipip0 <span class="built_in">type</span> ipip <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> ipip0 up</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip addr add INTERNAL_IPV4_ADDR/24 dev ipip0</span></span><br><span class="line">Add a remote internal subnet route if the endpoints don&#x27;t belong to the same subnet</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip route add REMOTE_INTERNAL_SUBNET/24 dev ipip0</span></span><br><span class="line"></span><br><span class="line">On Server B:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name ipip0 <span class="built_in">type</span> ipip <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> ipip0 up</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip addr add INTERNAL_IPV4_ADDR/24 dev ipip0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip route add REMOTE_INTERNAL_SUBNET/24 dev ipip0</span></span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：请根据测试环境将LOCAL_IPv4_ADDR，REMOTE_IPv4_ADDR，INTERNAL_IPV4_ADDR，REMOTE_INTERNAL_SUBNET替换为地址。</p>
<h2 id="SIT"><a href="#SIT" class="headerlink" title="SIT"></a>SIT</h2><p>SIT代表“简单Internet过渡”。主要目的是互连位于全球IPv4互联网中的隔离IPv6网络。</p>
<p>最初，它只有IPv6 over IPv4隧道模式。然而，经过多年的发展，它获得了对多种不同模式的支持，例如ipip（与IPIP隧道相同），ip6ip，mplsip等。模式any用于同时接受IP和IPv6流量，这在某些部署中可能很有用。 SIT隧道还支持ISATA，用法见<a target="_blank" rel="noopener" href="http://www.litech.org/isatap">示例</a>。</p>
<p>SIT隧道报文头看起来如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/sit.png" alt="sit.png"></p>
<p>加载sit模块后，Linux内核将创建一个默认设备，名为sit0。</p>
<p>如下是创建SIT隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">On Server A:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name sit1 <span class="built_in">type</span> sit <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR mode any</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> sit1 up</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip addr add INTERNAL_IPV4_ADDR/24 dev sit1</span></span><br></pre></td></tr></table></figure>

<p>然后，在远端执行相同的步骤。</p>
<h2 id="ip6tnl"><a href="#ip6tnl" class="headerlink" title="ip6tnl"></a>ip6tnl</h2><p>ip6tnl是基于IPv6的IPv4&#x2F;IPv6隧道接口，看起来像SIT隧道的IPv6版本。报文头看起来如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/ip6tnl.png" alt="ip6tnl.png"></p>
<p>ip6tnl支持ip6ip6，ipip6，和any模式。ipip6模式是IPv4 over IPv6，ip6ip6模式是IPv6 over IPv6，any模式支持IPv4&#x2F;IPv6 over Pv6。</p>
<p>加载ip6tnl模块后，Linux内核将创建一个名为ip6tnl0的默认设备。</p>
<p>如下是创建ip6tnl隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name ipip6 <span class="built_in">type</span> ip6tnl <span class="built_in">local</span> LOCAL_IPv6_ADDR remote REMOTE_IPv6_ADDR mode any</span></span><br></pre></td></tr></table></figure>

<h2 id="VTI和VTI6"><a href="#VTI和VTI6" class="headerlink" title="VTI和VTI6"></a>VTI和VTI6</h2><p>Linux上的虚拟隧道接口（VTI）与Cisco的VTI和Juniper的安全隧道（st.xx）类似。</p>
<p>这个特定的隧道驱动程序实现IP封装，可以与xfrm一起使用以提供安全隧道的概念，然后在其之上使用内核路由。</p>
<p>通常，VTI隧道的运行方式几乎与ipip或sit隧道相同，不同之处在于，它们添加了fwmark和IPsec封装&#x2F;解封装。</p>
<p>VTI6是VTI的IPv6实现。</p>
<p>如下是创建VTI隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name vti1 <span class="built_in">type</span> vti key VTI_KEY <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> <span class="built_in">set</span> vti1 up</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip addr add LOCAL_VIRTUAL_ADDR/24 dev vti1</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip xfrm state add src LOCAL_IPv4_ADDR dst REMOTE_IPv4_ADDR spi SPI PROTO ALGR mode tunnel</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip xfrm state add src REMOTE_IPv4_ADDR dst LOCAL_IPv4_ADDR spi SPI PROTO ALGR mode tunnel</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip xfrm policy add <span class="built_in">dir</span> <span class="keyword">in</span> tmpl src REMOTE_IPv4_ADDR dst LOCAL_IPv4_ADDR PROTO mode tunnel mark VTI_KEY</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip xfrm policy add <span class="built_in">dir</span> out tmpl src LOCAL_IPv4_ADDR dst REMOTE_IPv4_ADDR PROTO mode tunnel mark VTI_KEY</span></span><br></pre></td></tr></table></figure>

<p>也可以通过libreswan或strongSwan配置IPsec。</p>
<h2 id="GRE和GRETAP"><a href="#GRE和GRETAP" class="headerlink" title="GRE和GRETAP"></a>GRE和GRETAP</h2><p>通用路由封装，也称为GRE，在<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc2784">RFC 2784</a>中定义。</p>
<p>GRE隧道在内部和外部IP头之间添加了一个额外的GRE头。从理论上讲，GRE可以封装具有有效以太网类型的任何第3层协议，而IPIP只能封装IP。GRE报文头看起来如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/gre.png" alt="gre"></p>
<p>请注意，GRE隧道支持传输多播流量和IPv6报文。</p>
<p>当<code>gre</code>模块被加载，Linux内核将创建一个默认设备，命名<code>gre0</code>。</p>
<p>如下是创建GRE隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name gre1 <span class="built_in">type</span> gre <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR [<span class="built_in">seq</span>] key KEY</span></span><br></pre></td></tr></table></figure>

<p>GRE隧道在OSI第3层上运行，而GRETAP在OSI第2层上运行，这意味着内部头中有一个以太网头部。</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/gretap.png" alt="gretap"></p>
<p>如下是创建GRETAP隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name gretap1 <span class="built_in">type</span> gretap <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR</span></span><br></pre></td></tr></table></figure>

<h2 id="IP6GRE和IP6GRETAP"><a href="#IP6GRE和IP6GRETAP" class="headerlink" title="IP6GRE和IP6GRETAP"></a>IP6GRE和IP6GRETAP</h2><p>IP6GRE是GRE的IPv6实现，它使我们能够封装基于IPv6的任何第3层协议。隧道头看起来如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/gre6.png" alt="gre6"></p>
<p>与GRETAP一样，IP6GRETAP在内部标头中具有以太网头部：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/gre6tap.png" alt="gre6tap"></p>
<p>如下是创建GRE隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name gre1 <span class="built_in">type</span> ip6gre <span class="built_in">local</span> LOCAL_IPv6_ADDR remote REMOTE_IPv6_ADDR</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name gretap1 <span class="built_in">type</span> ip6gretap <span class="built_in">local</span> LOCAL_IPv6_ADDR remote REMOTE_IPv6_ADDR</span></span><br></pre></td></tr></table></figure>

<h2 id="FOU"><a href="#FOU" class="headerlink" title="FOU"></a>FOU</h2><p>隧道可以在网络堆栈的多个级别上发生。IPIP，SIT，GRE隧道位于IP级别，而FOU（UDP上的foo）是UDP级别的隧道。</p>
<p>使用UDP隧道具有一些优点，因为UDP与现有的硬件基础结构一起工作，例如NIC中的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Network_interface_controller#RSS">RSS</a>，交换机中的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing">ECMP</a>。开发人员的<a target="_blank" rel="noopener" href="https://lwn.net/Articles/614433/">验证结果</a>显示SIT和IPIP协议的性能显著提高。</p>
<p>当前，FOU隧道支持基于IPIP，SIT，GRE的封装协议。FOU报文头示例如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/fou.png" alt="fou"></p>
<p>如下是创建FOU隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip fou add port 5555 ipproto 4</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name tun1 <span class="built_in">type</span> ipip remote 192.168.1.1 <span class="built_in">local</span> 192.168.1.2 ttl 225 encap fou encap-sport auto encap-dport 5555</span></span><br></pre></td></tr></table></figure>

<p>第一条命令为绑定到5555的IPIP配置了FOU接收端口；对于GRE，需要设置<code>ipproto 47</code>。</p>
<p>第二条命令使用目标端口5555设置了用于FOU封装的新IPIP虚拟接口（tun1）。</p>
<p><strong>注意</strong>：Red Hat Enterprise Linux不支持FOU。</p>
<h2 id="GUE"><a href="#GUE" class="headerlink" title="GUE"></a>GUE</h2><p><a target="_blank" rel="noopener" href="https://tools.ietf.org/html/draft-ietf-intarea-gue">通用UDP封装</a>（GUE）是另一种UDP隧道。FOU和GUE之间的区别在于GUE具有自己的封装头，其中包含协议信息和其他数据。</p>
<p>当前，GUE隧道支持内部IPIP，SIT，GRE封装。GUE标头示例如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/gue.png" alt="gue"></p>
<p>如下是创建GUE隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip fou add port 5555 gue</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name tun1 <span class="built_in">type</span> ipip remote 192.168.1.1 <span class="built_in">local</span> 192.168.1.2 ttl 225 encap gue encap-sport auto encap-dport 5555</span></span><br></pre></td></tr></table></figure>

<p>这将为绑定到5555的IPIP设置一个GUE接收端口，并为GUE封装配置一个IPIP隧道。</p>
<p><strong>注意</strong>：Red Hat Enterprise Linux不支持GUE。</p>
<h2 id="GENEVE"><a href="#GENEVE" class="headerlink" title="GENEVE"></a>GENEVE</h2><p>通用网络虚拟化封装（GENEVE）支持VXLAN，NVGRE和STT的所有功能，旨在克服它们的局限性。许多人认为GENEVE最终可以完全取代这些早期格式。隧道头看起来如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/geneve.png" alt="geneve"></p>
<p>看起来非常类似于<a target="_blank" rel="noopener" href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/#vxlan">VXLAN</a>。主要区别在于GENEVE报文头是灵活的。通过使用新的Type-Length-Value（TLV）字段扩展标头来添加新功能非常容易。有关更多详细信息，可以查看最新的<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/draft-ietf-nvo3-geneve-08">ietf草案</a>或参考<a target="_blank" rel="noopener" href="https://www.redhat.com/en/blog/what-geneve">什么是GENEVE？</a></p>
<p><a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/networking_with_open_virtual_network/open_virtual_network_ovn">开放式虚拟网络（OVN）</a>使用GENEVE作为默认封装。</p>
<p>如下是创建GENEVE隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add name geneve0 <span class="built_in">type</span> geneve <span class="built_in">id</span> VNI remote REMOTE_IPv4_ADDR</span></span><br></pre></td></tr></table></figure>

<h2 id="ERSPAN和IP6ERSPAN"><a href="#ERSPAN和IP6ERSPAN" class="headerlink" title="ERSPAN和IP6ERSPAN"></a>ERSPAN和IP6ERSPAN</h2><p>封装的远程交换端口分析器（ERSPAN）使用GRE封装将基本的端口镜像功能从第2层扩展到第3层，从而允许通过可路由的IP网络发送镜像的流量。ERSPAN标头看起来如下所示：</p>
<p><img src="https://gitee.com/lyyao09/cdn/raw/master/linux/An-introduction-to-Linux-virtual-interfaces-Tunnels/erspan.png" alt="erspan"></p>
<p>ERSPAN隧道允许Linux主机充当ERSPAN流量源，并将ERSPAN镜像流量发送到远程主机或ERSPAN目标，后者接收并解析从Cisco或其他具有ERSPAN功能的交换机生成的ERSPAN数据包。此设置可用于分析，诊断和检测恶意流量。</p>
<p>Linux当前支持两个ERSPAN版本的大多数功能：v1（类型II）和v2（类型III）。</p>
<p>如下是创建ERSPAN隧道的方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add dev erspan1 <span class="built_in">type</span> erspan <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR <span class="built_in">seq</span> key KEY erspan_ver 1 erspan IDX</span></span><br><span class="line">or</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ip <span class="built_in">link</span> add dev erspan1 <span class="built_in">type</span> erspan <span class="built_in">local</span> LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR <span class="built_in">seq</span> key KEY erspan_ver 2 erspan_dir DIRECTION erspan_hwid HWID</span></span><br><span class="line"></span><br><span class="line">Add tc filter to monitor traffic</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tc qdisc add dev MONITOR_DEV handle ffff: ingress</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tc filter add dev MONITOR_DEV parent ffff: matchall skip_hw action mirred egress mirror dev erspan1</span></span><br></pre></td></tr></table></figure>

<h2 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h2><p>下面是我们介绍的所有隧道的总结。</p>
<table>
<thead>
<tr>
<th align="left">隧道&#x2F;链接类型</th>
<th align="left">外部报文头</th>
<th align="left">封装报文头</th>
<th align="left">内部报文头</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ipip</td>
<td align="left">IPv4</td>
<td align="left">None</td>
<td align="left">IPv4</td>
</tr>
<tr>
<td align="left">sit</td>
<td align="left">IPv4</td>
<td align="left">None</td>
<td align="left">IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">ip6tnl</td>
<td align="left">IPv6</td>
<td align="left">None</td>
<td align="left">IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">vti</td>
<td align="left">IPv4</td>
<td align="left">IPsec</td>
<td align="left">IPv4</td>
</tr>
<tr>
<td align="left">vti6</td>
<td align="left">IPv6</td>
<td align="left">IPsec</td>
<td align="left">IPv6</td>
</tr>
<tr>
<td align="left">gre</td>
<td align="left">IPv4</td>
<td align="left">GRE</td>
<td align="left">IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">gretap</td>
<td align="left">IPv4</td>
<td align="left">GRE</td>
<td align="left">以太网+ IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">ip6gre</td>
<td align="left">IPv6</td>
<td align="left">GRE</td>
<td align="left">IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">ip6gretap</td>
<td align="left">IPv6</td>
<td align="left">GRE</td>
<td align="left">以太网+ IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">fou</td>
<td align="left">IPv4 &#x2F; IPv6</td>
<td align="left">UDP</td>
<td align="left">IPv4 &#x2F; IPv6 &#x2F; GRE</td>
</tr>
<tr>
<td align="left">gue</td>
<td align="left">IPv4 &#x2F; IPv6</td>
<td align="left">UDP + GUE</td>
<td align="left">IPv4 &#x2F; IPv6 &#x2F; GRE</td>
</tr>
<tr>
<td align="left">geneve</td>
<td align="left">IPv4 &#x2F; IPv6</td>
<td align="left">UDP +geneve</td>
<td align="left">以太网+ IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">erspan</td>
<td align="left">IPv4</td>
<td align="left">GRE + ERSPAN</td>
<td align="left">IPv4 &#x2F; IPv6</td>
</tr>
<tr>
<td align="left">ip6erspan</td>
<td align="left">IPv6</td>
<td align="left">GRE + ERSPAN</td>
<td align="left">IPv4 &#x2F; IPv6</td>
</tr>
</tbody></table>
<p><strong>注意</strong>：本教程中的所有配置都是临时生效的，并且在服务器重新启动后会丢失。如果要使配置在重新引导后保持不变，请考虑使用网络配置守护程序，例如<a target="_blank" rel="noopener" href="https://developer.gnome.org/NetworkManager/stable/">NetworkManager</a>或特定于发行版的机制。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LeaoYao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">97</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LeaoYao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
